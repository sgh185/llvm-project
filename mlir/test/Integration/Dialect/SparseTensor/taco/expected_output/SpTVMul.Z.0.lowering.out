// -----// IR Dump After LinalgGeneralization (linalg-generalize-named-ops) //----- //
func.func @SpTVMul.Z.0.main(%arg0: tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>>, %arg1: tensor<64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense" ] }>>) -> tensor<16x32xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>> attributes {llvm.emit_c_interface} {
  %0 = bufferization.alloc_tensor() : tensor<16x32xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
  %1 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%arg0, %arg1 : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>>, tensor<64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense" ] }>>) outs(%0 : tensor<16x32xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %2 = arith.mulf %in, %in_0 : f32
    %3 = arith.addf %out, %2 : f32
    linalg.yield %3 : f32
  } -> tensor<16x32xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
  return %1 : tensor<16x32xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
}

// -----// IR Dump After PreSparsificationRewrite (pre-sparsification-rewrite) //----- //
#map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map1 = affine_map<(d0, d1, d2) -> (d2)>
#map2 = affine_map<(d0, d1, d2) -> (d0, d1)>
module {
  func.func @SpTVMul.Z.0.main(%arg0: tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>>, %arg1: tensor<64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense" ] }>>) -> tensor<16x32xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>> attributes {llvm.emit_c_interface} {
    %0 = bufferization.alloc_tensor() : tensor<16x32xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    %1 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "reduction"]} ins(%arg0, %arg1 : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>>, tensor<64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense" ] }>>) outs(%0 : tensor<16x32xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %2 = arith.mulf %in, %in_0 : f32
      %3 = arith.addf %out, %2 : f32
      linalg.yield %3 : f32
    } -> tensor<16x32xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    return %1 : tensor<16x32xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
  }
}


// -----// IR Dump After EmptyTensorToAllocTensor (empty-tensor-to-alloc-tensor) //----- //
func.func @SpTVMul.Z.0.main(%arg0: tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>>, %arg1: tensor<64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense" ] }>>) -> tensor<16x32xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>> attributes {llvm.emit_c_interface} {
  %0 = bufferization.alloc_tensor() : tensor<16x32xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
  %1 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>, affine_map<(d0, d1, d2) -> (d2)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"]} ins(%arg0, %arg1 : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>>, tensor<64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense" ] }>>) outs(%0 : tensor<16x32xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %2 = arith.mulf %in, %in_0 : f32
    %3 = arith.addf %out, %2 : f32
    linalg.yield %3 : f32
  } -> tensor<16x32xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
  return %1 : tensor<16x32xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
}

// -----// IR Dump After SparsificationPass (sparsification) //----- //
module {
  func.func @SpTVMul.Z.0.main(%arg0: tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>>, %arg1: tensor<64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense" ] }>>) -> tensor<16x32xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>> attributes {llvm.emit_c_interface} {
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = bufferization.alloc_tensor() {bufferization.escape = [true]} : tensor<16x32xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    %1 = sparse_tensor.positions %arg0 {level = 0 : index} : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xindex>
    %2 = sparse_tensor.coordinates %arg0 {level = 0 : index} : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xindex>
    %3 = sparse_tensor.positions %arg0 {level = 1 : index} : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xindex>
    %4 = sparse_tensor.coordinates %arg0 {level = 1 : index} : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xindex>
    %5 = sparse_tensor.positions %arg0 {level = 2 : index} : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xindex>
    %6 = sparse_tensor.coordinates %arg0 {level = 2 : index} : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xindex>
    %7 = sparse_tensor.values %arg0 : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xf32>
    %8 = sparse_tensor.values %arg1 : tensor<64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense" ] }>> to memref<?xf32>
    %9 = sparse_tensor.values %0 : tensor<16x32xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>> to memref<?xf32>
    %10 = memref.load %1[%c0] : memref<?xindex>
    %11 = memref.load %1[%c1] : memref<?xindex>
    scf.parallel (%arg2) = (%10) to (%11) step (%c1) {
      %13 = memref.load %2[%arg2] : memref<?xindex>
      %14 = memref.load %3[%arg2] : memref<?xindex>
      %15 = arith.addi %arg2, %c1 : index
      %16 = memref.load %3[%15] : memref<?xindex>
      scf.parallel (%arg3) = (%14) to (%16) step (%c1) {
        %17 = memref.load %4[%arg3] : memref<?xindex>
        %18 = arith.muli %13, %c32 : index
        %19 = arith.addi %18, %17 : index
        %20 = memref.load %9[%19] : memref<?xf32>
        %21 = memref.load %5[%arg3] : memref<?xindex>
        %22 = arith.addi %arg3, %c1 : index
        %23 = memref.load %5[%22] : memref<?xindex>
        %24 = scf.parallel (%arg4) = (%21) to (%23) step (%c1) init (%20) -> f32 {
          %25 = memref.load %6[%arg4] : memref<?xindex>
          %26 = memref.load %7[%arg4] : memref<?xf32>
          %27 = memref.load %8[%25] : memref<?xf32>
          %28 = arith.mulf %26, %27 : f32
          scf.reduce(%28)  : f32 {
          ^bb0(%arg5: f32, %arg6: f32):
            %29 = arith.addf %arg5, %arg6 : f32
            scf.reduce.return %29 : f32
          }
          scf.yield
        } {"Emitted from" = "linalg.generic"}
        memref.store %24, %9[%19] : memref<?xf32>
        scf.yield
      } {"Emitted from" = "linalg.generic"}
      scf.yield
    } {"Emitted from" = "linalg.generic"}
    %12 = sparse_tensor.load %0 : tensor<16x32xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    return %12 : tensor<16x32xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
  }
}


// -----// IR Dump After PostSparsificationRewrite (post-sparsification-rewrite) //----- //
module {
  func.func @SpTVMul.Z.0.main(%arg0: tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>>, %arg1: tensor<64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense" ] }>>) -> tensor<16x32xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>> attributes {llvm.emit_c_interface} {
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = bufferization.alloc_tensor() {bufferization.escape = [true]} : tensor<16x32xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    %1 = sparse_tensor.positions %arg0 {level = 0 : index} : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xindex>
    %2 = sparse_tensor.coordinates %arg0 {level = 0 : index} : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xindex>
    %3 = sparse_tensor.positions %arg0 {level = 1 : index} : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xindex>
    %4 = sparse_tensor.coordinates %arg0 {level = 1 : index} : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xindex>
    %5 = sparse_tensor.positions %arg0 {level = 2 : index} : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xindex>
    %6 = sparse_tensor.coordinates %arg0 {level = 2 : index} : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xindex>
    %7 = sparse_tensor.values %arg0 : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xf32>
    %8 = sparse_tensor.values %arg1 : tensor<64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense" ] }>> to memref<?xf32>
    %9 = sparse_tensor.values %0 : tensor<16x32xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>> to memref<?xf32>
    %10 = memref.load %1[%c0] : memref<?xindex>
    %11 = memref.load %1[%c1] : memref<?xindex>
    scf.parallel (%arg2) = (%10) to (%11) step (%c1) {
      %13 = memref.load %2[%arg2] : memref<?xindex>
      %14 = memref.load %3[%arg2] : memref<?xindex>
      %15 = arith.addi %arg2, %c1 : index
      %16 = memref.load %3[%15] : memref<?xindex>
      scf.parallel (%arg3) = (%14) to (%16) step (%c1) {
        %17 = memref.load %4[%arg3] : memref<?xindex>
        %18 = arith.muli %13, %c32 : index
        %19 = arith.addi %18, %17 : index
        %20 = memref.load %9[%19] : memref<?xf32>
        %21 = memref.load %5[%arg3] : memref<?xindex>
        %22 = arith.addi %arg3, %c1 : index
        %23 = memref.load %5[%22] : memref<?xindex>
        %24 = scf.parallel (%arg4) = (%21) to (%23) step (%c1) init (%20) -> f32 {
          %25 = memref.load %6[%arg4] : memref<?xindex>
          %26 = memref.load %7[%arg4] : memref<?xf32>
          %27 = memref.load %8[%25] : memref<?xf32>
          %28 = arith.mulf %26, %27 : f32
          scf.reduce(%28)  : f32 {
          ^bb0(%arg5: f32, %arg6: f32):
            %29 = arith.addf %arg5, %arg6 : f32
            scf.reduce.return %29 : f32
          }
          scf.yield
        } {"Emitted from" = "linalg.generic"}
        memref.store %24, %9[%19] : memref<?xf32>
        scf.yield
      } {"Emitted from" = "linalg.generic"}
      scf.yield
    } {"Emitted from" = "linalg.generic"}
    %12 = sparse_tensor.load %0 : tensor<16x32xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    return %12 : tensor<16x32xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
  }
}


// -----// IR Dump After SparseTensorCodegen (sparse-tensor-codegen) //----- //
module {
  func.func @SpTVMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>>, %arg8: memref<?xf32>, %arg9: !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense" ] }>>) -> (memref<?xf32>, !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>) attributes {llvm.emit_c_interface} {
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c16 = arith.constant 16 : index
    %c32_0 = arith.constant 32 : index
    %0 = arith.muli %c16, %c32_0 : index
    %alloc = memref.alloc(%0) : memref<?xf32>
    %1 = sparse_tensor.storage_specifier.init : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    %c0_1 = arith.constant 0 : index
    %2 = sparse_tensor.storage_specifier.set %1  lvl_sz at 0 with %c16 : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    %3 = sparse_tensor.storage_specifier.set %2  lvl_sz at 1 with %c32_0 : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    %c1_2 = arith.constant 1 : index
    %c16_3 = arith.constant 16 : index
    %4 = arith.muli %c1_2, %c16_3 : index
    %c32_4 = arith.constant 32 : index
    %5 = arith.muli %4, %c32_4 : index
    %cst = arith.constant 0.000000e+00 : f32
    %6 = sparse_tensor.storage_specifier.get %3  val_mem_sz : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    %outBuffer, %newSize = sparse_tensor.push_back %6, %alloc, %cst, %5 : index, memref<?xf32>, f32, index
    %7 = sparse_tensor.storage_specifier.set %3  val_mem_sz with %newSize : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    %8 = builtin.unrealized_conversion_cast %outBuffer, %7 : memref<?xf32>, !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>> to tensor<16x32xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    %9 = memref.load %arg0[%c0] : memref<?xindex>
    %10 = memref.load %arg0[%c1] : memref<?xindex>
    scf.parallel (%arg10) = (%9) to (%10) step (%c1) {
      %12 = memref.load %arg1[%arg10] : memref<?xindex>
      %13 = memref.load %arg2[%arg10] : memref<?xindex>
      %14 = arith.addi %arg10, %c1 : index
      %15 = memref.load %arg2[%14] : memref<?xindex>
      scf.parallel (%arg11) = (%13) to (%15) step (%c1) {
        %16 = memref.load %arg3[%arg11] : memref<?xindex>
        %17 = arith.muli %12, %c32 : index
        %18 = arith.addi %17, %16 : index
        %19 = memref.load %outBuffer[%18] : memref<?xf32>
        %20 = memref.load %arg4[%arg11] : memref<?xindex>
        %21 = arith.addi %arg11, %c1 : index
        %22 = memref.load %arg4[%21] : memref<?xindex>
        %23 = scf.parallel (%arg12) = (%20) to (%22) step (%c1) init (%19) -> f32 {
          %24 = memref.load %arg5[%arg12] : memref<?xindex>
          %25 = memref.load %arg6[%arg12] : memref<?xf32>
          %26 = memref.load %arg8[%24] : memref<?xf32>
          %27 = arith.mulf %25, %26 : f32
          scf.reduce(%27)  : f32 {
          ^bb0(%arg13: f32, %arg14: f32):
            %28 = arith.addf %arg13, %arg14 : f32
            scf.reduce.return %28 : f32
          }
          scf.yield
        } {"Emitted from" = "linalg.generic"}
        memref.store %23, %outBuffer[%18] : memref<?xf32>
        scf.yield
      } {"Emitted from" = "linalg.generic"}
      scf.yield
    } {"Emitted from" = "linalg.generic"}
    %11 = builtin.unrealized_conversion_cast %outBuffer, %7 : memref<?xf32>, !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>> to tensor<16x32xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    return %outBuffer, %7 : memref<?xf32>, !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
  }
}


// -----// IR Dump After SparseBufferRewrite (sparse-buffer-rewrite) //----- //
module {
  func.func @SpTVMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>>, %arg8: memref<?xf32>, %arg9: !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense" ] }>>) -> (memref<?xf32>, !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>) attributes {llvm.emit_c_interface} {
    %c512 = arith.constant 512 : index
    %c16 = arith.constant 16 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %alloc = memref.alloc(%c512) : memref<?xf32>
    %0 = sparse_tensor.storage_specifier.init : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    %1 = sparse_tensor.storage_specifier.set %0  lvl_sz at 0 with %c16 : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    %2 = sparse_tensor.storage_specifier.set %1  lvl_sz at 1 with %c32 : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    %3 = sparse_tensor.storage_specifier.get %2  val_mem_sz : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    %4 = arith.addi %3, %c512 : index
    %5 = arith.cmpi ugt, %4, %c512 : index
    %6 = scf.if %5 -> (memref<?xf32>) {
      %10 = scf.while (%arg10 = %c512) : (index) -> index {
        %12 = arith.muli %arg10, %c2 : index
        %13 = arith.cmpi ugt, %4, %12 : index
        scf.condition(%13) %12 : index
      } do {
      ^bb0(%arg10: index):
        scf.yield %arg10 : index
      }
      %11 = memref.realloc %alloc(%10) : memref<?xf32> to memref<?xf32>
      scf.yield %11 : memref<?xf32>
    } else {
      scf.yield %alloc : memref<?xf32>
    }
    %subview = memref.subview %6[%3] [%c512] [%c1] : memref<?xf32> to memref<?xf32, strided<[?], offset: ?>>
    linalg.fill ins(%cst : f32) outs(%subview : memref<?xf32, strided<[?], offset: ?>>)
    %7 = sparse_tensor.storage_specifier.set %2  val_mem_sz with %4 : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
    %8 = memref.load %arg0[%c0] : memref<?xindex>
    %9 = memref.load %arg0[%c1] : memref<?xindex>
    scf.parallel (%arg10) = (%8) to (%9) step (%c1) {
      %10 = memref.load %arg1[%arg10] : memref<?xindex>
      %11 = memref.load %arg2[%arg10] : memref<?xindex>
      %12 = arith.addi %arg10, %c1 : index
      %13 = memref.load %arg2[%12] : memref<?xindex>
      scf.parallel (%arg11) = (%11) to (%13) step (%c1) {
        %14 = memref.load %arg3[%arg11] : memref<?xindex>
        %15 = arith.muli %10, %c32 : index
        %16 = arith.addi %15, %14 : index
        %17 = memref.load %6[%16] : memref<?xf32>
        %18 = memref.load %arg4[%arg11] : memref<?xindex>
        %19 = arith.addi %arg11, %c1 : index
        %20 = memref.load %arg4[%19] : memref<?xindex>
        %21 = scf.parallel (%arg12) = (%18) to (%20) step (%c1) init (%17) -> f32 {
          %22 = memref.load %arg5[%arg12] : memref<?xindex>
          %23 = memref.load %arg6[%arg12] : memref<?xf32>
          %24 = memref.load %arg8[%22] : memref<?xf32>
          %25 = arith.mulf %23, %24 : f32
          scf.reduce(%25)  : f32 {
          ^bb0(%arg13: f32, %arg14: f32):
            %26 = arith.addf %arg13, %arg14 : f32
            scf.reduce.return %26 : f32
          }
          scf.yield
        } {"Emitted from" = "linalg.generic"}
        memref.store %21, %6[%16] : memref<?xf32>
        scf.yield
      } {"Emitted from" = "linalg.generic"}
      scf.yield
    } {"Emitted from" = "linalg.generic"}
    return %6, %7 : memref<?xf32>, !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>
  }
}


// -----// IR Dump After StorageSpecifierToLLVM (sparse-storage-specifier-to-llvm) //----- //
module {
  func.func @SpTVMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<1 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %c512 = arith.constant 512 : index
    %c16 = arith.constant 16 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %alloc = memref.alloc(%c512) : memref<?xf32>
    %0 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %c0_i64 = arith.constant 0 : i64
    %1 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %2 = arith.index_cast %c16 : index to i64
    %3 = llvm.insertvalue %2, %1[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %4 = arith.index_cast %c32 : index to i64
    %5 = llvm.insertvalue %4, %3[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %6 = llvm.extractvalue %5[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %7 = arith.index_cast %6 : i64 to index
    %8 = arith.addi %7, %c512 : index
    %9 = arith.cmpi ugt, %8, %c512 : index
    %10 = scf.if %9 -> (memref<?xf32>) {
      %15 = scf.while (%arg10 = %c512) : (index) -> index {
        %17 = arith.muli %arg10, %c2 : index
        %18 = arith.cmpi ugt, %8, %17 : index
        scf.condition(%18) %17 : index
      } do {
      ^bb0(%arg10: index):
        scf.yield %arg10 : index
      }
      %16 = memref.realloc %alloc(%15) : memref<?xf32> to memref<?xf32>
      scf.yield %16 : memref<?xf32>
    } else {
      scf.yield %alloc : memref<?xf32>
    }
    %subview = memref.subview %10[%7] [%c512] [%c1] : memref<?xf32> to memref<?xf32, strided<[?], offset: ?>>
    linalg.fill ins(%cst : f32) outs(%subview : memref<?xf32, strided<[?], offset: ?>>)
    %11 = arith.index_cast %8 : index to i64
    %12 = llvm.insertvalue %11, %5[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %13 = memref.load %arg0[%c0] : memref<?xindex>
    %14 = memref.load %arg0[%c1] : memref<?xindex>
    scf.parallel (%arg10) = (%13) to (%14) step (%c1) {
      %15 = memref.load %arg1[%arg10] : memref<?xindex>
      %16 = memref.load %arg2[%arg10] : memref<?xindex>
      %17 = arith.addi %arg10, %c1 : index
      %18 = memref.load %arg2[%17] : memref<?xindex>
      scf.parallel (%arg11) = (%16) to (%18) step (%c1) {
        %19 = memref.load %arg3[%arg11] : memref<?xindex>
        %20 = arith.muli %15, %c32 : index
        %21 = arith.addi %20, %19 : index
        %22 = memref.load %10[%21] : memref<?xf32>
        %23 = memref.load %arg4[%arg11] : memref<?xindex>
        %24 = arith.addi %arg11, %c1 : index
        %25 = memref.load %arg4[%24] : memref<?xindex>
        %26 = scf.parallel (%arg12) = (%23) to (%25) step (%c1) init (%22) -> f32 {
          %27 = memref.load %arg5[%arg12] : memref<?xindex>
          %28 = memref.load %arg6[%arg12] : memref<?xf32>
          %29 = memref.load %arg8[%27] : memref<?xf32>
          %30 = arith.mulf %28, %29 : f32
          scf.reduce(%30)  : f32 {
          ^bb0(%arg13: f32, %arg14: f32):
            %31 = arith.addf %arg13, %arg14 : f32
            scf.reduce.return %31 : f32
          }
          scf.yield
        } {"Emitted from" = "linalg.generic"}
        memref.store %26, %10[%21] : memref<?xf32>
        scf.yield
      } {"Emitted from" = "linalg.generic"}
      scf.yield
    } {"Emitted from" = "linalg.generic"}
    return %10, %12 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After mlir::sparse_tensor::SparsificationAndBufferizationPass () //----- //
module {
  func.func @SpTVMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<1 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %c512 = arith.constant 512 : index
    %c16 = arith.constant 16 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %alloc = memref.alloc(%c512) : memref<?xf32>
    %0 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %c0_i64 = arith.constant 0 : i64
    %1 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %2 = arith.index_cast %c16 : index to i64
    %3 = llvm.insertvalue %2, %1[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %4 = arith.index_cast %c32 : index to i64
    %5 = llvm.insertvalue %4, %3[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %6 = llvm.extractvalue %5[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %7 = arith.index_cast %6 : i64 to index
    %8 = arith.addi %7, %c512 : index
    %9 = arith.cmpi ugt, %8, %c512 : index
    %10 = scf.if %9 -> (memref<?xf32>) {
      %15 = scf.while (%arg10 = %c512) : (index) -> index {
        %17 = arith.muli %arg10, %c2 : index
        %18 = arith.cmpi ugt, %8, %17 : index
        scf.condition(%18) %17 : index
      } do {
      ^bb0(%arg10: index):
        scf.yield %arg10 : index
      }
      %16 = memref.realloc %alloc(%15) : memref<?xf32> to memref<?xf32>
      scf.yield %16 : memref<?xf32>
    } else {
      scf.yield %alloc : memref<?xf32>
    }
    %subview = memref.subview %10[%7] [%c512] [%c1] : memref<?xf32> to memref<?xf32, strided<[?], offset: ?>>
    linalg.fill ins(%cst : f32) outs(%subview : memref<?xf32, strided<[?], offset: ?>>)
    %11 = arith.index_cast %8 : index to i64
    %12 = llvm.insertvalue %11, %5[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %13 = memref.load %arg0[%c0] : memref<?xindex>
    %14 = memref.load %arg0[%c1] : memref<?xindex>
    scf.parallel (%arg10) = (%13) to (%14) step (%c1) {
      %15 = memref.load %arg1[%arg10] : memref<?xindex>
      %16 = memref.load %arg2[%arg10] : memref<?xindex>
      %17 = arith.addi %arg10, %c1 : index
      %18 = memref.load %arg2[%17] : memref<?xindex>
      scf.parallel (%arg11) = (%16) to (%18) step (%c1) {
        %19 = memref.load %arg3[%arg11] : memref<?xindex>
        %20 = arith.muli %15, %c32 : index
        %21 = arith.addi %20, %19 : index
        %22 = memref.load %10[%21] : memref<?xf32>
        %23 = memref.load %arg4[%arg11] : memref<?xindex>
        %24 = arith.addi %arg11, %c1 : index
        %25 = memref.load %arg4[%24] : memref<?xindex>
        %26 = scf.parallel (%arg12) = (%23) to (%25) step (%c1) init (%22) -> f32 {
          %27 = memref.load %arg5[%arg12] : memref<?xindex>
          %28 = memref.load %arg6[%arg12] : memref<?xf32>
          %29 = memref.load %arg8[%27] : memref<?xf32>
          %30 = arith.mulf %28, %29 : f32
          scf.reduce(%30)  : f32 {
          ^bb0(%arg13: f32, %arg14: f32):
            %31 = arith.addf %arg13, %arg14 : f32
            scf.reduce.return %31 : f32
          }
          scf.yield
        } {"Emitted from" = "linalg.generic"}
        memref.store %26, %10[%21] : memref<?xf32>
        scf.yield
      } {"Emitted from" = "linalg.generic"}
      scf.yield
    } {"Emitted from" = "linalg.generic"}
    return %10, %12 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @SpTVMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<1 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
  %c512_i64 = arith.constant 512 : i64
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %c16_i64 = arith.constant 16 : i64
  %c0_i64 = arith.constant 0 : i64
  %c1 = arith.constant 1 : index
  %cst = arith.constant 0.000000e+00 : f32
  %c32 = arith.constant 32 : index
  %alloc = memref.alloc() : memref<512xf32>
  %cast = memref.cast %alloc : memref<512xf32> to memref<?xf32>
  %0 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  %1 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %2 = llvm.insertvalue %c16_i64, %1[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %3 = llvm.insertvalue %c32_i64, %2[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  linalg.fill ins(%cst : f32) outs(%alloc : memref<512xf32>)
  %4 = llvm.insertvalue %c512_i64, %3[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %5 = memref.load %arg0[%c0] : memref<?xindex>
  %6 = memref.load %arg0[%c1] : memref<?xindex>
  scf.parallel (%arg10) = (%5) to (%6) step (%c1) {
    %7 = memref.load %arg1[%arg10] : memref<?xindex>
    %8 = memref.load %arg2[%arg10] : memref<?xindex>
    %9 = arith.addi %arg10, %c1 : index
    %10 = memref.load %arg2[%9] : memref<?xindex>
    scf.parallel (%arg11) = (%8) to (%10) step (%c1) {
      %11 = memref.load %arg3[%arg11] : memref<?xindex>
      %12 = arith.muli %7, %c32 : index
      %13 = arith.addi %12, %11 : index
      %14 = memref.load %alloc[%13] : memref<512xf32>
      %15 = memref.load %arg4[%arg11] : memref<?xindex>
      %16 = arith.addi %arg11, %c1 : index
      %17 = memref.load %arg4[%16] : memref<?xindex>
      %18 = scf.parallel (%arg12) = (%15) to (%17) step (%c1) init (%14) -> f32 {
        %19 = memref.load %arg5[%arg12] : memref<?xindex>
        %20 = memref.load %arg6[%arg12] : memref<?xf32>
        %21 = memref.load %arg8[%19] : memref<?xf32>
        %22 = arith.mulf %20, %21 : f32
        scf.reduce(%22)  : f32 {
        ^bb0(%arg13: f32, %arg14: f32):
          %23 = arith.addf %arg13, %arg14 : f32
          scf.reduce.return %23 : f32
        }
        scf.yield
      } {"Emitted from" = "linalg.generic"}
      memref.store %18, %alloc[%13] : memref<512xf32>
      scf.yield
    } {"Emitted from" = "linalg.generic"}
    scf.yield
  } {"Emitted from" = "linalg.generic"}
  return %cast, %4 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
}

// -----// IR Dump After FinalizingBufferize (finalizing-bufferize) //----- //
func.func @SpTVMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<1 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
  %c512_i64 = arith.constant 512 : i64
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %c16_i64 = arith.constant 16 : i64
  %c0_i64 = arith.constant 0 : i64
  %c1 = arith.constant 1 : index
  %cst = arith.constant 0.000000e+00 : f32
  %c32 = arith.constant 32 : index
  %alloc = memref.alloc() : memref<512xf32>
  %cast = memref.cast %alloc : memref<512xf32> to memref<?xf32>
  %0 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  %1 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %2 = llvm.insertvalue %c16_i64, %1[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %3 = llvm.insertvalue %c32_i64, %2[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  linalg.fill ins(%cst : f32) outs(%alloc : memref<512xf32>)
  %4 = llvm.insertvalue %c512_i64, %3[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %5 = memref.load %arg0[%c0] : memref<?xindex>
  %6 = memref.load %arg0[%c1] : memref<?xindex>
  scf.parallel (%arg10) = (%5) to (%6) step (%c1) {
    %7 = memref.load %arg1[%arg10] : memref<?xindex>
    %8 = memref.load %arg2[%arg10] : memref<?xindex>
    %9 = arith.addi %arg10, %c1 : index
    %10 = memref.load %arg2[%9] : memref<?xindex>
    scf.parallel (%arg11) = (%8) to (%10) step (%c1) {
      %11 = memref.load %arg3[%arg11] : memref<?xindex>
      %12 = arith.muli %7, %c32 : index
      %13 = arith.addi %12, %11 : index
      %14 = memref.load %alloc[%13] : memref<512xf32>
      %15 = memref.load %arg4[%arg11] : memref<?xindex>
      %16 = arith.addi %arg11, %c1 : index
      %17 = memref.load %arg4[%16] : memref<?xindex>
      %18 = scf.parallel (%arg12) = (%15) to (%17) step (%c1) init (%14) -> f32 {
        %19 = memref.load %arg5[%arg12] : memref<?xindex>
        %20 = memref.load %arg6[%arg12] : memref<?xf32>
        %21 = memref.load %arg8[%19] : memref<?xf32>
        %22 = arith.mulf %20, %21 : f32
        scf.reduce(%22)  : f32 {
        ^bb0(%arg13: f32, %arg14: f32):
          %23 = arith.addf %arg13, %arg14 : f32
          scf.reduce.return %23 : f32
        }
        scf.yield
      } {"Emitted from" = "linalg.generic"}
      memref.store %18, %alloc[%13] : memref<512xf32>
      scf.yield
    } {"Emitted from" = "linalg.generic"}
    scf.yield
  } {"Emitted from" = "linalg.generic"}
  return %cast, %4 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
}

// -----// IR Dump After LinalgLowerToLoops (convert-linalg-to-loops) //----- //
func.func @SpTVMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<1 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1 = arith.constant 1 : index
  %c512_i64 = arith.constant 512 : i64
  %c32_i64 = arith.constant 32 : i64
  %c16_i64 = arith.constant 16 : i64
  %c0_i64 = arith.constant 0 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %c32 = arith.constant 32 : index
  %alloc = memref.alloc() : memref<512xf32>
  %cast = memref.cast %alloc : memref<512xf32> to memref<?xf32>
  %0 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  %1 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %2 = llvm.insertvalue %c16_i64, %1[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %3 = llvm.insertvalue %c32_i64, %2[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  scf.for %arg10 = %c0 to %c512 step %c1 {
    memref.store %cst, %alloc[%arg10] : memref<512xf32>
  }
  %4 = llvm.insertvalue %c512_i64, %3[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %5 = memref.load %arg0[%c0] : memref<?xindex>
  %6 = memref.load %arg0[%c1] : memref<?xindex>
  scf.parallel (%arg10) = (%5) to (%6) step (%c1) {
    %7 = memref.load %arg1[%arg10] : memref<?xindex>
    %8 = memref.load %arg2[%arg10] : memref<?xindex>
    %9 = arith.addi %arg10, %c1 : index
    %10 = memref.load %arg2[%9] : memref<?xindex>
    scf.parallel (%arg11) = (%8) to (%10) step (%c1) {
      %11 = memref.load %arg3[%arg11] : memref<?xindex>
      %12 = arith.muli %7, %c32 : index
      %13 = arith.addi %12, %11 : index
      %14 = memref.load %alloc[%13] : memref<512xf32>
      %15 = memref.load %arg4[%arg11] : memref<?xindex>
      %16 = arith.addi %arg11, %c1 : index
      %17 = memref.load %arg4[%16] : memref<?xindex>
      %18 = scf.parallel (%arg12) = (%15) to (%17) step (%c1) init (%14) -> f32 {
        %19 = memref.load %arg5[%arg12] : memref<?xindex>
        %20 = memref.load %arg6[%arg12] : memref<?xf32>
        %21 = memref.load %arg8[%19] : memref<?xf32>
        %22 = arith.mulf %20, %21 : f32
        scf.reduce(%22)  : f32 {
        ^bb0(%arg13: f32, %arg14: f32):
          %23 = arith.addf %arg13, %arg14 : f32
          scf.reduce.return %23 : f32
        }
        scf.yield
      } {"Emitted from" = "linalg.generic"}
      memref.store %18, %alloc[%13] : memref<512xf32>
      scf.yield
    } {"Emitted from" = "linalg.generic"}
    scf.yield
  } {"Emitted from" = "linalg.generic"}
  return %cast, %4 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
}

// -----// IR Dump After ConvertVectorToSCF (convert-vector-to-scf) //----- //
func.func @SpTVMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<1 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1 = arith.constant 1 : index
  %c512_i64 = arith.constant 512 : i64
  %c32_i64 = arith.constant 32 : i64
  %c16_i64 = arith.constant 16 : i64
  %c0_i64 = arith.constant 0 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %c32 = arith.constant 32 : index
  %alloc = memref.alloc() : memref<512xf32>
  %cast = memref.cast %alloc : memref<512xf32> to memref<?xf32>
  %0 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  %1 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %2 = llvm.insertvalue %c16_i64, %1[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %3 = llvm.insertvalue %c32_i64, %2[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  scf.for %arg10 = %c0 to %c512 step %c1 {
    memref.store %cst, %alloc[%arg10] : memref<512xf32>
  }
  %4 = llvm.insertvalue %c512_i64, %3[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %5 = memref.load %arg0[%c0] : memref<?xindex>
  %6 = memref.load %arg0[%c1] : memref<?xindex>
  scf.parallel (%arg10) = (%5) to (%6) step (%c1) {
    %7 = memref.load %arg1[%arg10] : memref<?xindex>
    %8 = memref.load %arg2[%arg10] : memref<?xindex>
    %9 = arith.addi %arg10, %c1 : index
    %10 = memref.load %arg2[%9] : memref<?xindex>
    scf.parallel (%arg11) = (%8) to (%10) step (%c1) {
      %11 = memref.load %arg3[%arg11] : memref<?xindex>
      %12 = arith.muli %7, %c32 : index
      %13 = arith.addi %12, %11 : index
      %14 = memref.load %alloc[%13] : memref<512xf32>
      %15 = memref.load %arg4[%arg11] : memref<?xindex>
      %16 = arith.addi %arg11, %c1 : index
      %17 = memref.load %arg4[%16] : memref<?xindex>
      %18 = scf.parallel (%arg12) = (%15) to (%17) step (%c1) init (%14) -> f32 {
        %19 = memref.load %arg5[%arg12] : memref<?xindex>
        %20 = memref.load %arg6[%arg12] : memref<?xf32>
        %21 = memref.load %arg8[%19] : memref<?xf32>
        %22 = arith.mulf %20, %21 : f32
        scf.reduce(%22)  : f32 {
        ^bb0(%arg13: f32, %arg14: f32):
          %23 = arith.addf %arg13, %arg14 : f32
          scf.reduce.return %23 : f32
        }
        scf.yield
      } {"Emitted from" = "linalg.generic"}
      memref.store %18, %alloc[%13] : memref<512xf32>
      scf.yield
    } {"Emitted from" = "linalg.generic"}
    scf.yield
  } {"Emitted from" = "linalg.generic"}
  return %cast, %4 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
}

// -----// IR Dump After ConvertSCFToOpenMPPass (convert-scf-to-openmp) //----- //
module {
  omp.reduction.declare @__scf_reduction : f32 init {
  ^bb0(%arg0: f32):
    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    omp.yield(%0 : f32)
  } combiner {
  ^bb0(%arg0: f32, %arg1: f32):
    %0 = arith.addf %arg0, %arg1 : f32
    omp.yield(%0 : f32)
  } atomic {
  ^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr):
    %0 = llvm.load %arg1 : !llvm.ptr -> f32
    %1 = llvm.atomicrmw fadd %arg0, %0 monotonic : !llvm.ptr, f32
    omp.yield
  }
  func.func @SpTVMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<1 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1 = arith.constant 1 : index
    %c512_i64 = arith.constant 512 : i64
    %c32_i64 = arith.constant 32 : i64
    %c16_i64 = arith.constant 16 : i64
    %c0_i64 = arith.constant 0 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %c32 = arith.constant 32 : index
    %alloc = memref.alloc() : memref<512xf32>
    %cast = memref.cast %alloc : memref<512xf32> to memref<?xf32>
    %0 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %1 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %2 = llvm.insertvalue %c16_i64, %1[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %3 = llvm.insertvalue %c32_i64, %2[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    scf.for %arg10 = %c0 to %c512 step %c1 {
      memref.store %cst, %alloc[%arg10] : memref<512xf32>
    }
    %4 = llvm.insertvalue %c512_i64, %3[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %5 = memref.load %arg0[%c0] : memref<?xindex>
    %6 = memref.load %arg0[%c1] : memref<?xindex>
    %7 = llvm.mlir.constant(1 : i64) : i64
    omp.parallel   {
      omp.wsloop   for  (%arg10) : index = (%5) to (%6) step (%c1) {
        memref.alloca_scope  {
          %8 = memref.load %arg1[%arg10] : memref<?xindex>
          %9 = memref.load %arg2[%arg10] : memref<?xindex>
          %10 = arith.addi %arg10, %c1 : index
          %11 = memref.load %arg2[%10] : memref<?xindex>
          %12 = llvm.mlir.constant(1 : i64) : i64
          omp.parallel   {
            omp.wsloop   for  (%arg11) : index = (%9) to (%11) step (%c1) {
              memref.alloca_scope  {
                %13 = memref.load %arg3[%arg11] : memref<?xindex>
                %14 = arith.muli %8, %c32 : index
                %15 = arith.addi %14, %13 : index
                %16 = memref.load %alloc[%15] : memref<512xf32>
                %17 = memref.load %arg4[%arg11] : memref<?xindex>
                %18 = arith.addi %arg11, %c1 : index
                %19 = memref.load %arg4[%18] : memref<?xindex>
                %20 = llvm.mlir.constant(1 : i64) : i64
                %21 = llvm.alloca %20 x f32 : (i64) -> !llvm.ptr
                llvm.store %16, %21 : f32, !llvm.ptr
                omp.parallel   {
                  omp.wsloop   reduction(@__scf_reduction -> %21 : !llvm.ptr) for  (%arg12) : index = (%17) to (%19) step (%c1) {
                    memref.alloca_scope  {
                      %23 = memref.load %arg5[%arg12] : memref<?xindex>
                      %24 = memref.load %arg6[%arg12] : memref<?xf32>
                      %25 = memref.load %arg8[%23] : memref<?xf32>
                      %26 = arith.mulf %24, %25 : f32
                      omp.reduction %26, %21 : f32, !llvm.ptr
                    }
                    omp.yield
                  }
                  omp.terminator
                }
                %22 = llvm.load %21 : !llvm.ptr -> f32
                memref.store %22, %alloc[%15] : memref<512xf32>
              }
              omp.yield
            }
            omp.terminator
          }
        }
        omp.yield
      }
      omp.terminator
    }
    return %cast, %4 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @SpTVMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<1 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
  %0 = llvm.mlir.constant(1 : i64) : i64
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1 = arith.constant 1 : index
  %c512_i64 = arith.constant 512 : i64
  %c32_i64 = arith.constant 32 : i64
  %c16_i64 = arith.constant 16 : i64
  %c0_i64 = arith.constant 0 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %c32 = arith.constant 32 : index
  %alloc = memref.alloc() : memref<512xf32>
  %cast = memref.cast %alloc : memref<512xf32> to memref<?xf32>
  %1 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  %2 = llvm.insertvalue %c0_i64, %1[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %3 = llvm.insertvalue %c16_i64, %2[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %4 = llvm.insertvalue %c32_i64, %3[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  scf.for %arg10 = %c0 to %c512 step %c1 {
    memref.store %cst, %alloc[%arg10] : memref<512xf32>
  }
  %5 = llvm.insertvalue %c512_i64, %4[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %6 = memref.load %arg0[%c0] : memref<?xindex>
  %7 = memref.load %arg0[%c1] : memref<?xindex>
  omp.parallel   {
    omp.wsloop   for  (%arg10) : index = (%6) to (%7) step (%c1) {
      %8 = memref.load %arg1[%arg10] : memref<?xindex>
      %9 = memref.load %arg2[%arg10] : memref<?xindex>
      %10 = arith.addi %arg10, %c1 : index
      %11 = memref.load %arg2[%10] : memref<?xindex>
      omp.parallel   {
        %12 = llvm.alloca %0 x f32 : (i64) -> !llvm.ptr
        omp.wsloop   for  (%arg11) : index = (%9) to (%11) step (%c1) {
          %13 = memref.load %arg3[%arg11] : memref<?xindex>
          %14 = arith.muli %8, %c32 : index
          %15 = arith.addi %14, %13 : index
          %16 = memref.load %alloc[%15] : memref<512xf32>
          %17 = memref.load %arg4[%arg11] : memref<?xindex>
          %18 = arith.addi %arg11, %c1 : index
          %19 = memref.load %arg4[%18] : memref<?xindex>
          llvm.store %16, %12 : f32, !llvm.ptr
          omp.parallel   {
            omp.wsloop   reduction(@__scf_reduction -> %12 : !llvm.ptr) for  (%arg12) : index = (%17) to (%19) step (%c1) {
              memref.alloca_scope  {
                %21 = memref.load %arg5[%arg12] : memref<?xindex>
                %22 = memref.load %arg6[%arg12] : memref<?xf32>
                %23 = memref.load %arg8[%21] : memref<?xf32>
                %24 = arith.mulf %22, %23 : f32
                omp.reduction %24, %12 : f32, !llvm.ptr
              }
              omp.yield
            }
            omp.terminator
          }
          %20 = llvm.load %12 : !llvm.ptr -> f32
          memref.store %20, %alloc[%15] : memref<512xf32>
          omp.yield
        }
        omp.terminator
      }
      omp.yield
    }
    omp.terminator
  }
  return %cast, %5 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
func.func @SpTVMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<1 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
  %0 = llvm.mlir.constant(1 : i64) : i64
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1 = arith.constant 1 : index
  %c512_i64 = arith.constant 512 : i64
  %c32_i64 = arith.constant 32 : i64
  %c16_i64 = arith.constant 16 : i64
  %c0_i64 = arith.constant 0 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %c32 = arith.constant 32 : index
  %alloc = memref.alloc() : memref<512xf32>
  %cast = memref.cast %alloc : memref<512xf32> to memref<?xf32>
  %1 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  %2 = llvm.insertvalue %c0_i64, %1[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %3 = llvm.insertvalue %c16_i64, %2[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %4 = llvm.insertvalue %c32_i64, %3[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  cf.br ^bb1(%c0 : index)
^bb1(%5: index):  // 2 preds: ^bb0, ^bb2
  %6 = arith.cmpi slt, %5, %c512 : index
  cf.cond_br %6, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  memref.store %cst, %alloc[%5] : memref<512xf32>
  %7 = arith.addi %5, %c1 : index
  cf.br ^bb1(%7 : index)
^bb3:  // pred: ^bb1
  %8 = llvm.insertvalue %c512_i64, %4[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %9 = memref.load %arg0[%c0] : memref<?xindex>
  %10 = memref.load %arg0[%c1] : memref<?xindex>
  omp.parallel   {
    omp.wsloop   for  (%arg10) : index = (%9) to (%10) step (%c1) {
      %11 = memref.load %arg1[%arg10] : memref<?xindex>
      %12 = memref.load %arg2[%arg10] : memref<?xindex>
      %13 = arith.addi %arg10, %c1 : index
      %14 = memref.load %arg2[%13] : memref<?xindex>
      omp.parallel   {
        %15 = llvm.alloca %0 x f32 : (i64) -> !llvm.ptr
        omp.wsloop   for  (%arg11) : index = (%12) to (%14) step (%c1) {
          %16 = memref.load %arg3[%arg11] : memref<?xindex>
          %17 = arith.muli %11, %c32 : index
          %18 = arith.addi %17, %16 : index
          %19 = memref.load %alloc[%18] : memref<512xf32>
          %20 = memref.load %arg4[%arg11] : memref<?xindex>
          %21 = arith.addi %arg11, %c1 : index
          %22 = memref.load %arg4[%21] : memref<?xindex>
          llvm.store %19, %15 : f32, !llvm.ptr
          omp.parallel   {
            omp.wsloop   reduction(@__scf_reduction -> %15 : !llvm.ptr) for  (%arg12) : index = (%20) to (%22) step (%c1) {
              memref.alloca_scope  {
                %24 = memref.load %arg5[%arg12] : memref<?xindex>
                %25 = memref.load %arg6[%arg12] : memref<?xf32>
                %26 = memref.load %arg8[%24] : memref<?xf32>
                %27 = arith.mulf %25, %26 : f32
                omp.reduction %27, %15 : f32, !llvm.ptr
              }
              omp.yield
            }
            omp.terminator
          }
          %23 = llvm.load %15 : !llvm.ptr -> f32
          memref.store %23, %alloc[%18] : memref<512xf32>
          omp.yield
        }
        omp.terminator
      }
      omp.yield
    }
    omp.terminator
  }
  return %cast, %8 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
}

// -----// IR Dump After ExpandStridedMetadata (expand-strided-metadata) //----- //
module {
  omp.reduction.declare @__scf_reduction : f32 init {
  ^bb0(%arg0: f32):
    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    omp.yield(%0 : f32)
  } combiner {
  ^bb0(%arg0: f32, %arg1: f32):
    %0 = arith.addf %arg0, %arg1 : f32
    omp.yield(%0 : f32)
  } atomic {
  ^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr):
    %0 = llvm.load %arg1 : !llvm.ptr -> f32
    %1 = llvm.atomicrmw fadd %arg0, %0 monotonic : !llvm.ptr, f32
    omp.yield
  }
  func.func @SpTVMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<1 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(1 : i64) : i64
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1 = arith.constant 1 : index
    %c512_i64 = arith.constant 512 : i64
    %c32_i64 = arith.constant 32 : i64
    %c16_i64 = arith.constant 16 : i64
    %c0_i64 = arith.constant 0 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %c32 = arith.constant 32 : index
    %alloc = memref.alloc() : memref<512xf32>
    %cast = memref.cast %alloc : memref<512xf32> to memref<?xf32>
    %1 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %2 = llvm.insertvalue %c0_i64, %1[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %3 = llvm.insertvalue %c16_i64, %2[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %4 = llvm.insertvalue %c32_i64, %3[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%5: index):  // 2 preds: ^bb0, ^bb2
    %6 = arith.cmpi slt, %5, %c512 : index
    cf.cond_br %6, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    memref.store %cst, %alloc[%5] : memref<512xf32>
    %7 = arith.addi %5, %c1 : index
    cf.br ^bb1(%7 : index)
  ^bb3:  // pred: ^bb1
    %8 = llvm.insertvalue %c512_i64, %4[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %9 = memref.load %arg0[%c0] : memref<?xindex>
    %10 = memref.load %arg0[%c1] : memref<?xindex>
    omp.parallel   {
      omp.wsloop   for  (%arg10) : index = (%9) to (%10) step (%c1) {
        %11 = memref.load %arg1[%arg10] : memref<?xindex>
        %12 = memref.load %arg2[%arg10] : memref<?xindex>
        %13 = arith.addi %arg10, %c1 : index
        %14 = memref.load %arg2[%13] : memref<?xindex>
        omp.parallel   {
          %15 = llvm.alloca %0 x f32 : (i64) -> !llvm.ptr
          omp.wsloop   for  (%arg11) : index = (%12) to (%14) step (%c1) {
            %16 = memref.load %arg3[%arg11] : memref<?xindex>
            %17 = arith.muli %11, %c32 : index
            %18 = arith.addi %17, %16 : index
            %19 = memref.load %alloc[%18] : memref<512xf32>
            %20 = memref.load %arg4[%arg11] : memref<?xindex>
            %21 = arith.addi %arg11, %c1 : index
            %22 = memref.load %arg4[%21] : memref<?xindex>
            llvm.store %19, %15 : f32, !llvm.ptr
            omp.parallel   {
              omp.wsloop   reduction(@__scf_reduction -> %15 : !llvm.ptr) for  (%arg12) : index = (%20) to (%22) step (%c1) {
                memref.alloca_scope  {
                  %24 = memref.load %arg5[%arg12] : memref<?xindex>
                  %25 = memref.load %arg6[%arg12] : memref<?xf32>
                  %26 = memref.load %arg8[%24] : memref<?xf32>
                  %27 = arith.mulf %25, %26 : f32
                  omp.reduction %27, %15 : f32, !llvm.ptr
                }
                omp.yield
              }
              omp.terminator
            }
            %23 = llvm.load %15 : !llvm.ptr -> f32
            memref.store %23, %alloc[%18] : memref<512xf32>
            omp.yield
          }
          omp.terminator
        }
        omp.yield
      }
      omp.terminator
    }
    return %cast, %8 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
module {
  omp.reduction.declare @__scf_reduction : f32 init {
  ^bb0(%arg0: f32):
    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    omp.yield(%0 : f32)
  } combiner {
  ^bb0(%arg0: f32, %arg1: f32):
    %0 = arith.addf %arg0, %arg1 : f32
    omp.yield(%0 : f32)
  } atomic {
  ^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr):
    %0 = llvm.load %arg1 : !llvm.ptr -> f32
    %1 = llvm.atomicrmw fadd %arg0, %0 monotonic : !llvm.ptr, f32
    omp.yield
  }
  func.func @SpTVMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<1 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(1 : i64) : i64
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1 = arith.constant 1 : index
    %c512_i64 = arith.constant 512 : i64
    %c32_i64 = arith.constant 32 : i64
    %c16_i64 = arith.constant 16 : i64
    %c0_i64 = arith.constant 0 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %c32 = arith.constant 32 : index
    %alloc = memref.alloc() : memref<512xf32>
    %cast = memref.cast %alloc : memref<512xf32> to memref<?xf32>
    %1 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %2 = llvm.insertvalue %c0_i64, %1[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %3 = llvm.insertvalue %c16_i64, %2[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %4 = llvm.insertvalue %c32_i64, %3[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%5: index):  // 2 preds: ^bb0, ^bb2
    %6 = arith.cmpi slt, %5, %c512 : index
    cf.cond_br %6, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    memref.store %cst, %alloc[%5] : memref<512xf32>
    %7 = arith.addi %5, %c1 : index
    cf.br ^bb1(%7 : index)
  ^bb3:  // pred: ^bb1
    %8 = llvm.insertvalue %c512_i64, %4[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %9 = memref.load %arg0[%c0] : memref<?xindex>
    %10 = memref.load %arg0[%c1] : memref<?xindex>
    omp.parallel   {
      omp.wsloop   for  (%arg10) : index = (%9) to (%10) step (%c1) {
        %11 = memref.load %arg1[%arg10] : memref<?xindex>
        %12 = memref.load %arg2[%arg10] : memref<?xindex>
        %13 = arith.addi %arg10, %c1 : index
        %14 = memref.load %arg2[%13] : memref<?xindex>
        omp.parallel   {
          %15 = llvm.alloca %0 x f32 : (i64) -> !llvm.ptr
          omp.wsloop   for  (%arg11) : index = (%12) to (%14) step (%c1) {
            %16 = memref.load %arg3[%arg11] : memref<?xindex>
            %17 = arith.muli %11, %c32 : index
            %18 = arith.addi %17, %16 : index
            %19 = memref.load %alloc[%18] : memref<512xf32>
            %20 = memref.load %arg4[%arg11] : memref<?xindex>
            %21 = arith.addi %arg11, %c1 : index
            %22 = memref.load %arg4[%21] : memref<?xindex>
            llvm.store %19, %15 : f32, !llvm.ptr
            omp.parallel   {
              omp.wsloop   reduction(@__scf_reduction -> %15 : !llvm.ptr) for  (%arg12) : index = (%20) to (%22) step (%c1) {
                memref.alloca_scope  {
                  %24 = memref.load %arg5[%arg12] : memref<?xindex>
                  %25 = memref.load %arg6[%arg12] : memref<?xf32>
                  %26 = memref.load %arg8[%24] : memref<?xf32>
                  %27 = arith.mulf %25, %26 : f32
                  omp.reduction %27, %15 : f32, !llvm.ptr
                }
                omp.yield
              }
              omp.terminator
            }
            %23 = llvm.load %15 : !llvm.ptr -> f32
            memref.store %23, %alloc[%18] : memref<512xf32>
            omp.yield
          }
          omp.terminator
        }
        omp.yield
      }
      omp.terminator
    }
    return %cast, %8 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After ConvertVectorToLLVMPass (convert-vector-to-llvm) //----- //
module {
  omp.reduction.declare @__scf_reduction : f32 init {
  ^bb0(%arg0: f32):
    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    omp.yield(%0 : f32)
  } combiner {
  ^bb0(%arg0: f32, %arg1: f32):
    %0 = arith.addf %arg0, %arg1 : f32
    omp.yield(%0 : f32)
  } atomic {
  ^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr):
    %0 = llvm.load %arg1 : !llvm.ptr -> f32
    %1 = llvm.atomicrmw fadd %arg0, %0 monotonic : !llvm.ptr, f32
    omp.yield
  }
  func.func @SpTVMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<1 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(1 : i64) : i64
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1 = arith.constant 1 : index
    %c512_i64 = arith.constant 512 : i64
    %c32_i64 = arith.constant 32 : i64
    %c16_i64 = arith.constant 16 : i64
    %c0_i64 = arith.constant 0 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %c32 = arith.constant 32 : index
    %alloc = memref.alloc() : memref<512xf32>
    %cast = memref.cast %alloc : memref<512xf32> to memref<?xf32>
    %1 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %2 = llvm.insertvalue %c0_i64, %1[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %3 = llvm.insertvalue %c16_i64, %2[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %4 = llvm.insertvalue %c32_i64, %3[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%5: index):  // 2 preds: ^bb0, ^bb2
    %6 = arith.cmpi slt, %5, %c512 : index
    cf.cond_br %6, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    memref.store %cst, %alloc[%5] : memref<512xf32>
    %7 = arith.addi %5, %c1 : index
    cf.br ^bb1(%7 : index)
  ^bb3:  // pred: ^bb1
    %8 = llvm.insertvalue %c512_i64, %4[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %9 = memref.load %arg0[%c0] : memref<?xindex>
    %10 = memref.load %arg0[%c1] : memref<?xindex>
    omp.parallel   {
      omp.wsloop   for  (%arg10) : index = (%9) to (%10) step (%c1) {
        %11 = memref.load %arg1[%arg10] : memref<?xindex>
        %12 = memref.load %arg2[%arg10] : memref<?xindex>
        %13 = arith.addi %arg10, %c1 : index
        %14 = memref.load %arg2[%13] : memref<?xindex>
        omp.parallel   {
          %15 = llvm.alloca %0 x f32 : (i64) -> !llvm.ptr
          omp.wsloop   for  (%arg11) : index = (%12) to (%14) step (%c1) {
            %16 = memref.load %arg3[%arg11] : memref<?xindex>
            %17 = arith.muli %11, %c32 : index
            %18 = arith.addi %17, %16 : index
            %19 = memref.load %alloc[%18] : memref<512xf32>
            %20 = memref.load %arg4[%arg11] : memref<?xindex>
            %21 = arith.addi %arg11, %c1 : index
            %22 = memref.load %arg4[%21] : memref<?xindex>
            llvm.store %19, %15 : f32, !llvm.ptr
            omp.parallel   {
              omp.wsloop   reduction(@__scf_reduction -> %15 : !llvm.ptr) for  (%arg12) : index = (%20) to (%22) step (%c1) {
                memref.alloca_scope  {
                  %24 = memref.load %arg5[%arg12] : memref<?xindex>
                  %25 = memref.load %arg6[%arg12] : memref<?xf32>
                  %26 = memref.load %arg8[%24] : memref<?xf32>
                  %27 = arith.mulf %25, %26 : f32
                  omp.reduction %27, %15 : f32, !llvm.ptr
                }
                omp.yield
              }
              omp.terminator
            }
            %23 = llvm.load %15 : !llvm.ptr -> f32
            memref.store %23, %alloc[%18] : memref<512xf32>
            omp.yield
          }
          omp.terminator
        }
        omp.yield
      }
      omp.terminator
    }
    return %cast, %8 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After FinalizeMemRefToLLVMConversionPass (finalize-memref-to-llvm) //----- //
module {
  llvm.func @malloc(i64) -> !llvm.ptr
  omp.reduction.declare @__scf_reduction : f32 init {
  ^bb0(%arg0: f32):
    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    omp.yield(%0 : f32)
  } combiner {
  ^bb0(%arg0: f32, %arg1: f32):
    %0 = arith.addf %arg0, %arg1 : f32
    omp.yield(%0 : f32)
  } atomic {
  ^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr):
    %0 = llvm.load %arg1 : !llvm.ptr -> f32
    %1 = llvm.atomicrmw fadd %arg0, %0 monotonic : !llvm.ptr, f32
    omp.yield
  }
  func.func @SpTVMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<1 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %2 = builtin.unrealized_conversion_cast %arg2 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %3 = builtin.unrealized_conversion_cast %arg3 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %4 = builtin.unrealized_conversion_cast %arg4 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = builtin.unrealized_conversion_cast %arg5 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %6 = builtin.unrealized_conversion_cast %arg6 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = builtin.unrealized_conversion_cast %arg8 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %8 = llvm.mlir.constant(1 : i64) : i64
    %c0 = arith.constant 0 : index
    %9 = builtin.unrealized_conversion_cast %c0 : index to i64
    %c512 = arith.constant 512 : index
    %c1 = arith.constant 1 : index
    %10 = builtin.unrealized_conversion_cast %c1 : index to i64
    %c512_i64 = arith.constant 512 : i64
    %c32_i64 = arith.constant 32 : i64
    %c16_i64 = arith.constant 16 : i64
    %c0_i64 = arith.constant 0 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %c32 = arith.constant 32 : index
    %11 = llvm.mlir.constant(512 : index) : i64
    %12 = llvm.mlir.constant(1 : index) : i64
    %13 = llvm.mlir.null : !llvm.ptr
    %14 = llvm.getelementptr %13[%11] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %15 = llvm.ptrtoint %14 : !llvm.ptr to i64
    %16 = llvm.call @malloc(%15) : (i64) -> !llvm.ptr
    %17 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %18 = llvm.insertvalue %16, %17[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %19 = llvm.insertvalue %16, %18[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.mlir.constant(0 : index) : i64
    %21 = llvm.insertvalue %20, %19[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %11, %21[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %12, %22[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = builtin.unrealized_conversion_cast %23 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %25 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %26 = llvm.insertvalue %c0_i64, %25[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %27 = llvm.insertvalue %c16_i64, %26[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %28 = llvm.insertvalue %c32_i64, %27[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%29: index):  // 2 preds: ^bb0, ^bb2
    %30 = builtin.unrealized_conversion_cast %29 : index to i64
    %31 = arith.cmpi slt, %29, %c512 : index
    cf.cond_br %31, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %32 = llvm.extractvalue %23[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.getelementptr %32[%30] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %cst, %33 : f32, !llvm.ptr
    %34 = arith.addi %29, %c1 : index
    cf.br ^bb1(%34 : index)
  ^bb3:  // pred: ^bb1
    %35 = llvm.insertvalue %c512_i64, %28[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %36 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %37 = llvm.getelementptr %36[%9] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %38 = llvm.load %37 : !llvm.ptr -> i64
    %39 = builtin.unrealized_conversion_cast %38 : i64 to index
    %40 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %41 = llvm.getelementptr %40[%10] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %42 = llvm.load %41 : !llvm.ptr -> i64
    %43 = builtin.unrealized_conversion_cast %42 : i64 to index
    omp.parallel   {
      omp.wsloop   for  (%arg10) : index = (%39) to (%43) step (%c1) {
        %44 = builtin.unrealized_conversion_cast %arg10 : index to i64
        %45 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %46 = llvm.getelementptr %45[%44] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %47 = llvm.load %46 : !llvm.ptr -> i64
        %48 = builtin.unrealized_conversion_cast %47 : i64 to index
        %49 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %50 = llvm.getelementptr %49[%44] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %51 = llvm.load %50 : !llvm.ptr -> i64
        %52 = builtin.unrealized_conversion_cast %51 : i64 to index
        %53 = arith.addi %arg10, %c1 : index
        %54 = builtin.unrealized_conversion_cast %53 : index to i64
        %55 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %56 = llvm.getelementptr %55[%54] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %57 = llvm.load %56 : !llvm.ptr -> i64
        %58 = builtin.unrealized_conversion_cast %57 : i64 to index
        omp.parallel   {
          %59 = llvm.alloca %8 x f32 : (i64) -> !llvm.ptr
          omp.wsloop   for  (%arg11) : index = (%52) to (%58) step (%c1) {
            %60 = builtin.unrealized_conversion_cast %arg11 : index to i64
            %61 = llvm.extractvalue %3[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %62 = llvm.getelementptr %61[%60] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %63 = llvm.load %62 : !llvm.ptr -> i64
            %64 = builtin.unrealized_conversion_cast %63 : i64 to index
            %65 = arith.muli %48, %c32 : index
            %66 = arith.addi %65, %64 : index
            %67 = builtin.unrealized_conversion_cast %66 : index to i64
            %68 = llvm.extractvalue %23[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %69 = llvm.getelementptr %68[%67] : (!llvm.ptr, i64) -> !llvm.ptr, f32
            %70 = llvm.load %69 : !llvm.ptr -> f32
            %71 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %72 = llvm.getelementptr %71[%60] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %73 = llvm.load %72 : !llvm.ptr -> i64
            %74 = builtin.unrealized_conversion_cast %73 : i64 to index
            %75 = arith.addi %arg11, %c1 : index
            %76 = builtin.unrealized_conversion_cast %75 : index to i64
            %77 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %78 = llvm.getelementptr %77[%76] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %79 = llvm.load %78 : !llvm.ptr -> i64
            %80 = builtin.unrealized_conversion_cast %79 : i64 to index
            llvm.store %70, %59 : f32, !llvm.ptr
            omp.parallel   {
              omp.wsloop   reduction(@__scf_reduction -> %59 : !llvm.ptr) for  (%arg12) : index = (%74) to (%80) step (%c1) {
                %84 = builtin.unrealized_conversion_cast %arg12 : index to i64
                %85 = llvm.intr.stacksave : !llvm.ptr
                llvm.br ^bb1
              ^bb1:  // pred: ^bb0
                %86 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %87 = llvm.getelementptr %86[%84] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                %88 = llvm.load %87 : !llvm.ptr -> i64
                %89 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %90 = llvm.getelementptr %89[%84] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                %91 = llvm.load %90 : !llvm.ptr -> f32
                %92 = llvm.extractvalue %7[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %93 = llvm.getelementptr %92[%88] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                %94 = llvm.load %93 : !llvm.ptr -> f32
                %95 = arith.mulf %91, %94 : f32
                omp.reduction %95, %59 : f32, !llvm.ptr
                llvm.intr.stackrestore %85 : !llvm.ptr
                llvm.br ^bb2
              ^bb2:  // pred: ^bb1
                omp.yield
              }
              omp.terminator
            }
            %81 = llvm.load %59 : !llvm.ptr -> f32
            %82 = llvm.extractvalue %23[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %83 = llvm.getelementptr %82[%67] : (!llvm.ptr, i64) -> !llvm.ptr, f32
            llvm.store %81, %83 : f32, !llvm.ptr
            omp.yield
          }
          omp.terminator
        }
        omp.yield
      }
      omp.terminator
    }
    return %24, %35 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After ConvertComplexToStandard (convert-complex-to-standard) //----- //
func.func @SpTVMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<1 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
  %0 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %1 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %2 = builtin.unrealized_conversion_cast %arg2 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %3 = builtin.unrealized_conversion_cast %arg3 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %4 = builtin.unrealized_conversion_cast %arg4 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %5 = builtin.unrealized_conversion_cast %arg5 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %6 = builtin.unrealized_conversion_cast %arg6 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %7 = builtin.unrealized_conversion_cast %arg8 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %8 = llvm.mlir.constant(1 : i64) : i64
  %c0 = arith.constant 0 : index
  %9 = builtin.unrealized_conversion_cast %c0 : index to i64
  %c512 = arith.constant 512 : index
  %c1 = arith.constant 1 : index
  %10 = builtin.unrealized_conversion_cast %c1 : index to i64
  %c512_i64 = arith.constant 512 : i64
  %c32_i64 = arith.constant 32 : i64
  %c16_i64 = arith.constant 16 : i64
  %c0_i64 = arith.constant 0 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %c32 = arith.constant 32 : index
  %11 = llvm.mlir.constant(512 : index) : i64
  %12 = llvm.mlir.constant(1 : index) : i64
  %13 = llvm.mlir.null : !llvm.ptr
  %14 = llvm.getelementptr %13[512] : (!llvm.ptr) -> !llvm.ptr, f32
  %15 = llvm.ptrtoint %14 : !llvm.ptr to i64
  %16 = llvm.call @malloc(%15) : (i64) -> !llvm.ptr
  %17 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %18 = llvm.insertvalue %16, %17[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %19 = llvm.insertvalue %16, %18[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %20 = llvm.mlir.constant(0 : index) : i64
  %21 = llvm.insertvalue %20, %19[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %22 = llvm.insertvalue %11, %21[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %23 = llvm.insertvalue %12, %22[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %24 = builtin.unrealized_conversion_cast %23 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
  %25 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  %26 = llvm.insertvalue %c0_i64, %25[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %27 = llvm.insertvalue %c16_i64, %26[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %28 = llvm.insertvalue %c32_i64, %27[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  cf.br ^bb1(%c0 : index)
^bb1(%29: index):  // 2 preds: ^bb0, ^bb2
  %30 = builtin.unrealized_conversion_cast %29 : index to i64
  %31 = arith.cmpi slt, %29, %c512 : index
  cf.cond_br %31, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %32 = llvm.getelementptr %16[%30] : (!llvm.ptr, i64) -> !llvm.ptr, f32
  llvm.store %cst, %32 : f32, !llvm.ptr
  %33 = arith.addi %29, %c1 : index
  cf.br ^bb1(%33 : index)
^bb3:  // pred: ^bb1
  %34 = llvm.insertvalue %c512_i64, %28[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %35 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %36 = llvm.getelementptr %35[%9] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %37 = llvm.load %36 : !llvm.ptr -> i64
  %38 = builtin.unrealized_conversion_cast %37 : i64 to index
  %39 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %40 = llvm.getelementptr %39[%10] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %41 = llvm.load %40 : !llvm.ptr -> i64
  %42 = builtin.unrealized_conversion_cast %41 : i64 to index
  omp.parallel   {
    omp.wsloop   for  (%arg10) : index = (%38) to (%42) step (%c1) {
      %43 = builtin.unrealized_conversion_cast %arg10 : index to i64
      %44 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
      %45 = llvm.getelementptr %44[%43] : (!llvm.ptr, i64) -> !llvm.ptr, i64
      %46 = llvm.load %45 : !llvm.ptr -> i64
      %47 = builtin.unrealized_conversion_cast %46 : i64 to index
      %48 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
      %49 = llvm.getelementptr %48[%43] : (!llvm.ptr, i64) -> !llvm.ptr, i64
      %50 = llvm.load %49 : !llvm.ptr -> i64
      %51 = builtin.unrealized_conversion_cast %50 : i64 to index
      %52 = arith.addi %arg10, %c1 : index
      %53 = builtin.unrealized_conversion_cast %52 : index to i64
      %54 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
      %55 = llvm.getelementptr %54[%53] : (!llvm.ptr, i64) -> !llvm.ptr, i64
      %56 = llvm.load %55 : !llvm.ptr -> i64
      %57 = builtin.unrealized_conversion_cast %56 : i64 to index
      omp.parallel   {
        %58 = llvm.alloca %8 x f32 : (i64) -> !llvm.ptr
        omp.wsloop   for  (%arg11) : index = (%51) to (%57) step (%c1) {
          %59 = builtin.unrealized_conversion_cast %arg11 : index to i64
          %60 = llvm.extractvalue %3[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
          %61 = llvm.getelementptr %60[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
          %62 = llvm.load %61 : !llvm.ptr -> i64
          %63 = builtin.unrealized_conversion_cast %62 : i64 to index
          %64 = arith.muli %47, %c32 : index
          %65 = arith.addi %64, %63 : index
          %66 = builtin.unrealized_conversion_cast %65 : index to i64
          %67 = llvm.getelementptr %16[%66] : (!llvm.ptr, i64) -> !llvm.ptr, f32
          %68 = llvm.load %67 : !llvm.ptr -> f32
          %69 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
          %70 = llvm.getelementptr %69[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
          %71 = llvm.load %70 : !llvm.ptr -> i64
          %72 = builtin.unrealized_conversion_cast %71 : i64 to index
          %73 = arith.addi %arg11, %c1 : index
          %74 = builtin.unrealized_conversion_cast %73 : index to i64
          %75 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
          %76 = llvm.getelementptr %75[%74] : (!llvm.ptr, i64) -> !llvm.ptr, i64
          %77 = llvm.load %76 : !llvm.ptr -> i64
          %78 = builtin.unrealized_conversion_cast %77 : i64 to index
          llvm.store %68, %58 : f32, !llvm.ptr
          omp.parallel   {
            omp.wsloop   reduction(@__scf_reduction -> %58 : !llvm.ptr) for  (%arg12) : index = (%72) to (%78) step (%c1) {
              %81 = builtin.unrealized_conversion_cast %arg12 : index to i64
              %82 = llvm.intr.stacksave : !llvm.ptr
              llvm.br ^bb1
            ^bb1:  // pred: ^bb0
              %83 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
              %84 = llvm.getelementptr %83[%81] : (!llvm.ptr, i64) -> !llvm.ptr, i64
              %85 = llvm.load %84 : !llvm.ptr -> i64
              %86 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
              %87 = llvm.getelementptr %86[%81] : (!llvm.ptr, i64) -> !llvm.ptr, f32
              %88 = llvm.load %87 : !llvm.ptr -> f32
              %89 = llvm.extractvalue %7[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
              %90 = llvm.getelementptr %89[%85] : (!llvm.ptr, i64) -> !llvm.ptr, f32
              %91 = llvm.load %90 : !llvm.ptr -> f32
              %92 = arith.mulf %88, %91 : f32
              omp.reduction %92, %58 : f32, !llvm.ptr
              llvm.intr.stackrestore %82 : !llvm.ptr
              llvm.br ^bb2
            ^bb2:  // pred: ^bb1
              omp.yield
            }
            omp.terminator
          }
          %79 = llvm.load %58 : !llvm.ptr -> f32
          %80 = llvm.getelementptr %16[%66] : (!llvm.ptr, i64) -> !llvm.ptr, f32
          llvm.store %79, %80 : f32, !llvm.ptr
          omp.yield
        }
        omp.terminator
      }
      omp.yield
    }
    omp.terminator
  }
  return %24, %34 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
}

// -----// IR Dump After ArithExpandOps (arith-expand) //----- //
func.func @SpTVMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<1 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
  %0 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %1 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %2 = builtin.unrealized_conversion_cast %arg2 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %3 = builtin.unrealized_conversion_cast %arg3 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %4 = builtin.unrealized_conversion_cast %arg4 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %5 = builtin.unrealized_conversion_cast %arg5 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %6 = builtin.unrealized_conversion_cast %arg6 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %7 = builtin.unrealized_conversion_cast %arg8 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %8 = llvm.mlir.constant(1 : i64) : i64
  %c0 = arith.constant 0 : index
  %9 = builtin.unrealized_conversion_cast %c0 : index to i64
  %c512 = arith.constant 512 : index
  %c1 = arith.constant 1 : index
  %10 = builtin.unrealized_conversion_cast %c1 : index to i64
  %c512_i64 = arith.constant 512 : i64
  %c32_i64 = arith.constant 32 : i64
  %c16_i64 = arith.constant 16 : i64
  %c0_i64 = arith.constant 0 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %c32 = arith.constant 32 : index
  %11 = llvm.mlir.constant(512 : index) : i64
  %12 = llvm.mlir.constant(1 : index) : i64
  %13 = llvm.mlir.null : !llvm.ptr
  %14 = llvm.getelementptr %13[512] : (!llvm.ptr) -> !llvm.ptr, f32
  %15 = llvm.ptrtoint %14 : !llvm.ptr to i64
  %16 = llvm.call @malloc(%15) : (i64) -> !llvm.ptr
  %17 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %18 = llvm.insertvalue %16, %17[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %19 = llvm.insertvalue %16, %18[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %20 = llvm.mlir.constant(0 : index) : i64
  %21 = llvm.insertvalue %20, %19[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %22 = llvm.insertvalue %11, %21[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %23 = llvm.insertvalue %12, %22[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %24 = builtin.unrealized_conversion_cast %23 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
  %25 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  %26 = llvm.insertvalue %c0_i64, %25[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %27 = llvm.insertvalue %c16_i64, %26[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %28 = llvm.insertvalue %c32_i64, %27[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  cf.br ^bb1(%c0 : index)
^bb1(%29: index):  // 2 preds: ^bb0, ^bb2
  %30 = builtin.unrealized_conversion_cast %29 : index to i64
  %31 = arith.cmpi slt, %29, %c512 : index
  cf.cond_br %31, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %32 = llvm.getelementptr %16[%30] : (!llvm.ptr, i64) -> !llvm.ptr, f32
  llvm.store %cst, %32 : f32, !llvm.ptr
  %33 = arith.addi %29, %c1 : index
  cf.br ^bb1(%33 : index)
^bb3:  // pred: ^bb1
  %34 = llvm.insertvalue %c512_i64, %28[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %35 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %36 = llvm.getelementptr %35[%9] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %37 = llvm.load %36 : !llvm.ptr -> i64
  %38 = builtin.unrealized_conversion_cast %37 : i64 to index
  %39 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %40 = llvm.getelementptr %39[%10] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %41 = llvm.load %40 : !llvm.ptr -> i64
  %42 = builtin.unrealized_conversion_cast %41 : i64 to index
  omp.parallel   {
    omp.wsloop   for  (%arg10) : index = (%38) to (%42) step (%c1) {
      %43 = builtin.unrealized_conversion_cast %arg10 : index to i64
      %44 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
      %45 = llvm.getelementptr %44[%43] : (!llvm.ptr, i64) -> !llvm.ptr, i64
      %46 = llvm.load %45 : !llvm.ptr -> i64
      %47 = builtin.unrealized_conversion_cast %46 : i64 to index
      %48 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
      %49 = llvm.getelementptr %48[%43] : (!llvm.ptr, i64) -> !llvm.ptr, i64
      %50 = llvm.load %49 : !llvm.ptr -> i64
      %51 = builtin.unrealized_conversion_cast %50 : i64 to index
      %52 = arith.addi %arg10, %c1 : index
      %53 = builtin.unrealized_conversion_cast %52 : index to i64
      %54 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
      %55 = llvm.getelementptr %54[%53] : (!llvm.ptr, i64) -> !llvm.ptr, i64
      %56 = llvm.load %55 : !llvm.ptr -> i64
      %57 = builtin.unrealized_conversion_cast %56 : i64 to index
      omp.parallel   {
        %58 = llvm.alloca %8 x f32 : (i64) -> !llvm.ptr
        omp.wsloop   for  (%arg11) : index = (%51) to (%57) step (%c1) {
          %59 = builtin.unrealized_conversion_cast %arg11 : index to i64
          %60 = llvm.extractvalue %3[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
          %61 = llvm.getelementptr %60[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
          %62 = llvm.load %61 : !llvm.ptr -> i64
          %63 = builtin.unrealized_conversion_cast %62 : i64 to index
          %64 = arith.muli %47, %c32 : index
          %65 = arith.addi %64, %63 : index
          %66 = builtin.unrealized_conversion_cast %65 : index to i64
          %67 = llvm.getelementptr %16[%66] : (!llvm.ptr, i64) -> !llvm.ptr, f32
          %68 = llvm.load %67 : !llvm.ptr -> f32
          %69 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
          %70 = llvm.getelementptr %69[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
          %71 = llvm.load %70 : !llvm.ptr -> i64
          %72 = builtin.unrealized_conversion_cast %71 : i64 to index
          %73 = arith.addi %arg11, %c1 : index
          %74 = builtin.unrealized_conversion_cast %73 : index to i64
          %75 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
          %76 = llvm.getelementptr %75[%74] : (!llvm.ptr, i64) -> !llvm.ptr, i64
          %77 = llvm.load %76 : !llvm.ptr -> i64
          %78 = builtin.unrealized_conversion_cast %77 : i64 to index
          llvm.store %68, %58 : f32, !llvm.ptr
          omp.parallel   {
            omp.wsloop   reduction(@__scf_reduction -> %58 : !llvm.ptr) for  (%arg12) : index = (%72) to (%78) step (%c1) {
              %81 = builtin.unrealized_conversion_cast %arg12 : index to i64
              %82 = llvm.intr.stacksave : !llvm.ptr
              llvm.br ^bb1
            ^bb1:  // pred: ^bb0
              %83 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
              %84 = llvm.getelementptr %83[%81] : (!llvm.ptr, i64) -> !llvm.ptr, i64
              %85 = llvm.load %84 : !llvm.ptr -> i64
              %86 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
              %87 = llvm.getelementptr %86[%81] : (!llvm.ptr, i64) -> !llvm.ptr, f32
              %88 = llvm.load %87 : !llvm.ptr -> f32
              %89 = llvm.extractvalue %7[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
              %90 = llvm.getelementptr %89[%85] : (!llvm.ptr, i64) -> !llvm.ptr, f32
              %91 = llvm.load %90 : !llvm.ptr -> f32
              %92 = arith.mulf %88, %91 : f32
              omp.reduction %92, %58 : f32, !llvm.ptr
              llvm.intr.stackrestore %82 : !llvm.ptr
              llvm.br ^bb2
            ^bb2:  // pred: ^bb1
              omp.yield
            }
            omp.terminator
          }
          %79 = llvm.load %58 : !llvm.ptr -> f32
          %80 = llvm.getelementptr %16[%66] : (!llvm.ptr, i64) -> !llvm.ptr, f32
          llvm.store %79, %80 : f32, !llvm.ptr
          omp.yield
        }
        omp.terminator
      }
      omp.yield
    }
    omp.terminator
  }
  return %24, %34 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
}

// -----// IR Dump After ConvertMathToLLVMPass (convert-math-to-llvm) //----- //
func.func @SpTVMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<1 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
  %0 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %1 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %2 = builtin.unrealized_conversion_cast %arg2 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %3 = builtin.unrealized_conversion_cast %arg3 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %4 = builtin.unrealized_conversion_cast %arg4 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %5 = builtin.unrealized_conversion_cast %arg5 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %6 = builtin.unrealized_conversion_cast %arg6 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %7 = builtin.unrealized_conversion_cast %arg8 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %8 = llvm.mlir.constant(1 : i64) : i64
  %c0 = arith.constant 0 : index
  %9 = builtin.unrealized_conversion_cast %c0 : index to i64
  %c512 = arith.constant 512 : index
  %c1 = arith.constant 1 : index
  %10 = builtin.unrealized_conversion_cast %c1 : index to i64
  %c512_i64 = arith.constant 512 : i64
  %c32_i64 = arith.constant 32 : i64
  %c16_i64 = arith.constant 16 : i64
  %c0_i64 = arith.constant 0 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %c32 = arith.constant 32 : index
  %11 = llvm.mlir.constant(512 : index) : i64
  %12 = llvm.mlir.constant(1 : index) : i64
  %13 = llvm.mlir.null : !llvm.ptr
  %14 = llvm.getelementptr %13[512] : (!llvm.ptr) -> !llvm.ptr, f32
  %15 = llvm.ptrtoint %14 : !llvm.ptr to i64
  %16 = llvm.call @malloc(%15) : (i64) -> !llvm.ptr
  %17 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %18 = llvm.insertvalue %16, %17[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %19 = llvm.insertvalue %16, %18[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %20 = llvm.mlir.constant(0 : index) : i64
  %21 = llvm.insertvalue %20, %19[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %22 = llvm.insertvalue %11, %21[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %23 = llvm.insertvalue %12, %22[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %24 = builtin.unrealized_conversion_cast %23 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
  %25 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  %26 = llvm.insertvalue %c0_i64, %25[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %27 = llvm.insertvalue %c16_i64, %26[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %28 = llvm.insertvalue %c32_i64, %27[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  cf.br ^bb1(%c0 : index)
^bb1(%29: index):  // 2 preds: ^bb0, ^bb2
  %30 = builtin.unrealized_conversion_cast %29 : index to i64
  %31 = arith.cmpi slt, %29, %c512 : index
  cf.cond_br %31, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %32 = llvm.getelementptr %16[%30] : (!llvm.ptr, i64) -> !llvm.ptr, f32
  llvm.store %cst, %32 : f32, !llvm.ptr
  %33 = arith.addi %29, %c1 : index
  cf.br ^bb1(%33 : index)
^bb3:  // pred: ^bb1
  %34 = llvm.insertvalue %c512_i64, %28[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
  %35 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %36 = llvm.getelementptr %35[%9] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %37 = llvm.load %36 : !llvm.ptr -> i64
  %38 = builtin.unrealized_conversion_cast %37 : i64 to index
  %39 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %40 = llvm.getelementptr %39[%10] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %41 = llvm.load %40 : !llvm.ptr -> i64
  %42 = builtin.unrealized_conversion_cast %41 : i64 to index
  omp.parallel   {
    omp.wsloop   for  (%arg10) : index = (%38) to (%42) step (%c1) {
      %43 = builtin.unrealized_conversion_cast %arg10 : index to i64
      %44 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
      %45 = llvm.getelementptr %44[%43] : (!llvm.ptr, i64) -> !llvm.ptr, i64
      %46 = llvm.load %45 : !llvm.ptr -> i64
      %47 = builtin.unrealized_conversion_cast %46 : i64 to index
      %48 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
      %49 = llvm.getelementptr %48[%43] : (!llvm.ptr, i64) -> !llvm.ptr, i64
      %50 = llvm.load %49 : !llvm.ptr -> i64
      %51 = builtin.unrealized_conversion_cast %50 : i64 to index
      %52 = arith.addi %arg10, %c1 : index
      %53 = builtin.unrealized_conversion_cast %52 : index to i64
      %54 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
      %55 = llvm.getelementptr %54[%53] : (!llvm.ptr, i64) -> !llvm.ptr, i64
      %56 = llvm.load %55 : !llvm.ptr -> i64
      %57 = builtin.unrealized_conversion_cast %56 : i64 to index
      omp.parallel   {
        %58 = llvm.alloca %8 x f32 : (i64) -> !llvm.ptr
        omp.wsloop   for  (%arg11) : index = (%51) to (%57) step (%c1) {
          %59 = builtin.unrealized_conversion_cast %arg11 : index to i64
          %60 = llvm.extractvalue %3[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
          %61 = llvm.getelementptr %60[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
          %62 = llvm.load %61 : !llvm.ptr -> i64
          %63 = builtin.unrealized_conversion_cast %62 : i64 to index
          %64 = arith.muli %47, %c32 : index
          %65 = arith.addi %64, %63 : index
          %66 = builtin.unrealized_conversion_cast %65 : index to i64
          %67 = llvm.getelementptr %16[%66] : (!llvm.ptr, i64) -> !llvm.ptr, f32
          %68 = llvm.load %67 : !llvm.ptr -> f32
          %69 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
          %70 = llvm.getelementptr %69[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
          %71 = llvm.load %70 : !llvm.ptr -> i64
          %72 = builtin.unrealized_conversion_cast %71 : i64 to index
          %73 = arith.addi %arg11, %c1 : index
          %74 = builtin.unrealized_conversion_cast %73 : index to i64
          %75 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
          %76 = llvm.getelementptr %75[%74] : (!llvm.ptr, i64) -> !llvm.ptr, i64
          %77 = llvm.load %76 : !llvm.ptr -> i64
          %78 = builtin.unrealized_conversion_cast %77 : i64 to index
          llvm.store %68, %58 : f32, !llvm.ptr
          omp.parallel   {
            omp.wsloop   reduction(@__scf_reduction -> %58 : !llvm.ptr) for  (%arg12) : index = (%72) to (%78) step (%c1) {
              %81 = builtin.unrealized_conversion_cast %arg12 : index to i64
              %82 = llvm.intr.stacksave : !llvm.ptr
              llvm.br ^bb1
            ^bb1:  // pred: ^bb0
              %83 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
              %84 = llvm.getelementptr %83[%81] : (!llvm.ptr, i64) -> !llvm.ptr, i64
              %85 = llvm.load %84 : !llvm.ptr -> i64
              %86 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
              %87 = llvm.getelementptr %86[%81] : (!llvm.ptr, i64) -> !llvm.ptr, f32
              %88 = llvm.load %87 : !llvm.ptr -> f32
              %89 = llvm.extractvalue %7[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
              %90 = llvm.getelementptr %89[%85] : (!llvm.ptr, i64) -> !llvm.ptr, f32
              %91 = llvm.load %90 : !llvm.ptr -> f32
              %92 = arith.mulf %88, %91 : f32
              omp.reduction %92, %58 : f32, !llvm.ptr
              llvm.intr.stackrestore %82 : !llvm.ptr
              llvm.br ^bb2
            ^bb2:  // pred: ^bb1
              omp.yield
            }
            omp.terminator
          }
          %79 = llvm.load %58 : !llvm.ptr -> f32
          %80 = llvm.getelementptr %16[%66] : (!llvm.ptr, i64) -> !llvm.ptr, f32
          llvm.store %79, %80 : f32, !llvm.ptr
          omp.yield
        }
        omp.terminator
      }
      omp.yield
    }
    omp.terminator
  }
  return %24, %34 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
}

// -----// IR Dump After ConvertMathToLibm (convert-math-to-libm) //----- //
module {
  llvm.func @malloc(i64) -> !llvm.ptr
  omp.reduction.declare @__scf_reduction : f32 init {
  ^bb0(%arg0: f32):
    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    omp.yield(%0 : f32)
  } combiner {
  ^bb0(%arg0: f32, %arg1: f32):
    %0 = arith.addf %arg0, %arg1 : f32
    omp.yield(%0 : f32)
  } atomic {
  ^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr):
    %0 = llvm.load %arg1 : !llvm.ptr -> f32
    %1 = llvm.atomicrmw fadd %arg0, %0 monotonic : !llvm.ptr, f32
    omp.yield
  }
  func.func @SpTVMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<1 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %2 = builtin.unrealized_conversion_cast %arg2 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %3 = builtin.unrealized_conversion_cast %arg3 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %4 = builtin.unrealized_conversion_cast %arg4 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = builtin.unrealized_conversion_cast %arg5 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %6 = builtin.unrealized_conversion_cast %arg6 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = builtin.unrealized_conversion_cast %arg8 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %8 = llvm.mlir.constant(1 : i64) : i64
    %c0 = arith.constant 0 : index
    %9 = builtin.unrealized_conversion_cast %c0 : index to i64
    %c512 = arith.constant 512 : index
    %c1 = arith.constant 1 : index
    %10 = builtin.unrealized_conversion_cast %c1 : index to i64
    %c512_i64 = arith.constant 512 : i64
    %c32_i64 = arith.constant 32 : i64
    %c16_i64 = arith.constant 16 : i64
    %c0_i64 = arith.constant 0 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %c32 = arith.constant 32 : index
    %11 = llvm.mlir.constant(512 : index) : i64
    %12 = llvm.mlir.constant(1 : index) : i64
    %13 = llvm.mlir.null : !llvm.ptr
    %14 = llvm.getelementptr %13[512] : (!llvm.ptr) -> !llvm.ptr, f32
    %15 = llvm.ptrtoint %14 : !llvm.ptr to i64
    %16 = llvm.call @malloc(%15) : (i64) -> !llvm.ptr
    %17 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %18 = llvm.insertvalue %16, %17[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %19 = llvm.insertvalue %16, %18[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.mlir.constant(0 : index) : i64
    %21 = llvm.insertvalue %20, %19[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %11, %21[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %12, %22[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = builtin.unrealized_conversion_cast %23 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %25 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %26 = llvm.insertvalue %c0_i64, %25[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %27 = llvm.insertvalue %c16_i64, %26[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %28 = llvm.insertvalue %c32_i64, %27[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%29: index):  // 2 preds: ^bb0, ^bb2
    %30 = builtin.unrealized_conversion_cast %29 : index to i64
    %31 = arith.cmpi slt, %29, %c512 : index
    cf.cond_br %31, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %32 = llvm.getelementptr %16[%30] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %cst, %32 : f32, !llvm.ptr
    %33 = arith.addi %29, %c1 : index
    cf.br ^bb1(%33 : index)
  ^bb3:  // pred: ^bb1
    %34 = llvm.insertvalue %c512_i64, %28[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %35 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %36 = llvm.getelementptr %35[%9] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %37 = llvm.load %36 : !llvm.ptr -> i64
    %38 = builtin.unrealized_conversion_cast %37 : i64 to index
    %39 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %40 = llvm.getelementptr %39[%10] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %41 = llvm.load %40 : !llvm.ptr -> i64
    %42 = builtin.unrealized_conversion_cast %41 : i64 to index
    omp.parallel   {
      omp.wsloop   for  (%arg10) : index = (%38) to (%42) step (%c1) {
        %43 = builtin.unrealized_conversion_cast %arg10 : index to i64
        %44 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %45 = llvm.getelementptr %44[%43] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %46 = llvm.load %45 : !llvm.ptr -> i64
        %47 = builtin.unrealized_conversion_cast %46 : i64 to index
        %48 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %49 = llvm.getelementptr %48[%43] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %50 = llvm.load %49 : !llvm.ptr -> i64
        %51 = builtin.unrealized_conversion_cast %50 : i64 to index
        %52 = arith.addi %arg10, %c1 : index
        %53 = builtin.unrealized_conversion_cast %52 : index to i64
        %54 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %55 = llvm.getelementptr %54[%53] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %56 = llvm.load %55 : !llvm.ptr -> i64
        %57 = builtin.unrealized_conversion_cast %56 : i64 to index
        omp.parallel   {
          %58 = llvm.alloca %8 x f32 : (i64) -> !llvm.ptr
          omp.wsloop   for  (%arg11) : index = (%51) to (%57) step (%c1) {
            %59 = builtin.unrealized_conversion_cast %arg11 : index to i64
            %60 = llvm.extractvalue %3[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %61 = llvm.getelementptr %60[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %62 = llvm.load %61 : !llvm.ptr -> i64
            %63 = builtin.unrealized_conversion_cast %62 : i64 to index
            %64 = arith.muli %47, %c32 : index
            %65 = arith.addi %64, %63 : index
            %66 = builtin.unrealized_conversion_cast %65 : index to i64
            %67 = llvm.getelementptr %16[%66] : (!llvm.ptr, i64) -> !llvm.ptr, f32
            %68 = llvm.load %67 : !llvm.ptr -> f32
            %69 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %70 = llvm.getelementptr %69[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %71 = llvm.load %70 : !llvm.ptr -> i64
            %72 = builtin.unrealized_conversion_cast %71 : i64 to index
            %73 = arith.addi %arg11, %c1 : index
            %74 = builtin.unrealized_conversion_cast %73 : index to i64
            %75 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %76 = llvm.getelementptr %75[%74] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %77 = llvm.load %76 : !llvm.ptr -> i64
            %78 = builtin.unrealized_conversion_cast %77 : i64 to index
            llvm.store %68, %58 : f32, !llvm.ptr
            omp.parallel   {
              omp.wsloop   reduction(@__scf_reduction -> %58 : !llvm.ptr) for  (%arg12) : index = (%72) to (%78) step (%c1) {
                %81 = builtin.unrealized_conversion_cast %arg12 : index to i64
                %82 = llvm.intr.stacksave : !llvm.ptr
                llvm.br ^bb1
              ^bb1:  // pred: ^bb0
                %83 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %84 = llvm.getelementptr %83[%81] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                %85 = llvm.load %84 : !llvm.ptr -> i64
                %86 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %87 = llvm.getelementptr %86[%81] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                %88 = llvm.load %87 : !llvm.ptr -> f32
                %89 = llvm.extractvalue %7[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %90 = llvm.getelementptr %89[%85] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                %91 = llvm.load %90 : !llvm.ptr -> f32
                %92 = arith.mulf %88, %91 : f32
                omp.reduction %92, %58 : f32, !llvm.ptr
                llvm.intr.stackrestore %82 : !llvm.ptr
                llvm.br ^bb2
              ^bb2:  // pred: ^bb1
                omp.yield
              }
              omp.terminator
            }
            %79 = llvm.load %58 : !llvm.ptr -> f32
            %80 = llvm.getelementptr %16[%66] : (!llvm.ptr, i64) -> !llvm.ptr, f32
            llvm.store %79, %80 : f32, !llvm.ptr
            omp.yield
          }
          omp.terminator
        }
        omp.yield
      }
      omp.terminator
    }
    return %24, %34 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After ConvertComplexToLibm (convert-complex-to-libm) //----- //
module {
  llvm.func @malloc(i64) -> !llvm.ptr
  omp.reduction.declare @__scf_reduction : f32 init {
  ^bb0(%arg0: f32):
    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    omp.yield(%0 : f32)
  } combiner {
  ^bb0(%arg0: f32, %arg1: f32):
    %0 = arith.addf %arg0, %arg1 : f32
    omp.yield(%0 : f32)
  } atomic {
  ^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr):
    %0 = llvm.load %arg1 : !llvm.ptr -> f32
    %1 = llvm.atomicrmw fadd %arg0, %0 monotonic : !llvm.ptr, f32
    omp.yield
  }
  func.func @SpTVMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<1 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %2 = builtin.unrealized_conversion_cast %arg2 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %3 = builtin.unrealized_conversion_cast %arg3 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %4 = builtin.unrealized_conversion_cast %arg4 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = builtin.unrealized_conversion_cast %arg5 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %6 = builtin.unrealized_conversion_cast %arg6 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = builtin.unrealized_conversion_cast %arg8 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %8 = llvm.mlir.constant(1 : i64) : i64
    %c0 = arith.constant 0 : index
    %9 = builtin.unrealized_conversion_cast %c0 : index to i64
    %c512 = arith.constant 512 : index
    %c1 = arith.constant 1 : index
    %10 = builtin.unrealized_conversion_cast %c1 : index to i64
    %c512_i64 = arith.constant 512 : i64
    %c32_i64 = arith.constant 32 : i64
    %c16_i64 = arith.constant 16 : i64
    %c0_i64 = arith.constant 0 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %c32 = arith.constant 32 : index
    %11 = llvm.mlir.constant(512 : index) : i64
    %12 = llvm.mlir.constant(1 : index) : i64
    %13 = llvm.mlir.null : !llvm.ptr
    %14 = llvm.getelementptr %13[512] : (!llvm.ptr) -> !llvm.ptr, f32
    %15 = llvm.ptrtoint %14 : !llvm.ptr to i64
    %16 = llvm.call @malloc(%15) : (i64) -> !llvm.ptr
    %17 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %18 = llvm.insertvalue %16, %17[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %19 = llvm.insertvalue %16, %18[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.mlir.constant(0 : index) : i64
    %21 = llvm.insertvalue %20, %19[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %11, %21[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %12, %22[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = builtin.unrealized_conversion_cast %23 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %25 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %26 = llvm.insertvalue %c0_i64, %25[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %27 = llvm.insertvalue %c16_i64, %26[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %28 = llvm.insertvalue %c32_i64, %27[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%29: index):  // 2 preds: ^bb0, ^bb2
    %30 = builtin.unrealized_conversion_cast %29 : index to i64
    %31 = arith.cmpi slt, %29, %c512 : index
    cf.cond_br %31, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %32 = llvm.getelementptr %16[%30] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %cst, %32 : f32, !llvm.ptr
    %33 = arith.addi %29, %c1 : index
    cf.br ^bb1(%33 : index)
  ^bb3:  // pred: ^bb1
    %34 = llvm.insertvalue %c512_i64, %28[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %35 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %36 = llvm.getelementptr %35[%9] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %37 = llvm.load %36 : !llvm.ptr -> i64
    %38 = builtin.unrealized_conversion_cast %37 : i64 to index
    %39 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %40 = llvm.getelementptr %39[%10] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %41 = llvm.load %40 : !llvm.ptr -> i64
    %42 = builtin.unrealized_conversion_cast %41 : i64 to index
    omp.parallel   {
      omp.wsloop   for  (%arg10) : index = (%38) to (%42) step (%c1) {
        %43 = builtin.unrealized_conversion_cast %arg10 : index to i64
        %44 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %45 = llvm.getelementptr %44[%43] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %46 = llvm.load %45 : !llvm.ptr -> i64
        %47 = builtin.unrealized_conversion_cast %46 : i64 to index
        %48 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %49 = llvm.getelementptr %48[%43] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %50 = llvm.load %49 : !llvm.ptr -> i64
        %51 = builtin.unrealized_conversion_cast %50 : i64 to index
        %52 = arith.addi %arg10, %c1 : index
        %53 = builtin.unrealized_conversion_cast %52 : index to i64
        %54 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %55 = llvm.getelementptr %54[%53] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %56 = llvm.load %55 : !llvm.ptr -> i64
        %57 = builtin.unrealized_conversion_cast %56 : i64 to index
        omp.parallel   {
          %58 = llvm.alloca %8 x f32 : (i64) -> !llvm.ptr
          omp.wsloop   for  (%arg11) : index = (%51) to (%57) step (%c1) {
            %59 = builtin.unrealized_conversion_cast %arg11 : index to i64
            %60 = llvm.extractvalue %3[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %61 = llvm.getelementptr %60[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %62 = llvm.load %61 : !llvm.ptr -> i64
            %63 = builtin.unrealized_conversion_cast %62 : i64 to index
            %64 = arith.muli %47, %c32 : index
            %65 = arith.addi %64, %63 : index
            %66 = builtin.unrealized_conversion_cast %65 : index to i64
            %67 = llvm.getelementptr %16[%66] : (!llvm.ptr, i64) -> !llvm.ptr, f32
            %68 = llvm.load %67 : !llvm.ptr -> f32
            %69 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %70 = llvm.getelementptr %69[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %71 = llvm.load %70 : !llvm.ptr -> i64
            %72 = builtin.unrealized_conversion_cast %71 : i64 to index
            %73 = arith.addi %arg11, %c1 : index
            %74 = builtin.unrealized_conversion_cast %73 : index to i64
            %75 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %76 = llvm.getelementptr %75[%74] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %77 = llvm.load %76 : !llvm.ptr -> i64
            %78 = builtin.unrealized_conversion_cast %77 : i64 to index
            llvm.store %68, %58 : f32, !llvm.ptr
            omp.parallel   {
              omp.wsloop   reduction(@__scf_reduction -> %58 : !llvm.ptr) for  (%arg12) : index = (%72) to (%78) step (%c1) {
                %81 = builtin.unrealized_conversion_cast %arg12 : index to i64
                %82 = llvm.intr.stacksave : !llvm.ptr
                llvm.br ^bb1
              ^bb1:  // pred: ^bb0
                %83 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %84 = llvm.getelementptr %83[%81] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                %85 = llvm.load %84 : !llvm.ptr -> i64
                %86 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %87 = llvm.getelementptr %86[%81] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                %88 = llvm.load %87 : !llvm.ptr -> f32
                %89 = llvm.extractvalue %7[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %90 = llvm.getelementptr %89[%85] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                %91 = llvm.load %90 : !llvm.ptr -> f32
                %92 = arith.mulf %88, %91 : f32
                omp.reduction %92, %58 : f32, !llvm.ptr
                llvm.intr.stackrestore %82 : !llvm.ptr
                llvm.br ^bb2
              ^bb2:  // pred: ^bb1
                omp.yield
              }
              omp.terminator
            }
            %79 = llvm.load %58 : !llvm.ptr -> f32
            %80 = llvm.getelementptr %16[%66] : (!llvm.ptr, i64) -> !llvm.ptr, f32
            llvm.store %79, %80 : f32, !llvm.ptr
            omp.yield
          }
          omp.terminator
        }
        omp.yield
      }
      omp.terminator
    }
    return %24, %34 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After ConvertVectorToLLVMPass (convert-vector-to-llvm) //----- //
module {
  llvm.func @malloc(i64) -> !llvm.ptr
  omp.reduction.declare @__scf_reduction : f32 init {
  ^bb0(%arg0: f32):
    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    omp.yield(%0 : f32)
  } combiner {
  ^bb0(%arg0: f32, %arg1: f32):
    %0 = arith.addf %arg0, %arg1 : f32
    omp.yield(%0 : f32)
  } atomic {
  ^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr):
    %0 = llvm.load %arg1 : !llvm.ptr -> f32
    %1 = llvm.atomicrmw fadd %arg0, %0 monotonic : !llvm.ptr, f32
    omp.yield
  }
  func.func @SpTVMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<1 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.constant(1 : index) : i64
    %2 = llvm.mlir.constant(512 : index) : i64
    %c32 = arith.constant 32 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c0_i64 = arith.constant 0 : i64
    %c16_i64 = arith.constant 16 : i64
    %c32_i64 = arith.constant 32 : i64
    %c512_i64 = arith.constant 512 : i64
    %c1 = arith.constant 1 : index
    %c512 = arith.constant 512 : index
    %c0 = arith.constant 0 : index
    %3 = llvm.mlir.constant(1 : i64) : i64
    %4 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %6 = builtin.unrealized_conversion_cast %arg2 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = builtin.unrealized_conversion_cast %arg3 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %8 = builtin.unrealized_conversion_cast %arg4 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %9 = builtin.unrealized_conversion_cast %arg5 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %10 = builtin.unrealized_conversion_cast %arg6 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %11 = builtin.unrealized_conversion_cast %arg8 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %12 = builtin.unrealized_conversion_cast %c0 : index to i64
    %13 = builtin.unrealized_conversion_cast %c1 : index to i64
    %14 = llvm.mlir.null : !llvm.ptr
    %15 = llvm.getelementptr %14[512] : (!llvm.ptr) -> !llvm.ptr, f32
    %16 = llvm.ptrtoint %15 : !llvm.ptr to i64
    %17 = llvm.call @malloc(%16) : (i64) -> !llvm.ptr
    %18 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %19 = llvm.insertvalue %17, %18[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.insertvalue %17, %19[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.insertvalue %0, %20[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %2, %21[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %1, %22[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = builtin.unrealized_conversion_cast %23 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %25 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %26 = llvm.insertvalue %c0_i64, %25[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %27 = llvm.insertvalue %c16_i64, %26[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %28 = llvm.insertvalue %c32_i64, %27[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%29: index):  // 2 preds: ^bb0, ^bb2
    %30 = builtin.unrealized_conversion_cast %29 : index to i64
    %31 = arith.cmpi slt, %29, %c512 : index
    cf.cond_br %31, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %32 = llvm.getelementptr %17[%30] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %cst, %32 : f32, !llvm.ptr
    %33 = arith.addi %29, %c1 : index
    cf.br ^bb1(%33 : index)
  ^bb3:  // pred: ^bb1
    %34 = llvm.insertvalue %c512_i64, %28[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %35 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %36 = llvm.getelementptr %35[%12] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %37 = llvm.load %36 : !llvm.ptr -> i64
    %38 = builtin.unrealized_conversion_cast %37 : i64 to index
    %39 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %40 = llvm.getelementptr %39[%13] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %41 = llvm.load %40 : !llvm.ptr -> i64
    %42 = builtin.unrealized_conversion_cast %41 : i64 to index
    omp.parallel   {
      omp.wsloop   for  (%arg10) : index = (%38) to (%42) step (%c1) {
        %43 = builtin.unrealized_conversion_cast %arg10 : index to i64
        %44 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %45 = llvm.getelementptr %44[%43] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %46 = llvm.load %45 : !llvm.ptr -> i64
        %47 = builtin.unrealized_conversion_cast %46 : i64 to index
        %48 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %49 = llvm.getelementptr %48[%43] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %50 = llvm.load %49 : !llvm.ptr -> i64
        %51 = builtin.unrealized_conversion_cast %50 : i64 to index
        %52 = arith.addi %arg10, %c1 : index
        %53 = builtin.unrealized_conversion_cast %52 : index to i64
        %54 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %55 = llvm.getelementptr %54[%53] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %56 = llvm.load %55 : !llvm.ptr -> i64
        %57 = builtin.unrealized_conversion_cast %56 : i64 to index
        omp.parallel   {
          %58 = llvm.alloca %3 x f32 : (i64) -> !llvm.ptr
          omp.wsloop   for  (%arg11) : index = (%51) to (%57) step (%c1) {
            %59 = builtin.unrealized_conversion_cast %arg11 : index to i64
            %60 = llvm.extractvalue %7[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %61 = llvm.getelementptr %60[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %62 = llvm.load %61 : !llvm.ptr -> i64
            %63 = builtin.unrealized_conversion_cast %62 : i64 to index
            %64 = arith.muli %47, %c32 : index
            %65 = arith.addi %64, %63 : index
            %66 = builtin.unrealized_conversion_cast %65 : index to i64
            %67 = llvm.getelementptr %17[%66] : (!llvm.ptr, i64) -> !llvm.ptr, f32
            %68 = llvm.load %67 : !llvm.ptr -> f32
            %69 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %70 = llvm.getelementptr %69[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %71 = llvm.load %70 : !llvm.ptr -> i64
            %72 = builtin.unrealized_conversion_cast %71 : i64 to index
            %73 = arith.addi %arg11, %c1 : index
            %74 = builtin.unrealized_conversion_cast %73 : index to i64
            %75 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %76 = llvm.getelementptr %75[%74] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %77 = llvm.load %76 : !llvm.ptr -> i64
            %78 = builtin.unrealized_conversion_cast %77 : i64 to index
            llvm.store %68, %58 : f32, !llvm.ptr
            omp.parallel   {
              omp.wsloop   reduction(@__scf_reduction -> %58 : !llvm.ptr) for  (%arg12) : index = (%72) to (%78) step (%c1) {
                %81 = builtin.unrealized_conversion_cast %arg12 : index to i64
                %82 = llvm.intr.stacksave : !llvm.ptr
                llvm.br ^bb1
              ^bb1:  // pred: ^bb0
                %83 = llvm.extractvalue %9[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %84 = llvm.getelementptr %83[%81] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                %85 = llvm.load %84 : !llvm.ptr -> i64
                %86 = llvm.extractvalue %10[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %87 = llvm.getelementptr %86[%81] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                %88 = llvm.load %87 : !llvm.ptr -> f32
                %89 = llvm.extractvalue %11[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %90 = llvm.getelementptr %89[%85] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                %91 = llvm.load %90 : !llvm.ptr -> f32
                %92 = arith.mulf %88, %91 : f32
                omp.reduction %92, %58 : f32, !llvm.ptr
                llvm.intr.stackrestore %82 : !llvm.ptr
                llvm.br ^bb2
              ^bb2:  // pred: ^bb1
                omp.yield
              }
              omp.terminator
            }
            %79 = llvm.load %58 : !llvm.ptr -> f32
            %80 = llvm.getelementptr %17[%66] : (!llvm.ptr, i64) -> !llvm.ptr, f32
            llvm.store %79, %80 : f32, !llvm.ptr
            omp.yield
          }
          omp.terminator
        }
        omp.yield
      }
      omp.terminator
    }
    return %24, %34 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After ConvertComplexToLLVMPass (convert-complex-to-llvm) //----- //
module {
  llvm.func @malloc(i64) -> !llvm.ptr
  omp.reduction.declare @__scf_reduction : f32 init {
  ^bb0(%arg0: f32):
    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    omp.yield(%0 : f32)
  } combiner {
  ^bb0(%arg0: f32, %arg1: f32):
    %0 = arith.addf %arg0, %arg1 : f32
    omp.yield(%0 : f32)
  } atomic {
  ^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr):
    %0 = llvm.load %arg1 : !llvm.ptr -> f32
    %1 = llvm.atomicrmw fadd %arg0, %0 monotonic : !llvm.ptr, f32
    omp.yield
  }
  func.func @SpTVMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<1 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.constant(1 : index) : i64
    %2 = llvm.mlir.constant(512 : index) : i64
    %c32 = arith.constant 32 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c0_i64 = arith.constant 0 : i64
    %c16_i64 = arith.constant 16 : i64
    %c32_i64 = arith.constant 32 : i64
    %c512_i64 = arith.constant 512 : i64
    %c1 = arith.constant 1 : index
    %c512 = arith.constant 512 : index
    %c0 = arith.constant 0 : index
    %3 = llvm.mlir.constant(1 : i64) : i64
    %4 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %6 = builtin.unrealized_conversion_cast %arg2 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = builtin.unrealized_conversion_cast %arg3 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %8 = builtin.unrealized_conversion_cast %arg4 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %9 = builtin.unrealized_conversion_cast %arg5 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %10 = builtin.unrealized_conversion_cast %arg6 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %11 = builtin.unrealized_conversion_cast %arg8 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %12 = builtin.unrealized_conversion_cast %c0 : index to i64
    %13 = builtin.unrealized_conversion_cast %c1 : index to i64
    %14 = llvm.mlir.null : !llvm.ptr
    %15 = llvm.getelementptr %14[512] : (!llvm.ptr) -> !llvm.ptr, f32
    %16 = llvm.ptrtoint %15 : !llvm.ptr to i64
    %17 = llvm.call @malloc(%16) : (i64) -> !llvm.ptr
    %18 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %19 = llvm.insertvalue %17, %18[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.insertvalue %17, %19[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.insertvalue %0, %20[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %2, %21[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %1, %22[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = builtin.unrealized_conversion_cast %23 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %25 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %26 = llvm.insertvalue %c0_i64, %25[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %27 = llvm.insertvalue %c16_i64, %26[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %28 = llvm.insertvalue %c32_i64, %27[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%29: index):  // 2 preds: ^bb0, ^bb2
    %30 = builtin.unrealized_conversion_cast %29 : index to i64
    %31 = arith.cmpi slt, %29, %c512 : index
    cf.cond_br %31, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %32 = llvm.getelementptr %17[%30] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %cst, %32 : f32, !llvm.ptr
    %33 = arith.addi %29, %c1 : index
    cf.br ^bb1(%33 : index)
  ^bb3:  // pred: ^bb1
    %34 = llvm.insertvalue %c512_i64, %28[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %35 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %36 = llvm.getelementptr %35[%12] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %37 = llvm.load %36 : !llvm.ptr -> i64
    %38 = builtin.unrealized_conversion_cast %37 : i64 to index
    %39 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %40 = llvm.getelementptr %39[%13] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %41 = llvm.load %40 : !llvm.ptr -> i64
    %42 = builtin.unrealized_conversion_cast %41 : i64 to index
    omp.parallel   {
      omp.wsloop   for  (%arg10) : index = (%38) to (%42) step (%c1) {
        %43 = builtin.unrealized_conversion_cast %arg10 : index to i64
        %44 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %45 = llvm.getelementptr %44[%43] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %46 = llvm.load %45 : !llvm.ptr -> i64
        %47 = builtin.unrealized_conversion_cast %46 : i64 to index
        %48 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %49 = llvm.getelementptr %48[%43] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %50 = llvm.load %49 : !llvm.ptr -> i64
        %51 = builtin.unrealized_conversion_cast %50 : i64 to index
        %52 = arith.addi %arg10, %c1 : index
        %53 = builtin.unrealized_conversion_cast %52 : index to i64
        %54 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %55 = llvm.getelementptr %54[%53] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %56 = llvm.load %55 : !llvm.ptr -> i64
        %57 = builtin.unrealized_conversion_cast %56 : i64 to index
        omp.parallel   {
          %58 = llvm.alloca %3 x f32 : (i64) -> !llvm.ptr
          omp.wsloop   for  (%arg11) : index = (%51) to (%57) step (%c1) {
            %59 = builtin.unrealized_conversion_cast %arg11 : index to i64
            %60 = llvm.extractvalue %7[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %61 = llvm.getelementptr %60[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %62 = llvm.load %61 : !llvm.ptr -> i64
            %63 = builtin.unrealized_conversion_cast %62 : i64 to index
            %64 = arith.muli %47, %c32 : index
            %65 = arith.addi %64, %63 : index
            %66 = builtin.unrealized_conversion_cast %65 : index to i64
            %67 = llvm.getelementptr %17[%66] : (!llvm.ptr, i64) -> !llvm.ptr, f32
            %68 = llvm.load %67 : !llvm.ptr -> f32
            %69 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %70 = llvm.getelementptr %69[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %71 = llvm.load %70 : !llvm.ptr -> i64
            %72 = builtin.unrealized_conversion_cast %71 : i64 to index
            %73 = arith.addi %arg11, %c1 : index
            %74 = builtin.unrealized_conversion_cast %73 : index to i64
            %75 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %76 = llvm.getelementptr %75[%74] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %77 = llvm.load %76 : !llvm.ptr -> i64
            %78 = builtin.unrealized_conversion_cast %77 : i64 to index
            llvm.store %68, %58 : f32, !llvm.ptr
            omp.parallel   {
              omp.wsloop   reduction(@__scf_reduction -> %58 : !llvm.ptr) for  (%arg12) : index = (%72) to (%78) step (%c1) {
                %81 = builtin.unrealized_conversion_cast %arg12 : index to i64
                %82 = llvm.intr.stacksave : !llvm.ptr
                llvm.br ^bb1
              ^bb1:  // pred: ^bb0
                %83 = llvm.extractvalue %9[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %84 = llvm.getelementptr %83[%81] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                %85 = llvm.load %84 : !llvm.ptr -> i64
                %86 = llvm.extractvalue %10[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %87 = llvm.getelementptr %86[%81] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                %88 = llvm.load %87 : !llvm.ptr -> f32
                %89 = llvm.extractvalue %11[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %90 = llvm.getelementptr %89[%85] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                %91 = llvm.load %90 : !llvm.ptr -> f32
                %92 = arith.mulf %88, %91 : f32
                omp.reduction %92, %58 : f32, !llvm.ptr
                llvm.intr.stackrestore %82 : !llvm.ptr
                llvm.br ^bb2
              ^bb2:  // pred: ^bb1
                omp.yield
              }
              omp.terminator
            }
            %79 = llvm.load %58 : !llvm.ptr -> f32
            %80 = llvm.getelementptr %17[%66] : (!llvm.ptr, i64) -> !llvm.ptr, f32
            llvm.store %79, %80 : f32, !llvm.ptr
            omp.yield
          }
          omp.terminator
        }
        omp.yield
      }
      omp.terminator
    }
    return %24, %34 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After ConvertVectorToLLVMPass (convert-vector-to-llvm) //----- //
module {
  llvm.func @malloc(i64) -> !llvm.ptr
  omp.reduction.declare @__scf_reduction : f32 init {
  ^bb0(%arg0: f32):
    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    omp.yield(%0 : f32)
  } combiner {
  ^bb0(%arg0: f32, %arg1: f32):
    %0 = arith.addf %arg0, %arg1 : f32
    omp.yield(%0 : f32)
  } atomic {
  ^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr):
    %0 = llvm.load %arg1 : !llvm.ptr -> f32
    %1 = llvm.atomicrmw fadd %arg0, %0 monotonic : !llvm.ptr, f32
    omp.yield
  }
  func.func @SpTVMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<1 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.constant(1 : index) : i64
    %2 = llvm.mlir.constant(512 : index) : i64
    %c32 = arith.constant 32 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c0_i64 = arith.constant 0 : i64
    %c16_i64 = arith.constant 16 : i64
    %c32_i64 = arith.constant 32 : i64
    %c512_i64 = arith.constant 512 : i64
    %c1 = arith.constant 1 : index
    %c512 = arith.constant 512 : index
    %c0 = arith.constant 0 : index
    %3 = llvm.mlir.constant(1 : i64) : i64
    %4 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %6 = builtin.unrealized_conversion_cast %arg2 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = builtin.unrealized_conversion_cast %arg3 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %8 = builtin.unrealized_conversion_cast %arg4 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %9 = builtin.unrealized_conversion_cast %arg5 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %10 = builtin.unrealized_conversion_cast %arg6 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %11 = builtin.unrealized_conversion_cast %arg8 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %12 = builtin.unrealized_conversion_cast %c0 : index to i64
    %13 = builtin.unrealized_conversion_cast %c1 : index to i64
    %14 = llvm.mlir.null : !llvm.ptr
    %15 = llvm.getelementptr %14[512] : (!llvm.ptr) -> !llvm.ptr, f32
    %16 = llvm.ptrtoint %15 : !llvm.ptr to i64
    %17 = llvm.call @malloc(%16) : (i64) -> !llvm.ptr
    %18 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %19 = llvm.insertvalue %17, %18[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.insertvalue %17, %19[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.insertvalue %0, %20[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %2, %21[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %1, %22[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = builtin.unrealized_conversion_cast %23 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %25 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %26 = llvm.insertvalue %c0_i64, %25[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %27 = llvm.insertvalue %c16_i64, %26[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %28 = llvm.insertvalue %c32_i64, %27[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%29: index):  // 2 preds: ^bb0, ^bb2
    %30 = builtin.unrealized_conversion_cast %29 : index to i64
    %31 = arith.cmpi slt, %29, %c512 : index
    cf.cond_br %31, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %32 = llvm.getelementptr %17[%30] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %cst, %32 : f32, !llvm.ptr
    %33 = arith.addi %29, %c1 : index
    cf.br ^bb1(%33 : index)
  ^bb3:  // pred: ^bb1
    %34 = llvm.insertvalue %c512_i64, %28[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %35 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %36 = llvm.getelementptr %35[%12] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %37 = llvm.load %36 : !llvm.ptr -> i64
    %38 = builtin.unrealized_conversion_cast %37 : i64 to index
    %39 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %40 = llvm.getelementptr %39[%13] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %41 = llvm.load %40 : !llvm.ptr -> i64
    %42 = builtin.unrealized_conversion_cast %41 : i64 to index
    omp.parallel   {
      omp.wsloop   for  (%arg10) : index = (%38) to (%42) step (%c1) {
        %43 = builtin.unrealized_conversion_cast %arg10 : index to i64
        %44 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %45 = llvm.getelementptr %44[%43] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %46 = llvm.load %45 : !llvm.ptr -> i64
        %47 = builtin.unrealized_conversion_cast %46 : i64 to index
        %48 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %49 = llvm.getelementptr %48[%43] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %50 = llvm.load %49 : !llvm.ptr -> i64
        %51 = builtin.unrealized_conversion_cast %50 : i64 to index
        %52 = arith.addi %arg10, %c1 : index
        %53 = builtin.unrealized_conversion_cast %52 : index to i64
        %54 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %55 = llvm.getelementptr %54[%53] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %56 = llvm.load %55 : !llvm.ptr -> i64
        %57 = builtin.unrealized_conversion_cast %56 : i64 to index
        omp.parallel   {
          %58 = llvm.alloca %3 x f32 : (i64) -> !llvm.ptr
          omp.wsloop   for  (%arg11) : index = (%51) to (%57) step (%c1) {
            %59 = builtin.unrealized_conversion_cast %arg11 : index to i64
            %60 = llvm.extractvalue %7[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %61 = llvm.getelementptr %60[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %62 = llvm.load %61 : !llvm.ptr -> i64
            %63 = builtin.unrealized_conversion_cast %62 : i64 to index
            %64 = arith.muli %47, %c32 : index
            %65 = arith.addi %64, %63 : index
            %66 = builtin.unrealized_conversion_cast %65 : index to i64
            %67 = llvm.getelementptr %17[%66] : (!llvm.ptr, i64) -> !llvm.ptr, f32
            %68 = llvm.load %67 : !llvm.ptr -> f32
            %69 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %70 = llvm.getelementptr %69[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %71 = llvm.load %70 : !llvm.ptr -> i64
            %72 = builtin.unrealized_conversion_cast %71 : i64 to index
            %73 = arith.addi %arg11, %c1 : index
            %74 = builtin.unrealized_conversion_cast %73 : index to i64
            %75 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %76 = llvm.getelementptr %75[%74] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %77 = llvm.load %76 : !llvm.ptr -> i64
            %78 = builtin.unrealized_conversion_cast %77 : i64 to index
            llvm.store %68, %58 : f32, !llvm.ptr
            omp.parallel   {
              omp.wsloop   reduction(@__scf_reduction -> %58 : !llvm.ptr) for  (%arg12) : index = (%72) to (%78) step (%c1) {
                %81 = builtin.unrealized_conversion_cast %arg12 : index to i64
                %82 = llvm.intr.stacksave : !llvm.ptr
                llvm.br ^bb1
              ^bb1:  // pred: ^bb0
                %83 = llvm.extractvalue %9[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %84 = llvm.getelementptr %83[%81] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                %85 = llvm.load %84 : !llvm.ptr -> i64
                %86 = llvm.extractvalue %10[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %87 = llvm.getelementptr %86[%81] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                %88 = llvm.load %87 : !llvm.ptr -> f32
                %89 = llvm.extractvalue %11[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %90 = llvm.getelementptr %89[%85] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                %91 = llvm.load %90 : !llvm.ptr -> f32
                %92 = arith.mulf %88, %91 : f32
                omp.reduction %92, %58 : f32, !llvm.ptr
                llvm.intr.stackrestore %82 : !llvm.ptr
                llvm.br ^bb2
              ^bb2:  // pred: ^bb1
                omp.yield
              }
              omp.terminator
            }
            %79 = llvm.load %58 : !llvm.ptr -> f32
            %80 = llvm.getelementptr %17[%66] : (!llvm.ptr, i64) -> !llvm.ptr, f32
            llvm.store %79, %80 : f32, !llvm.ptr
            omp.yield
          }
          omp.terminator
        }
        omp.yield
      }
      omp.terminator
    }
    return %24, %34 : memref<?xf32>, !llvm.struct<(array<2 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After ConvertOpenMPToLLVMPass (convert-openmp-to-llvm) //----- //
module {
  llvm.func @malloc(i64) -> !llvm.ptr
  omp.reduction.declare @__scf_reduction : f32 init {
  ^bb0(%arg0: f32):
    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    omp.yield(%0 : f32)
  } combiner {
  ^bb0(%arg0: f32, %arg1: f32):
    %0 = llvm.fadd %arg0, %arg1  : f32
    omp.yield(%0 : f32)
  } atomic {
  ^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr):
    %0 = llvm.load %arg1 : !llvm.ptr -> f32
    %1 = llvm.atomicrmw fadd %arg0, %0 monotonic : !llvm.ptr, f32
    omp.yield
  }
  llvm.func @SpTVMul.Z.0.main(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: !llvm.ptr, %arg6: !llvm.ptr, %arg7: i64, %arg8: i64, %arg9: i64, %arg10: !llvm.ptr, %arg11: !llvm.ptr, %arg12: i64, %arg13: i64, %arg14: i64, %arg15: !llvm.ptr, %arg16: !llvm.ptr, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: !llvm.ptr, %arg21: !llvm.ptr, %arg22: i64, %arg23: i64, %arg24: i64, %arg25: !llvm.ptr, %arg26: !llvm.ptr, %arg27: i64, %arg28: i64, %arg29: i64, %arg30: !llvm.ptr, %arg31: !llvm.ptr, %arg32: i64, %arg33: i64, %arg34: i64, %arg35: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg36: !llvm.ptr, %arg37: !llvm.ptr, %arg38: i64, %arg39: i64, %arg40: i64, %arg41: !llvm.struct<(array<1 x i64>, array<1 x i64>)>) -> !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)> attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = llvm.insertvalue %arg0, %0[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %2 = llvm.insertvalue %arg1, %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %3 = llvm.insertvalue %arg2, %2[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %4 = llvm.insertvalue %arg3, %3[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %5 = llvm.insertvalue %arg4, %4[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %6 = builtin.unrealized_conversion_cast %5 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %7 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %8 = llvm.insertvalue %arg5, %7[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %9 = llvm.insertvalue %arg6, %8[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %10 = llvm.insertvalue %arg7, %9[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %11 = llvm.insertvalue %arg8, %10[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %12 = llvm.insertvalue %arg9, %11[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %13 = builtin.unrealized_conversion_cast %12 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %14 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %15 = llvm.insertvalue %arg10, %14[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.insertvalue %arg11, %15[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.insertvalue %arg12, %16[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.insertvalue %arg13, %17[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %19 = llvm.insertvalue %arg14, %18[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = builtin.unrealized_conversion_cast %19 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %21 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %22 = llvm.insertvalue %arg15, %21[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %arg16, %22[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = llvm.insertvalue %arg17, %23[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %25 = llvm.insertvalue %arg18, %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %26 = llvm.insertvalue %arg19, %25[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %27 = builtin.unrealized_conversion_cast %26 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %28 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %29 = llvm.insertvalue %arg20, %28[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.insertvalue %arg21, %29[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %31 = llvm.insertvalue %arg22, %30[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %32 = llvm.insertvalue %arg23, %31[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.insertvalue %arg24, %32[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = builtin.unrealized_conversion_cast %33 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %35 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %36 = llvm.insertvalue %arg25, %35[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %37 = llvm.insertvalue %arg26, %36[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %38 = llvm.insertvalue %arg27, %37[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %39 = llvm.insertvalue %arg28, %38[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %40 = llvm.insertvalue %arg29, %39[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %41 = builtin.unrealized_conversion_cast %40 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %42 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %43 = llvm.insertvalue %arg30, %42[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %44 = llvm.insertvalue %arg31, %43[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %45 = llvm.insertvalue %arg32, %44[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %46 = llvm.insertvalue %arg33, %45[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %47 = llvm.insertvalue %arg34, %46[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %48 = builtin.unrealized_conversion_cast %47 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %49 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %50 = llvm.insertvalue %arg36, %49[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %51 = llvm.insertvalue %arg37, %50[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %52 = llvm.insertvalue %arg38, %51[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %53 = llvm.insertvalue %arg39, %52[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %54 = llvm.insertvalue %arg40, %53[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %55 = builtin.unrealized_conversion_cast %54 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %56 = llvm.mlir.constant(0 : index) : i64
    %57 = llvm.mlir.constant(1 : index) : i64
    %58 = llvm.mlir.constant(512 : index) : i64
    %59 = llvm.mlir.constant(32 : index) : i64
    %60 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %61 = llvm.mlir.constant(0 : i64) : i64
    %62 = llvm.mlir.constant(16 : i64) : i64
    %63 = llvm.mlir.constant(32 : i64) : i64
    %64 = llvm.mlir.constant(512 : i64) : i64
    %65 = llvm.mlir.constant(1 : index) : i64
    %66 = builtin.unrealized_conversion_cast %65 : i64 to index
    %67 = llvm.mlir.constant(512 : index) : i64
    %68 = llvm.mlir.constant(0 : index) : i64
    %69 = builtin.unrealized_conversion_cast %68 : i64 to index
    %70 = llvm.mlir.constant(1 : i64) : i64
    %71 = builtin.unrealized_conversion_cast %6 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %72 = builtin.unrealized_conversion_cast %13 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %73 = builtin.unrealized_conversion_cast %20 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %74 = builtin.unrealized_conversion_cast %27 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %75 = builtin.unrealized_conversion_cast %34 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %76 = builtin.unrealized_conversion_cast %41 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %77 = builtin.unrealized_conversion_cast %48 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %78 = builtin.unrealized_conversion_cast %55 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %79 = builtin.unrealized_conversion_cast %69 : index to i64
    %80 = builtin.unrealized_conversion_cast %66 : index to i64
    %81 = llvm.mlir.null : !llvm.ptr
    %82 = llvm.getelementptr %81[512] : (!llvm.ptr) -> !llvm.ptr, f32
    %83 = llvm.ptrtoint %82 : !llvm.ptr to i64
    %84 = llvm.call @malloc(%83) : (i64) -> !llvm.ptr
    %85 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %86 = llvm.insertvalue %84, %85[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %87 = llvm.insertvalue %84, %86[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %88 = llvm.insertvalue %56, %87[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %89 = llvm.insertvalue %58, %88[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %90 = llvm.insertvalue %57, %89[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %91 = builtin.unrealized_conversion_cast %90 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %92 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %93 = llvm.insertvalue %61, %92[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %94 = llvm.insertvalue %62, %93[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %95 = llvm.insertvalue %63, %94[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    llvm.br ^bb1(%68 : i64)
  ^bb1(%96: i64):  // 2 preds: ^bb0, ^bb2
    %97 = builtin.unrealized_conversion_cast %96 : i64 to index
    %98 = builtin.unrealized_conversion_cast %97 : index to i64
    %99 = llvm.icmp "slt" %96, %67 : i64
    llvm.cond_br %99, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %100 = llvm.getelementptr %84[%98] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %60, %100 : f32, !llvm.ptr
    %101 = llvm.add %96, %65  : i64
    llvm.br ^bb1(%101 : i64)
  ^bb3:  // pred: ^bb1
    %102 = llvm.insertvalue %64, %95[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %103 = llvm.extractvalue %71[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %104 = llvm.getelementptr %103[%79] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %105 = llvm.load %104 : !llvm.ptr -> i64
    %106 = builtin.unrealized_conversion_cast %105 : i64 to index
    %107 = llvm.extractvalue %71[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %108 = llvm.getelementptr %107[%80] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %109 = llvm.load %108 : !llvm.ptr -> i64
    %110 = builtin.unrealized_conversion_cast %109 : i64 to index
    omp.parallel   {
      omp.wsloop   for  (%arg42) : i64 = (%105) to (%109) step (%65) {
        %114 = builtin.unrealized_conversion_cast %arg42 : i64 to index
        %115 = builtin.unrealized_conversion_cast %114 : index to i64
        %116 = llvm.extractvalue %72[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %117 = llvm.getelementptr %116[%115] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %118 = llvm.load %117 : !llvm.ptr -> i64
        %119 = builtin.unrealized_conversion_cast %118 : i64 to index
        %120 = llvm.extractvalue %73[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %121 = llvm.getelementptr %120[%115] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %122 = llvm.load %121 : !llvm.ptr -> i64
        %123 = builtin.unrealized_conversion_cast %122 : i64 to index
        %124 = llvm.add %arg42, %65  : i64
        %125 = builtin.unrealized_conversion_cast %124 : i64 to index
        %126 = builtin.unrealized_conversion_cast %125 : index to i64
        %127 = llvm.extractvalue %73[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %128 = llvm.getelementptr %127[%126] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %129 = llvm.load %128 : !llvm.ptr -> i64
        %130 = builtin.unrealized_conversion_cast %129 : i64 to index
        omp.parallel   {
          %131 = llvm.alloca %70 x f32 : (i64) -> !llvm.ptr
          omp.wsloop   for  (%arg43) : i64 = (%122) to (%129) step (%65) {
            %132 = builtin.unrealized_conversion_cast %arg43 : i64 to index
            %133 = builtin.unrealized_conversion_cast %132 : index to i64
            %134 = llvm.extractvalue %74[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %135 = llvm.getelementptr %134[%133] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %136 = llvm.load %135 : !llvm.ptr -> i64
            %137 = builtin.unrealized_conversion_cast %136 : i64 to index
            %138 = llvm.mul %118, %59  : i64
            %139 = llvm.add %138, %136  : i64
            %140 = builtin.unrealized_conversion_cast %139 : i64 to index
            %141 = builtin.unrealized_conversion_cast %140 : index to i64
            %142 = llvm.getelementptr %84[%141] : (!llvm.ptr, i64) -> !llvm.ptr, f32
            %143 = llvm.load %142 : !llvm.ptr -> f32
            %144 = llvm.extractvalue %75[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %145 = llvm.getelementptr %144[%133] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %146 = llvm.load %145 : !llvm.ptr -> i64
            %147 = builtin.unrealized_conversion_cast %146 : i64 to index
            %148 = llvm.add %arg43, %65  : i64
            %149 = builtin.unrealized_conversion_cast %148 : i64 to index
            %150 = builtin.unrealized_conversion_cast %149 : index to i64
            %151 = llvm.extractvalue %75[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %152 = llvm.getelementptr %151[%150] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %153 = llvm.load %152 : !llvm.ptr -> i64
            %154 = builtin.unrealized_conversion_cast %153 : i64 to index
            llvm.store %143, %131 : f32, !llvm.ptr
            omp.parallel   {
              omp.wsloop   reduction(@__scf_reduction -> %131 : !llvm.ptr) for  (%arg44) : i64 = (%146) to (%153) step (%65) {
                %157 = builtin.unrealized_conversion_cast %arg44 : i64 to index
                %158 = builtin.unrealized_conversion_cast %157 : index to i64
                %159 = llvm.intr.stacksave : !llvm.ptr
                llvm.br ^bb1
              ^bb1:  // pred: ^bb0
                %160 = llvm.extractvalue %76[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %161 = llvm.getelementptr %160[%158] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                %162 = llvm.load %161 : !llvm.ptr -> i64
                %163 = llvm.extractvalue %77[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %164 = llvm.getelementptr %163[%158] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                %165 = llvm.load %164 : !llvm.ptr -> f32
                %166 = llvm.extractvalue %78[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %167 = llvm.getelementptr %166[%162] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                %168 = llvm.load %167 : !llvm.ptr -> f32
                %169 = llvm.fmul %165, %168  : f32
                omp.reduction %169, %131 : f32, !llvm.ptr
                llvm.intr.stackrestore %159 : !llvm.ptr
                llvm.br ^bb2
              ^bb2:  // pred: ^bb1
                omp.yield
              }
              omp.terminator
            }
            %155 = llvm.load %131 : !llvm.ptr -> f32
            %156 = llvm.getelementptr %84[%141] : (!llvm.ptr, i64) -> !llvm.ptr, f32
            llvm.store %155, %156 : f32, !llvm.ptr
            omp.yield
          }
          omp.terminator
        }
        omp.yield
      }
      omp.terminator
    }
    %111 = llvm.mlir.undef : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)>
    %112 = llvm.insertvalue %90, %111[0] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)> 
    %113 = llvm.insertvalue %102, %112[1] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)> 
    llvm.return %113 : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)>
  }
  llvm.func @_mlir_ciface_SpTVMul.Z.0.main(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr, %arg3: !llvm.ptr, %arg4: !llvm.ptr, %arg5: !llvm.ptr, %arg6: !llvm.ptr, %arg7: !llvm.ptr, %arg8: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg9: !llvm.ptr, %arg10: !llvm.struct<(array<1 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %5 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %6 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = llvm.extractvalue %6[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %8 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %9 = llvm.extractvalue %6[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %10 = llvm.extractvalue %6[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %11 = llvm.extractvalue %6[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %12 = llvm.load %arg3 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %13 = llvm.extractvalue %12[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.extractvalue %12[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.extractvalue %12[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.extractvalue %12[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.extractvalue %12[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.load %arg4 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %19 = llvm.extractvalue %18[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.extractvalue %18[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.extractvalue %18[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.extractvalue %18[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.extractvalue %18[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = llvm.load %arg5 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %25 = llvm.extractvalue %24[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %26 = llvm.extractvalue %24[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %27 = llvm.extractvalue %24[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %28 = llvm.extractvalue %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %29 = llvm.extractvalue %24[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.load %arg6 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %31 = llvm.extractvalue %30[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %32 = llvm.extractvalue %30[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.extractvalue %30[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = llvm.extractvalue %30[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %35 = llvm.extractvalue %30[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %36 = llvm.load %arg7 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %37 = llvm.extractvalue %36[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %38 = llvm.extractvalue %36[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %39 = llvm.extractvalue %36[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %40 = llvm.extractvalue %36[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %41 = llvm.extractvalue %36[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %42 = llvm.load %arg9 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %43 = llvm.extractvalue %42[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %44 = llvm.extractvalue %42[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %45 = llvm.extractvalue %42[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %46 = llvm.extractvalue %42[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %47 = llvm.extractvalue %42[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %48 = llvm.call @SpTVMul.Z.0.main(%1, %2, %3, %4, %5, %7, %8, %9, %10, %11, %13, %14, %15, %16, %17, %19, %20, %21, %22, %23, %25, %26, %27, %28, %29, %31, %32, %33, %34, %35, %37, %38, %39, %40, %41, %arg8, %43, %44, %45, %46, %47, %arg10) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.struct<(array<3 x i64>, array<7 x i64>)>, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.struct<(array<1 x i64>, array<1 x i64>)>) -> !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)>
    llvm.store %48, %arg0 : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)>, !llvm.ptr
    llvm.return
  }
}


// -----// IR Dump After ConvertFuncToLLVMPass (convert-func-to-llvm) //----- //
module attributes {llvm.data_layout = ""} {
  llvm.func @malloc(i64) -> !llvm.ptr
  omp.reduction.declare @__scf_reduction : f32 init {
  ^bb0(%arg0: f32):
    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    omp.yield(%0 : f32)
  } combiner {
  ^bb0(%arg0: f32, %arg1: f32):
    %0 = llvm.fadd %arg0, %arg1  : f32
    omp.yield(%0 : f32)
  } atomic {
  ^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr):
    %0 = llvm.load %arg1 : !llvm.ptr -> f32
    %1 = llvm.atomicrmw fadd %arg0, %0 monotonic : !llvm.ptr, f32
    omp.yield
  }
  llvm.func @SpTVMul.Z.0.main(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: !llvm.ptr, %arg6: !llvm.ptr, %arg7: i64, %arg8: i64, %arg9: i64, %arg10: !llvm.ptr, %arg11: !llvm.ptr, %arg12: i64, %arg13: i64, %arg14: i64, %arg15: !llvm.ptr, %arg16: !llvm.ptr, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: !llvm.ptr, %arg21: !llvm.ptr, %arg22: i64, %arg23: i64, %arg24: i64, %arg25: !llvm.ptr, %arg26: !llvm.ptr, %arg27: i64, %arg28: i64, %arg29: i64, %arg30: !llvm.ptr, %arg31: !llvm.ptr, %arg32: i64, %arg33: i64, %arg34: i64, %arg35: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg36: !llvm.ptr, %arg37: !llvm.ptr, %arg38: i64, %arg39: i64, %arg40: i64, %arg41: !llvm.struct<(array<1 x i64>, array<1 x i64>)>) -> !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)> attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = llvm.insertvalue %arg0, %0[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %2 = llvm.insertvalue %arg1, %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %3 = llvm.insertvalue %arg2, %2[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %4 = llvm.insertvalue %arg3, %3[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %5 = llvm.insertvalue %arg4, %4[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %6 = builtin.unrealized_conversion_cast %5 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %7 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %8 = llvm.insertvalue %arg5, %7[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %9 = llvm.insertvalue %arg6, %8[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %10 = llvm.insertvalue %arg7, %9[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %11 = llvm.insertvalue %arg8, %10[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %12 = llvm.insertvalue %arg9, %11[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %13 = builtin.unrealized_conversion_cast %12 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %14 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %15 = llvm.insertvalue %arg10, %14[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.insertvalue %arg11, %15[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.insertvalue %arg12, %16[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.insertvalue %arg13, %17[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %19 = llvm.insertvalue %arg14, %18[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = builtin.unrealized_conversion_cast %19 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %21 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %22 = llvm.insertvalue %arg15, %21[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %arg16, %22[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = llvm.insertvalue %arg17, %23[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %25 = llvm.insertvalue %arg18, %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %26 = llvm.insertvalue %arg19, %25[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %27 = builtin.unrealized_conversion_cast %26 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %28 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %29 = llvm.insertvalue %arg20, %28[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.insertvalue %arg21, %29[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %31 = llvm.insertvalue %arg22, %30[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %32 = llvm.insertvalue %arg23, %31[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.insertvalue %arg24, %32[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = builtin.unrealized_conversion_cast %33 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %35 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %36 = llvm.insertvalue %arg25, %35[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %37 = llvm.insertvalue %arg26, %36[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %38 = llvm.insertvalue %arg27, %37[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %39 = llvm.insertvalue %arg28, %38[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %40 = llvm.insertvalue %arg29, %39[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %41 = builtin.unrealized_conversion_cast %40 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %42 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %43 = llvm.insertvalue %arg30, %42[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %44 = llvm.insertvalue %arg31, %43[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %45 = llvm.insertvalue %arg32, %44[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %46 = llvm.insertvalue %arg33, %45[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %47 = llvm.insertvalue %arg34, %46[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %48 = builtin.unrealized_conversion_cast %47 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %49 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %50 = llvm.insertvalue %arg36, %49[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %51 = llvm.insertvalue %arg37, %50[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %52 = llvm.insertvalue %arg38, %51[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %53 = llvm.insertvalue %arg39, %52[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %54 = llvm.insertvalue %arg40, %53[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %55 = builtin.unrealized_conversion_cast %54 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %56 = llvm.mlir.constant(0 : index) : i64
    %57 = llvm.mlir.constant(1 : index) : i64
    %58 = llvm.mlir.constant(512 : index) : i64
    %59 = llvm.mlir.constant(32 : index) : i64
    %60 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %61 = llvm.mlir.constant(0 : i64) : i64
    %62 = llvm.mlir.constant(16 : i64) : i64
    %63 = llvm.mlir.constant(32 : i64) : i64
    %64 = llvm.mlir.constant(512 : i64) : i64
    %65 = llvm.mlir.constant(1 : index) : i64
    %66 = builtin.unrealized_conversion_cast %65 : i64 to index
    %67 = llvm.mlir.constant(512 : index) : i64
    %68 = llvm.mlir.constant(0 : index) : i64
    %69 = builtin.unrealized_conversion_cast %68 : i64 to index
    %70 = llvm.mlir.constant(1 : i64) : i64
    %71 = builtin.unrealized_conversion_cast %6 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %72 = builtin.unrealized_conversion_cast %13 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %73 = builtin.unrealized_conversion_cast %20 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %74 = builtin.unrealized_conversion_cast %27 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %75 = builtin.unrealized_conversion_cast %34 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %76 = builtin.unrealized_conversion_cast %41 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %77 = builtin.unrealized_conversion_cast %48 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %78 = builtin.unrealized_conversion_cast %55 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %79 = builtin.unrealized_conversion_cast %69 : index to i64
    %80 = builtin.unrealized_conversion_cast %66 : index to i64
    %81 = llvm.mlir.null : !llvm.ptr
    %82 = llvm.getelementptr %81[512] : (!llvm.ptr) -> !llvm.ptr, f32
    %83 = llvm.ptrtoint %82 : !llvm.ptr to i64
    %84 = llvm.call @malloc(%83) : (i64) -> !llvm.ptr
    %85 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %86 = llvm.insertvalue %84, %85[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %87 = llvm.insertvalue %84, %86[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %88 = llvm.insertvalue %56, %87[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %89 = llvm.insertvalue %58, %88[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %90 = llvm.insertvalue %57, %89[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %91 = builtin.unrealized_conversion_cast %90 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %92 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %93 = llvm.insertvalue %61, %92[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %94 = llvm.insertvalue %62, %93[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %95 = llvm.insertvalue %63, %94[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    llvm.br ^bb1(%68 : i64)
  ^bb1(%96: i64):  // 2 preds: ^bb0, ^bb2
    %97 = builtin.unrealized_conversion_cast %96 : i64 to index
    %98 = builtin.unrealized_conversion_cast %97 : index to i64
    %99 = llvm.icmp "slt" %96, %67 : i64
    llvm.cond_br %99, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %100 = llvm.getelementptr %84[%98] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %60, %100 : f32, !llvm.ptr
    %101 = llvm.add %96, %65  : i64
    llvm.br ^bb1(%101 : i64)
  ^bb3:  // pred: ^bb1
    %102 = llvm.insertvalue %64, %95[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %103 = llvm.extractvalue %71[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %104 = llvm.getelementptr %103[%79] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %105 = llvm.load %104 : !llvm.ptr -> i64
    %106 = builtin.unrealized_conversion_cast %105 : i64 to index
    %107 = llvm.extractvalue %71[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %108 = llvm.getelementptr %107[%80] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %109 = llvm.load %108 : !llvm.ptr -> i64
    %110 = builtin.unrealized_conversion_cast %109 : i64 to index
    omp.parallel   {
      omp.wsloop   for  (%arg42) : i64 = (%105) to (%109) step (%65) {
        %114 = builtin.unrealized_conversion_cast %arg42 : i64 to index
        %115 = builtin.unrealized_conversion_cast %114 : index to i64
        %116 = llvm.extractvalue %72[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %117 = llvm.getelementptr %116[%115] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %118 = llvm.load %117 : !llvm.ptr -> i64
        %119 = builtin.unrealized_conversion_cast %118 : i64 to index
        %120 = llvm.extractvalue %73[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %121 = llvm.getelementptr %120[%115] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %122 = llvm.load %121 : !llvm.ptr -> i64
        %123 = builtin.unrealized_conversion_cast %122 : i64 to index
        %124 = llvm.add %arg42, %65  : i64
        %125 = builtin.unrealized_conversion_cast %124 : i64 to index
        %126 = builtin.unrealized_conversion_cast %125 : index to i64
        %127 = llvm.extractvalue %73[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %128 = llvm.getelementptr %127[%126] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %129 = llvm.load %128 : !llvm.ptr -> i64
        %130 = builtin.unrealized_conversion_cast %129 : i64 to index
        omp.parallel   {
          %131 = llvm.alloca %70 x f32 : (i64) -> !llvm.ptr
          omp.wsloop   for  (%arg43) : i64 = (%122) to (%129) step (%65) {
            %132 = builtin.unrealized_conversion_cast %arg43 : i64 to index
            %133 = builtin.unrealized_conversion_cast %132 : index to i64
            %134 = llvm.extractvalue %74[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %135 = llvm.getelementptr %134[%133] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %136 = llvm.load %135 : !llvm.ptr -> i64
            %137 = builtin.unrealized_conversion_cast %136 : i64 to index
            %138 = llvm.mul %118, %59  : i64
            %139 = llvm.add %138, %136  : i64
            %140 = builtin.unrealized_conversion_cast %139 : i64 to index
            %141 = builtin.unrealized_conversion_cast %140 : index to i64
            %142 = llvm.getelementptr %84[%141] : (!llvm.ptr, i64) -> !llvm.ptr, f32
            %143 = llvm.load %142 : !llvm.ptr -> f32
            %144 = llvm.extractvalue %75[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %145 = llvm.getelementptr %144[%133] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %146 = llvm.load %145 : !llvm.ptr -> i64
            %147 = builtin.unrealized_conversion_cast %146 : i64 to index
            %148 = llvm.add %arg43, %65  : i64
            %149 = builtin.unrealized_conversion_cast %148 : i64 to index
            %150 = builtin.unrealized_conversion_cast %149 : index to i64
            %151 = llvm.extractvalue %75[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %152 = llvm.getelementptr %151[%150] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %153 = llvm.load %152 : !llvm.ptr -> i64
            %154 = builtin.unrealized_conversion_cast %153 : i64 to index
            llvm.store %143, %131 : f32, !llvm.ptr
            omp.parallel   {
              omp.wsloop   reduction(@__scf_reduction -> %131 : !llvm.ptr) for  (%arg44) : i64 = (%146) to (%153) step (%65) {
                %157 = builtin.unrealized_conversion_cast %arg44 : i64 to index
                %158 = builtin.unrealized_conversion_cast %157 : index to i64
                %159 = llvm.intr.stacksave : !llvm.ptr
                llvm.br ^bb1
              ^bb1:  // pred: ^bb0
                %160 = llvm.extractvalue %76[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %161 = llvm.getelementptr %160[%158] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                %162 = llvm.load %161 : !llvm.ptr -> i64
                %163 = llvm.extractvalue %77[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %164 = llvm.getelementptr %163[%158] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                %165 = llvm.load %164 : !llvm.ptr -> f32
                %166 = llvm.extractvalue %78[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %167 = llvm.getelementptr %166[%162] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                %168 = llvm.load %167 : !llvm.ptr -> f32
                %169 = llvm.fmul %165, %168  : f32
                omp.reduction %169, %131 : f32, !llvm.ptr
                llvm.intr.stackrestore %159 : !llvm.ptr
                llvm.br ^bb2
              ^bb2:  // pred: ^bb1
                omp.yield
              }
              omp.terminator
            }
            %155 = llvm.load %131 : !llvm.ptr -> f32
            %156 = llvm.getelementptr %84[%141] : (!llvm.ptr, i64) -> !llvm.ptr, f32
            llvm.store %155, %156 : f32, !llvm.ptr
            omp.yield
          }
          omp.terminator
        }
        omp.yield
      }
      omp.terminator
    }
    %111 = llvm.mlir.undef : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)>
    %112 = llvm.insertvalue %90, %111[0] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)> 
    %113 = llvm.insertvalue %102, %112[1] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)> 
    llvm.return %113 : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)>
  }
  llvm.func @_mlir_ciface_SpTVMul.Z.0.main(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr, %arg3: !llvm.ptr, %arg4: !llvm.ptr, %arg5: !llvm.ptr, %arg6: !llvm.ptr, %arg7: !llvm.ptr, %arg8: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg9: !llvm.ptr, %arg10: !llvm.struct<(array<1 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %5 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %6 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = llvm.extractvalue %6[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %8 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %9 = llvm.extractvalue %6[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %10 = llvm.extractvalue %6[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %11 = llvm.extractvalue %6[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %12 = llvm.load %arg3 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %13 = llvm.extractvalue %12[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.extractvalue %12[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.extractvalue %12[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.extractvalue %12[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.extractvalue %12[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.load %arg4 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %19 = llvm.extractvalue %18[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.extractvalue %18[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.extractvalue %18[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.extractvalue %18[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.extractvalue %18[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = llvm.load %arg5 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %25 = llvm.extractvalue %24[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %26 = llvm.extractvalue %24[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %27 = llvm.extractvalue %24[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %28 = llvm.extractvalue %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %29 = llvm.extractvalue %24[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.load %arg6 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %31 = llvm.extractvalue %30[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %32 = llvm.extractvalue %30[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.extractvalue %30[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = llvm.extractvalue %30[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %35 = llvm.extractvalue %30[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %36 = llvm.load %arg7 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %37 = llvm.extractvalue %36[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %38 = llvm.extractvalue %36[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %39 = llvm.extractvalue %36[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %40 = llvm.extractvalue %36[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %41 = llvm.extractvalue %36[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %42 = llvm.load %arg9 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %43 = llvm.extractvalue %42[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %44 = llvm.extractvalue %42[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %45 = llvm.extractvalue %42[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %46 = llvm.extractvalue %42[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %47 = llvm.extractvalue %42[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %48 = llvm.call @SpTVMul.Z.0.main(%1, %2, %3, %4, %5, %7, %8, %9, %10, %11, %13, %14, %15, %16, %17, %19, %20, %21, %22, %23, %25, %26, %27, %28, %29, %31, %32, %33, %34, %35, %37, %38, %39, %40, %41, %arg8, %43, %44, %45, %46, %47, %arg10) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.struct<(array<3 x i64>, array<7 x i64>)>, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.struct<(array<1 x i64>, array<1 x i64>)>) -> !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)>
    llvm.store %48, %arg0 : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)>, !llvm.ptr
    llvm.return
  }
}


// -----// IR Dump After ReconcileUnrealizedCasts (reconcile-unrealized-casts) //----- //
module attributes {llvm.data_layout = ""} {
  llvm.func @malloc(i64) -> !llvm.ptr
  omp.reduction.declare @__scf_reduction : f32 init {
  ^bb0(%arg0: f32):
    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    omp.yield(%0 : f32)
  } combiner {
  ^bb0(%arg0: f32, %arg1: f32):
    %0 = llvm.fadd %arg0, %arg1  : f32
    omp.yield(%0 : f32)
  } atomic {
  ^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr):
    %0 = llvm.load %arg1 : !llvm.ptr -> f32
    %1 = llvm.atomicrmw fadd %arg0, %0 monotonic : !llvm.ptr, f32
    omp.yield
  }
  llvm.func @SpTVMul.Z.0.main(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: !llvm.ptr, %arg6: !llvm.ptr, %arg7: i64, %arg8: i64, %arg9: i64, %arg10: !llvm.ptr, %arg11: !llvm.ptr, %arg12: i64, %arg13: i64, %arg14: i64, %arg15: !llvm.ptr, %arg16: !llvm.ptr, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: !llvm.ptr, %arg21: !llvm.ptr, %arg22: i64, %arg23: i64, %arg24: i64, %arg25: !llvm.ptr, %arg26: !llvm.ptr, %arg27: i64, %arg28: i64, %arg29: i64, %arg30: !llvm.ptr, %arg31: !llvm.ptr, %arg32: i64, %arg33: i64, %arg34: i64, %arg35: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg36: !llvm.ptr, %arg37: !llvm.ptr, %arg38: i64, %arg39: i64, %arg40: i64, %arg41: !llvm.struct<(array<1 x i64>, array<1 x i64>)>) -> !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)> attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = llvm.insertvalue %arg0, %0[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %2 = llvm.insertvalue %arg1, %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %3 = llvm.insertvalue %arg2, %2[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %4 = llvm.insertvalue %arg3, %3[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %5 = llvm.insertvalue %arg4, %4[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %6 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = llvm.insertvalue %arg5, %6[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %8 = llvm.insertvalue %arg6, %7[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %9 = llvm.insertvalue %arg7, %8[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %10 = llvm.insertvalue %arg8, %9[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %11 = llvm.insertvalue %arg9, %10[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %12 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %13 = llvm.insertvalue %arg10, %12[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.insertvalue %arg11, %13[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.insertvalue %arg12, %14[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.insertvalue %arg13, %15[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.insertvalue %arg14, %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %19 = llvm.insertvalue %arg15, %18[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.insertvalue %arg16, %19[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.insertvalue %arg17, %20[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %arg18, %21[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %arg19, %22[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %25 = llvm.insertvalue %arg20, %24[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %26 = llvm.insertvalue %arg21, %25[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %27 = llvm.insertvalue %arg22, %26[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %28 = llvm.insertvalue %arg23, %27[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %29 = llvm.insertvalue %arg24, %28[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %31 = llvm.insertvalue %arg25, %30[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %32 = llvm.insertvalue %arg26, %31[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.insertvalue %arg27, %32[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = llvm.insertvalue %arg28, %33[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %35 = llvm.insertvalue %arg29, %34[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %36 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %37 = llvm.insertvalue %arg30, %36[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %38 = llvm.insertvalue %arg31, %37[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %39 = llvm.insertvalue %arg32, %38[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %40 = llvm.insertvalue %arg33, %39[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %41 = llvm.insertvalue %arg34, %40[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %42 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %43 = llvm.insertvalue %arg36, %42[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %44 = llvm.insertvalue %arg37, %43[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %45 = llvm.insertvalue %arg38, %44[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %46 = llvm.insertvalue %arg39, %45[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %47 = llvm.insertvalue %arg40, %46[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %48 = llvm.mlir.constant(0 : index) : i64
    %49 = llvm.mlir.constant(1 : index) : i64
    %50 = llvm.mlir.constant(512 : index) : i64
    %51 = llvm.mlir.constant(32 : index) : i64
    %52 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %53 = llvm.mlir.constant(0 : i64) : i64
    %54 = llvm.mlir.constant(16 : i64) : i64
    %55 = llvm.mlir.constant(32 : i64) : i64
    %56 = llvm.mlir.constant(512 : i64) : i64
    %57 = llvm.mlir.constant(1 : index) : i64
    %58 = llvm.mlir.constant(512 : index) : i64
    %59 = llvm.mlir.constant(0 : index) : i64
    %60 = llvm.mlir.constant(1 : i64) : i64
    %61 = llvm.mlir.null : !llvm.ptr
    %62 = llvm.getelementptr %61[512] : (!llvm.ptr) -> !llvm.ptr, f32
    %63 = llvm.ptrtoint %62 : !llvm.ptr to i64
    %64 = llvm.call @malloc(%63) : (i64) -> !llvm.ptr
    %65 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %66 = llvm.insertvalue %64, %65[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %67 = llvm.insertvalue %64, %66[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %68 = llvm.insertvalue %48, %67[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %69 = llvm.insertvalue %50, %68[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %70 = llvm.insertvalue %49, %69[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %71 = llvm.mlir.undef : !llvm.struct<(array<2 x i64>, array<1 x i64>)>
    %72 = llvm.insertvalue %53, %71[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %73 = llvm.insertvalue %54, %72[0, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %74 = llvm.insertvalue %55, %73[0, 1] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    llvm.br ^bb1(%59 : i64)
  ^bb1(%75: i64):  // 2 preds: ^bb0, ^bb2
    %76 = llvm.icmp "slt" %75, %58 : i64
    llvm.cond_br %76, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %77 = llvm.getelementptr %64[%75] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %52, %77 : f32, !llvm.ptr
    %78 = llvm.add %75, %57  : i64
    llvm.br ^bb1(%78 : i64)
  ^bb3:  // pred: ^bb1
    %79 = llvm.insertvalue %56, %74[1, 0] : !llvm.struct<(array<2 x i64>, array<1 x i64>)> 
    %80 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %81 = llvm.getelementptr %80[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %82 = llvm.load %81 : !llvm.ptr -> i64
    %83 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %84 = llvm.getelementptr %83[%57] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %85 = llvm.load %84 : !llvm.ptr -> i64
    omp.parallel   {
      omp.wsloop   for  (%arg42) : i64 = (%82) to (%85) step (%57) {
        %89 = llvm.extractvalue %11[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %90 = llvm.getelementptr %89[%arg42] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %91 = llvm.load %90 : !llvm.ptr -> i64
        %92 = llvm.extractvalue %17[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %93 = llvm.getelementptr %92[%arg42] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %94 = llvm.load %93 : !llvm.ptr -> i64
        %95 = llvm.add %arg42, %57  : i64
        %96 = llvm.extractvalue %17[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %97 = llvm.getelementptr %96[%95] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %98 = llvm.load %97 : !llvm.ptr -> i64
        omp.parallel   {
          %99 = llvm.alloca %60 x f32 : (i64) -> !llvm.ptr
          omp.wsloop   for  (%arg43) : i64 = (%94) to (%98) step (%57) {
            %100 = llvm.extractvalue %23[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %101 = llvm.getelementptr %100[%arg43] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %102 = llvm.load %101 : !llvm.ptr -> i64
            %103 = llvm.mul %91, %51  : i64
            %104 = llvm.add %103, %102  : i64
            %105 = llvm.getelementptr %64[%104] : (!llvm.ptr, i64) -> !llvm.ptr, f32
            %106 = llvm.load %105 : !llvm.ptr -> f32
            %107 = llvm.extractvalue %29[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %108 = llvm.getelementptr %107[%arg43] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %109 = llvm.load %108 : !llvm.ptr -> i64
            %110 = llvm.add %arg43, %57  : i64
            %111 = llvm.extractvalue %29[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %112 = llvm.getelementptr %111[%110] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %113 = llvm.load %112 : !llvm.ptr -> i64
            llvm.store %106, %99 : f32, !llvm.ptr
            omp.parallel   {
              omp.wsloop   reduction(@__scf_reduction -> %99 : !llvm.ptr) for  (%arg44) : i64 = (%109) to (%113) step (%57) {
                %116 = llvm.intr.stacksave : !llvm.ptr
                llvm.br ^bb1
              ^bb1:  // pred: ^bb0
                %117 = llvm.extractvalue %35[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %118 = llvm.getelementptr %117[%arg44] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                %119 = llvm.load %118 : !llvm.ptr -> i64
                %120 = llvm.extractvalue %41[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %121 = llvm.getelementptr %120[%arg44] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                %122 = llvm.load %121 : !llvm.ptr -> f32
                %123 = llvm.extractvalue %47[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %124 = llvm.getelementptr %123[%119] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                %125 = llvm.load %124 : !llvm.ptr -> f32
                %126 = llvm.fmul %122, %125  : f32
                omp.reduction %126, %99 : f32, !llvm.ptr
                llvm.intr.stackrestore %116 : !llvm.ptr
                llvm.br ^bb2
              ^bb2:  // pred: ^bb1
                omp.yield
              }
              omp.terminator
            }
            %114 = llvm.load %99 : !llvm.ptr -> f32
            %115 = llvm.getelementptr %64[%104] : (!llvm.ptr, i64) -> !llvm.ptr, f32
            llvm.store %114, %115 : f32, !llvm.ptr
            omp.yield
          }
          omp.terminator
        }
        omp.yield
      }
      omp.terminator
    }
    %86 = llvm.mlir.undef : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)>
    %87 = llvm.insertvalue %70, %86[0] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)> 
    %88 = llvm.insertvalue %79, %87[1] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)> 
    llvm.return %88 : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)>
  }
  llvm.func @_mlir_ciface_SpTVMul.Z.0.main(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr, %arg3: !llvm.ptr, %arg4: !llvm.ptr, %arg5: !llvm.ptr, %arg6: !llvm.ptr, %arg7: !llvm.ptr, %arg8: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg9: !llvm.ptr, %arg10: !llvm.struct<(array<1 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %5 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %6 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = llvm.extractvalue %6[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %8 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %9 = llvm.extractvalue %6[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %10 = llvm.extractvalue %6[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %11 = llvm.extractvalue %6[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %12 = llvm.load %arg3 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %13 = llvm.extractvalue %12[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.extractvalue %12[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.extractvalue %12[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.extractvalue %12[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.extractvalue %12[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.load %arg4 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %19 = llvm.extractvalue %18[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.extractvalue %18[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.extractvalue %18[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.extractvalue %18[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.extractvalue %18[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = llvm.load %arg5 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %25 = llvm.extractvalue %24[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %26 = llvm.extractvalue %24[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %27 = llvm.extractvalue %24[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %28 = llvm.extractvalue %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %29 = llvm.extractvalue %24[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.load %arg6 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %31 = llvm.extractvalue %30[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %32 = llvm.extractvalue %30[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.extractvalue %30[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = llvm.extractvalue %30[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %35 = llvm.extractvalue %30[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %36 = llvm.load %arg7 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %37 = llvm.extractvalue %36[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %38 = llvm.extractvalue %36[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %39 = llvm.extractvalue %36[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %40 = llvm.extractvalue %36[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %41 = llvm.extractvalue %36[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %42 = llvm.load %arg9 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %43 = llvm.extractvalue %42[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %44 = llvm.extractvalue %42[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %45 = llvm.extractvalue %42[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %46 = llvm.extractvalue %42[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %47 = llvm.extractvalue %42[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %48 = llvm.call @SpTVMul.Z.0.main(%1, %2, %3, %4, %5, %7, %8, %9, %10, %11, %13, %14, %15, %16, %17, %19, %20, %21, %22, %23, %25, %26, %27, %28, %29, %31, %32, %33, %34, %35, %37, %38, %39, %40, %41, %arg8, %43, %44, %45, %46, %47, %arg10) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.struct<(array<3 x i64>, array<7 x i64>)>, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.struct<(array<1 x i64>, array<1 x i64>)>) -> !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)>
    llvm.store %48, %arg0 : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<1 x i64>)>)>, !llvm.ptr
    llvm.return
  }
}


