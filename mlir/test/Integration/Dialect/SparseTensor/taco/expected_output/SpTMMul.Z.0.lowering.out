// -----// IR Dump After LinalgGeneralization (linalg-generalize-named-ops) //----- //
func.func @SpTMMul.Z.0.main(%arg0: tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>>, %arg1: tensor<64x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>) -> tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>> attributes {llvm.emit_c_interface} {
  %0 = bufferization.alloc_tensor() : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
  %1 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%arg0, %arg1 : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>>, tensor<64x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>) outs(%0 : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %2 = arith.mulf %in, %in_0 : f32
    %3 = arith.addf %out, %2 : f32
    linalg.yield %3 : f32
  } -> tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
  return %1 : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
}

// -----// IR Dump After PreSparsificationRewrite (pre-sparsification-rewrite) //----- //
#map = affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>
module {
  func.func @SpTMMul.Z.0.main(%arg0: tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>>, %arg1: tensor<64x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>) -> tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>> attributes {llvm.emit_c_interface} {
    %0 = bufferization.alloc_tensor() : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
    %1 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%arg0, %arg1 : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>>, tensor<64x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>) outs(%0 : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %2 = arith.mulf %in, %in_0 : f32
      %3 = arith.addf %out, %2 : f32
      linalg.yield %3 : f32
    } -> tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
    return %1 : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
  }
}


// -----// IR Dump After EmptyTensorToAllocTensor (empty-tensor-to-alloc-tensor) //----- //
func.func @SpTMMul.Z.0.main(%arg0: tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>>, %arg1: tensor<64x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>) -> tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>> attributes {llvm.emit_c_interface} {
  %0 = bufferization.alloc_tensor() : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
  %1 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> (d0, d1, d3)>, affine_map<(d0, d1, d2, d3) -> (d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2)>], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%arg0, %arg1 : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>>, tensor<64x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>) outs(%0 : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %2 = arith.mulf %in, %in_0 : f32
    %3 = arith.addf %out, %2 : f32
    linalg.yield %3 : f32
  } -> tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
  return %1 : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
}

// -----// IR Dump After SparsificationPass (sparsification) //----- //
module {
  func.func @SpTMMul.Z.0.main(%arg0: tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>>, %arg1: tensor<64x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>) -> tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>> attributes {llvm.emit_c_interface} {
    %c64 = arith.constant 64 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = bufferization.alloc_tensor() {bufferization.escape = [true]} : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
    %1 = sparse_tensor.positions %arg0 {level = 0 : index} : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xindex>
    %2 = sparse_tensor.coordinates %arg0 {level = 0 : index} : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xindex>
    %3 = sparse_tensor.positions %arg0 {level = 1 : index} : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xindex>
    %4 = sparse_tensor.coordinates %arg0 {level = 1 : index} : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xindex>
    %5 = sparse_tensor.positions %arg0 {level = 2 : index} : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xindex>
    %6 = sparse_tensor.coordinates %arg0 {level = 2 : index} : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xindex>
    %7 = sparse_tensor.values %arg0 : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xf32>
    %8 = sparse_tensor.values %arg1 : tensor<64x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>> to memref<?xf32>
    %9 = sparse_tensor.values %0 : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>> to memref<?xf32>
    %10 = memref.load %1[%c0] : memref<?xindex>
    %11 = memref.load %1[%c1] : memref<?xindex>
    scf.parallel (%arg2) = (%10) to (%11) step (%c1) {
      %13 = memref.load %2[%arg2] : memref<?xindex>
      %14 = memref.load %3[%arg2] : memref<?xindex>
      %15 = arith.addi %arg2, %c1 : index
      %16 = memref.load %3[%15] : memref<?xindex>
      scf.parallel (%arg3) = (%14) to (%16) step (%c1) {
        %17 = memref.load %4[%arg3] : memref<?xindex>
        %18 = arith.muli %13, %c32 : index
        %19 = arith.addi %18, %17 : index
        scf.parallel (%arg4) = (%c0) to (%c64) step (%c1) {
          %20 = arith.muli %19, %c64 : index
          %21 = arith.addi %20, %arg4 : index
          %22 = memref.load %9[%21] : memref<?xf32>
          %23 = memref.load %5[%arg3] : memref<?xindex>
          %24 = arith.addi %arg3, %c1 : index
          %25 = memref.load %5[%24] : memref<?xindex>
          %26 = scf.parallel (%arg5) = (%23) to (%25) step (%c1) init (%22) -> f32 {
            %27 = memref.load %6[%arg5] : memref<?xindex>
            %28 = arith.muli %arg4, %c64 : index
            %29 = arith.addi %28, %27 : index
            %30 = memref.load %7[%arg5] : memref<?xf32>
            %31 = memref.load %8[%29] : memref<?xf32>
            %32 = arith.mulf %30, %31 : f32
            scf.reduce(%32)  : f32 {
            ^bb0(%arg6: f32, %arg7: f32):
              %33 = arith.addf %arg6, %arg7 : f32
              scf.reduce.return %33 : f32
            }
            scf.yield
          } {"Emitted from" = "linalg.generic"}
          memref.store %26, %9[%21] : memref<?xf32>
          scf.yield
        } {"Emitted from" = "linalg.generic"}
        scf.yield
      } {"Emitted from" = "linalg.generic"}
      scf.yield
    } {"Emitted from" = "linalg.generic"}
    %12 = sparse_tensor.load %0 : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
    return %12 : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
  }
}


// -----// IR Dump After PostSparsificationRewrite (post-sparsification-rewrite) //----- //
module {
  func.func @SpTMMul.Z.0.main(%arg0: tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>>, %arg1: tensor<64x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>) -> tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>> attributes {llvm.emit_c_interface} {
    %c64 = arith.constant 64 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %0 = bufferization.alloc_tensor() {bufferization.escape = [true]} : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
    %1 = sparse_tensor.positions %arg0 {level = 0 : index} : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xindex>
    %2 = sparse_tensor.coordinates %arg0 {level = 0 : index} : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xindex>
    %3 = sparse_tensor.positions %arg0 {level = 1 : index} : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xindex>
    %4 = sparse_tensor.coordinates %arg0 {level = 1 : index} : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xindex>
    %5 = sparse_tensor.positions %arg0 {level = 2 : index} : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xindex>
    %6 = sparse_tensor.coordinates %arg0 {level = 2 : index} : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xindex>
    %7 = sparse_tensor.values %arg0 : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>> to memref<?xf32>
    %8 = sparse_tensor.values %arg1 : tensor<64x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>> to memref<?xf32>
    %9 = sparse_tensor.values %0 : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>> to memref<?xf32>
    %10 = memref.load %1[%c0] : memref<?xindex>
    %11 = memref.load %1[%c1] : memref<?xindex>
    scf.parallel (%arg2) = (%10) to (%11) step (%c1) {
      %13 = memref.load %2[%arg2] : memref<?xindex>
      %14 = memref.load %3[%arg2] : memref<?xindex>
      %15 = arith.addi %arg2, %c1 : index
      %16 = memref.load %3[%15] : memref<?xindex>
      scf.parallel (%arg3) = (%14) to (%16) step (%c1) {
        %17 = memref.load %4[%arg3] : memref<?xindex>
        %18 = arith.muli %13, %c32 : index
        %19 = arith.addi %18, %17 : index
        scf.parallel (%arg4) = (%c0) to (%c64) step (%c1) {
          %20 = arith.muli %19, %c64 : index
          %21 = arith.addi %20, %arg4 : index
          %22 = memref.load %9[%21] : memref<?xf32>
          %23 = memref.load %5[%arg3] : memref<?xindex>
          %24 = arith.addi %arg3, %c1 : index
          %25 = memref.load %5[%24] : memref<?xindex>
          %26 = scf.parallel (%arg5) = (%23) to (%25) step (%c1) init (%22) -> f32 {
            %27 = memref.load %6[%arg5] : memref<?xindex>
            %28 = arith.muli %arg4, %c64 : index
            %29 = arith.addi %28, %27 : index
            %30 = memref.load %7[%arg5] : memref<?xf32>
            %31 = memref.load %8[%29] : memref<?xf32>
            %32 = arith.mulf %30, %31 : f32
            scf.reduce(%32)  : f32 {
            ^bb0(%arg6: f32, %arg7: f32):
              %33 = arith.addf %arg6, %arg7 : f32
              scf.reduce.return %33 : f32
            }
            scf.yield
          } {"Emitted from" = "linalg.generic"}
          memref.store %26, %9[%21] : memref<?xf32>
          scf.yield
        } {"Emitted from" = "linalg.generic"}
        scf.yield
      } {"Emitted from" = "linalg.generic"}
      scf.yield
    } {"Emitted from" = "linalg.generic"}
    %12 = sparse_tensor.load %0 : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
    return %12 : tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
  }
}


// -----// IR Dump After SparseTensorCodegen (sparse-tensor-codegen) //----- //
module {
  func.func @SpTMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>>, %arg8: memref<?xf32>, %arg9: !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>) -> (memref<?xf32>, !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>) attributes {llvm.emit_c_interface} {
    %c64 = arith.constant 64 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c16 = arith.constant 16 : index
    %c32_0 = arith.constant 32 : index
    %c64_1 = arith.constant 64 : index
    %0 = arith.muli %c16, %c32_0 : index
    %1 = arith.muli %0, %c64_1 : index
    %alloc = memref.alloc(%1) : memref<?xf32>
    %2 = sparse_tensor.storage_specifier.init : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
    %c0_2 = arith.constant 0 : index
    %3 = sparse_tensor.storage_specifier.set %2  lvl_sz at 0 with %c16 : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
    %4 = sparse_tensor.storage_specifier.set %3  lvl_sz at 1 with %c32_0 : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
    %5 = sparse_tensor.storage_specifier.set %4  lvl_sz at 2 with %c64_1 : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
    %c1_3 = arith.constant 1 : index
    %c16_4 = arith.constant 16 : index
    %6 = arith.muli %c1_3, %c16_4 : index
    %c32_5 = arith.constant 32 : index
    %7 = arith.muli %6, %c32_5 : index
    %c64_6 = arith.constant 64 : index
    %8 = arith.muli %7, %c64_6 : index
    %cst = arith.constant 0.000000e+00 : f32
    %9 = sparse_tensor.storage_specifier.get %5  val_mem_sz : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
    %outBuffer, %newSize = sparse_tensor.push_back %9, %alloc, %cst, %8 : index, memref<?xf32>, f32, index
    %10 = sparse_tensor.storage_specifier.set %5  val_mem_sz with %newSize : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
    %11 = builtin.unrealized_conversion_cast %outBuffer, %10 : memref<?xf32>, !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>> to tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
    %12 = memref.load %arg0[%c0] : memref<?xindex>
    %13 = memref.load %arg0[%c1] : memref<?xindex>
    scf.parallel (%arg10) = (%12) to (%13) step (%c1) {
      %15 = memref.load %arg1[%arg10] : memref<?xindex>
      %16 = memref.load %arg2[%arg10] : memref<?xindex>
      %17 = arith.addi %arg10, %c1 : index
      %18 = memref.load %arg2[%17] : memref<?xindex>
      scf.parallel (%arg11) = (%16) to (%18) step (%c1) {
        %19 = memref.load %arg3[%arg11] : memref<?xindex>
        %20 = arith.muli %15, %c32 : index
        %21 = arith.addi %20, %19 : index
        scf.parallel (%arg12) = (%c0) to (%c64) step (%c1) {
          %22 = arith.muli %21, %c64 : index
          %23 = arith.addi %22, %arg12 : index
          %24 = memref.load %outBuffer[%23] : memref<?xf32>
          %25 = memref.load %arg4[%arg11] : memref<?xindex>
          %26 = arith.addi %arg11, %c1 : index
          %27 = memref.load %arg4[%26] : memref<?xindex>
          %28 = scf.parallel (%arg13) = (%25) to (%27) step (%c1) init (%24) -> f32 {
            %29 = memref.load %arg5[%arg13] : memref<?xindex>
            %30 = arith.muli %arg12, %c64 : index
            %31 = arith.addi %30, %29 : index
            %32 = memref.load %arg6[%arg13] : memref<?xf32>
            %33 = memref.load %arg8[%31] : memref<?xf32>
            %34 = arith.mulf %32, %33 : f32
            scf.reduce(%34)  : f32 {
            ^bb0(%arg14: f32, %arg15: f32):
              %35 = arith.addf %arg14, %arg15 : f32
              scf.reduce.return %35 : f32
            }
            scf.yield
          } {"Emitted from" = "linalg.generic"}
          memref.store %28, %outBuffer[%23] : memref<?xf32>
          scf.yield
        } {"Emitted from" = "linalg.generic"}
        scf.yield
      } {"Emitted from" = "linalg.generic"}
      scf.yield
    } {"Emitted from" = "linalg.generic"}
    %14 = builtin.unrealized_conversion_cast %outBuffer, %10 : memref<?xf32>, !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>> to tensor<16x32x64xf32, #sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
    return %outBuffer, %10 : memref<?xf32>, !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
  }
}


// -----// IR Dump After SparseBufferRewrite (sparse-buffer-rewrite) //----- //
module {
  func.func @SpTMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "compressed", "compressed", "compressed" ] }>>, %arg8: memref<?xf32>, %arg9: !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense" ] }>>) -> (memref<?xf32>, !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>) attributes {llvm.emit_c_interface} {
    %c32768 = arith.constant 32768 : index
    %c16 = arith.constant 16 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c64 = arith.constant 64 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %alloc = memref.alloc(%c32768) : memref<?xf32>
    %0 = sparse_tensor.storage_specifier.init : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
    %1 = sparse_tensor.storage_specifier.set %0  lvl_sz at 0 with %c16 : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
    %2 = sparse_tensor.storage_specifier.set %1  lvl_sz at 1 with %c32 : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
    %3 = sparse_tensor.storage_specifier.set %2  lvl_sz at 2 with %c64 : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
    %4 = sparse_tensor.storage_specifier.get %3  val_mem_sz : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
    %5 = arith.addi %4, %c32768 : index
    %6 = arith.cmpi ugt, %5, %c32768 : index
    %7 = scf.if %6 -> (memref<?xf32>) {
      %11 = scf.while (%arg10 = %c32768) : (index) -> index {
        %13 = arith.muli %arg10, %c2 : index
        %14 = arith.cmpi ugt, %5, %13 : index
        scf.condition(%14) %13 : index
      } do {
      ^bb0(%arg10: index):
        scf.yield %arg10 : index
      }
      %12 = memref.realloc %alloc(%11) : memref<?xf32> to memref<?xf32>
      scf.yield %12 : memref<?xf32>
    } else {
      scf.yield %alloc : memref<?xf32>
    }
    %subview = memref.subview %7[%4] [%c32768] [%c1] : memref<?xf32> to memref<?xf32, strided<[?], offset: ?>>
    linalg.fill ins(%cst : f32) outs(%subview : memref<?xf32, strided<[?], offset: ?>>)
    %8 = sparse_tensor.storage_specifier.set %3  val_mem_sz with %5 : !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
    %9 = memref.load %arg0[%c0] : memref<?xindex>
    %10 = memref.load %arg0[%c1] : memref<?xindex>
    scf.parallel (%arg10) = (%9) to (%10) step (%c1) {
      %11 = memref.load %arg1[%arg10] : memref<?xindex>
      %12 = memref.load %arg2[%arg10] : memref<?xindex>
      %13 = arith.addi %arg10, %c1 : index
      %14 = memref.load %arg2[%13] : memref<?xindex>
      scf.parallel (%arg11) = (%12) to (%14) step (%c1) {
        %15 = memref.load %arg3[%arg11] : memref<?xindex>
        %16 = arith.muli %11, %c32 : index
        %17 = arith.addi %16, %15 : index
        scf.parallel (%arg12) = (%c0) to (%c64) step (%c1) {
          %18 = arith.muli %17, %c64 : index
          %19 = arith.addi %18, %arg12 : index
          %20 = memref.load %7[%19] : memref<?xf32>
          %21 = memref.load %arg4[%arg11] : memref<?xindex>
          %22 = arith.addi %arg11, %c1 : index
          %23 = memref.load %arg4[%22] : memref<?xindex>
          %24 = scf.parallel (%arg13) = (%21) to (%23) step (%c1) init (%20) -> f32 {
            %25 = memref.load %arg5[%arg13] : memref<?xindex>
            %26 = arith.muli %arg12, %c64 : index
            %27 = arith.addi %26, %25 : index
            %28 = memref.load %arg6[%arg13] : memref<?xf32>
            %29 = memref.load %arg8[%27] : memref<?xf32>
            %30 = arith.mulf %28, %29 : f32
            scf.reduce(%30)  : f32 {
            ^bb0(%arg14: f32, %arg15: f32):
              %31 = arith.addf %arg14, %arg15 : f32
              scf.reduce.return %31 : f32
            }
            scf.yield
          } {"Emitted from" = "linalg.generic"}
          memref.store %24, %7[%19] : memref<?xf32>
          scf.yield
        } {"Emitted from" = "linalg.generic"}
        scf.yield
      } {"Emitted from" = "linalg.generic"}
      scf.yield
    } {"Emitted from" = "linalg.generic"}
    return %7, %8 : memref<?xf32>, !sparse_tensor.storage_specifier<#sparse_tensor.encoding<{ lvlTypes = [ "dense", "dense", "dense" ] }>>
  }
}


// -----// IR Dump After StorageSpecifierToLLVM (sparse-storage-specifier-to-llvm) //----- //
module {
  func.func @SpTMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<2 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %c32768 = arith.constant 32768 : index
    %c16 = arith.constant 16 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c64 = arith.constant 64 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %alloc = memref.alloc(%c32768) : memref<?xf32>
    %0 = llvm.mlir.undef : !llvm.struct<(array<3 x i64>, array<1 x i64>)>
    %c0_i64 = arith.constant 0 : i64
    %1 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %2 = arith.index_cast %c16 : index to i64
    %3 = llvm.insertvalue %2, %1[0, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %4 = arith.index_cast %c32 : index to i64
    %5 = llvm.insertvalue %4, %3[0, 1] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %6 = arith.index_cast %c64 : index to i64
    %7 = llvm.insertvalue %6, %5[0, 2] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %8 = llvm.extractvalue %7[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %9 = arith.index_cast %8 : i64 to index
    %10 = arith.addi %9, %c32768 : index
    %11 = arith.cmpi ugt, %10, %c32768 : index
    %12 = scf.if %11 -> (memref<?xf32>) {
      %17 = scf.while (%arg10 = %c32768) : (index) -> index {
        %19 = arith.muli %arg10, %c2 : index
        %20 = arith.cmpi ugt, %10, %19 : index
        scf.condition(%20) %19 : index
      } do {
      ^bb0(%arg10: index):
        scf.yield %arg10 : index
      }
      %18 = memref.realloc %alloc(%17) : memref<?xf32> to memref<?xf32>
      scf.yield %18 : memref<?xf32>
    } else {
      scf.yield %alloc : memref<?xf32>
    }
    %subview = memref.subview %12[%9] [%c32768] [%c1] : memref<?xf32> to memref<?xf32, strided<[?], offset: ?>>
    linalg.fill ins(%cst : f32) outs(%subview : memref<?xf32, strided<[?], offset: ?>>)
    %13 = arith.index_cast %10 : index to i64
    %14 = llvm.insertvalue %13, %7[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %15 = memref.load %arg0[%c0] : memref<?xindex>
    %16 = memref.load %arg0[%c1] : memref<?xindex>
    scf.parallel (%arg10) = (%15) to (%16) step (%c1) {
      %17 = memref.load %arg1[%arg10] : memref<?xindex>
      %18 = memref.load %arg2[%arg10] : memref<?xindex>
      %19 = arith.addi %arg10, %c1 : index
      %20 = memref.load %arg2[%19] : memref<?xindex>
      scf.parallel (%arg11) = (%18) to (%20) step (%c1) {
        %21 = memref.load %arg3[%arg11] : memref<?xindex>
        %22 = arith.muli %17, %c32 : index
        %23 = arith.addi %22, %21 : index
        scf.parallel (%arg12) = (%c0) to (%c64) step (%c1) {
          %24 = arith.muli %23, %c64 : index
          %25 = arith.addi %24, %arg12 : index
          %26 = memref.load %12[%25] : memref<?xf32>
          %27 = memref.load %arg4[%arg11] : memref<?xindex>
          %28 = arith.addi %arg11, %c1 : index
          %29 = memref.load %arg4[%28] : memref<?xindex>
          %30 = scf.parallel (%arg13) = (%27) to (%29) step (%c1) init (%26) -> f32 {
            %31 = memref.load %arg5[%arg13] : memref<?xindex>
            %32 = arith.muli %arg12, %c64 : index
            %33 = arith.addi %32, %31 : index
            %34 = memref.load %arg6[%arg13] : memref<?xf32>
            %35 = memref.load %arg8[%33] : memref<?xf32>
            %36 = arith.mulf %34, %35 : f32
            scf.reduce(%36)  : f32 {
            ^bb0(%arg14: f32, %arg15: f32):
              %37 = arith.addf %arg14, %arg15 : f32
              scf.reduce.return %37 : f32
            }
            scf.yield
          } {"Emitted from" = "linalg.generic"}
          memref.store %30, %12[%25] : memref<?xf32>
          scf.yield
        } {"Emitted from" = "linalg.generic"}
        scf.yield
      } {"Emitted from" = "linalg.generic"}
      scf.yield
    } {"Emitted from" = "linalg.generic"}
    return %12, %14 : memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After mlir::sparse_tensor::SparsificationAndBufferizationPass () //----- //
module {
  func.func @SpTMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<2 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %c32768 = arith.constant 32768 : index
    %c16 = arith.constant 16 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c64 = arith.constant 64 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %alloc = memref.alloc(%c32768) : memref<?xf32>
    %0 = llvm.mlir.undef : !llvm.struct<(array<3 x i64>, array<1 x i64>)>
    %c0_i64 = arith.constant 0 : i64
    %1 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %2 = arith.index_cast %c16 : index to i64
    %3 = llvm.insertvalue %2, %1[0, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %4 = arith.index_cast %c32 : index to i64
    %5 = llvm.insertvalue %4, %3[0, 1] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %6 = arith.index_cast %c64 : index to i64
    %7 = llvm.insertvalue %6, %5[0, 2] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %8 = llvm.extractvalue %7[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %9 = arith.index_cast %8 : i64 to index
    %10 = arith.addi %9, %c32768 : index
    %11 = arith.cmpi ugt, %10, %c32768 : index
    %12 = scf.if %11 -> (memref<?xf32>) {
      %17 = scf.while (%arg10 = %c32768) : (index) -> index {
        %19 = arith.muli %arg10, %c2 : index
        %20 = arith.cmpi ugt, %10, %19 : index
        scf.condition(%20) %19 : index
      } do {
      ^bb0(%arg10: index):
        scf.yield %arg10 : index
      }
      %18 = memref.realloc %alloc(%17) : memref<?xf32> to memref<?xf32>
      scf.yield %18 : memref<?xf32>
    } else {
      scf.yield %alloc : memref<?xf32>
    }
    %subview = memref.subview %12[%9] [%c32768] [%c1] : memref<?xf32> to memref<?xf32, strided<[?], offset: ?>>
    linalg.fill ins(%cst : f32) outs(%subview : memref<?xf32, strided<[?], offset: ?>>)
    %13 = arith.index_cast %10 : index to i64
    %14 = llvm.insertvalue %13, %7[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %15 = memref.load %arg0[%c0] : memref<?xindex>
    %16 = memref.load %arg0[%c1] : memref<?xindex>
    scf.parallel (%arg10) = (%15) to (%16) step (%c1) {
      %17 = memref.load %arg1[%arg10] : memref<?xindex>
      %18 = memref.load %arg2[%arg10] : memref<?xindex>
      %19 = arith.addi %arg10, %c1 : index
      %20 = memref.load %arg2[%19] : memref<?xindex>
      scf.parallel (%arg11) = (%18) to (%20) step (%c1) {
        %21 = memref.load %arg3[%arg11] : memref<?xindex>
        %22 = arith.muli %17, %c32 : index
        %23 = arith.addi %22, %21 : index
        scf.parallel (%arg12) = (%c0) to (%c64) step (%c1) {
          %24 = arith.muli %23, %c64 : index
          %25 = arith.addi %24, %arg12 : index
          %26 = memref.load %12[%25] : memref<?xf32>
          %27 = memref.load %arg4[%arg11] : memref<?xindex>
          %28 = arith.addi %arg11, %c1 : index
          %29 = memref.load %arg4[%28] : memref<?xindex>
          %30 = scf.parallel (%arg13) = (%27) to (%29) step (%c1) init (%26) -> f32 {
            %31 = memref.load %arg5[%arg13] : memref<?xindex>
            %32 = arith.muli %arg12, %c64 : index
            %33 = arith.addi %32, %31 : index
            %34 = memref.load %arg6[%arg13] : memref<?xf32>
            %35 = memref.load %arg8[%33] : memref<?xf32>
            %36 = arith.mulf %34, %35 : f32
            scf.reduce(%36)  : f32 {
            ^bb0(%arg14: f32, %arg15: f32):
              %37 = arith.addf %arg14, %arg15 : f32
              scf.reduce.return %37 : f32
            }
            scf.yield
          } {"Emitted from" = "linalg.generic"}
          memref.store %30, %12[%25] : memref<?xf32>
          scf.yield
        } {"Emitted from" = "linalg.generic"}
        scf.yield
      } {"Emitted from" = "linalg.generic"}
      scf.yield
    } {"Emitted from" = "linalg.generic"}
    return %12, %14 : memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @SpTMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<2 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
  %c32768_i64 = arith.constant 32768 : i64
  %c0 = arith.constant 0 : index
  %c64_i64 = arith.constant 64 : i64
  %c32_i64 = arith.constant 32 : i64
  %c16_i64 = arith.constant 16 : i64
  %c0_i64 = arith.constant 0 : i64
  %c1 = arith.constant 1 : index
  %cst = arith.constant 0.000000e+00 : f32
  %c64 = arith.constant 64 : index
  %c32 = arith.constant 32 : index
  %alloc = memref.alloc() : memref<32768xf32>
  %cast = memref.cast %alloc : memref<32768xf32> to memref<?xf32>
  %0 = llvm.mlir.undef : !llvm.struct<(array<3 x i64>, array<1 x i64>)>
  %1 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %2 = llvm.insertvalue %c16_i64, %1[0, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %3 = llvm.insertvalue %c32_i64, %2[0, 1] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %4 = llvm.insertvalue %c64_i64, %3[0, 2] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  linalg.fill ins(%cst : f32) outs(%alloc : memref<32768xf32>)
  %5 = llvm.insertvalue %c32768_i64, %4[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %6 = memref.load %arg0[%c0] : memref<?xindex>
  %7 = memref.load %arg0[%c1] : memref<?xindex>
  scf.parallel (%arg10) = (%6) to (%7) step (%c1) {
    %8 = memref.load %arg1[%arg10] : memref<?xindex>
    %9 = memref.load %arg2[%arg10] : memref<?xindex>
    %10 = arith.addi %arg10, %c1 : index
    %11 = memref.load %arg2[%10] : memref<?xindex>
    scf.parallel (%arg11) = (%9) to (%11) step (%c1) {
      %12 = memref.load %arg3[%arg11] : memref<?xindex>
      %13 = arith.muli %8, %c32 : index
      %14 = arith.addi %13, %12 : index
      scf.parallel (%arg12) = (%c0) to (%c64) step (%c1) {
        %15 = arith.muli %14, %c64 : index
        %16 = arith.addi %15, %arg12 : index
        %17 = memref.load %alloc[%16] : memref<32768xf32>
        %18 = memref.load %arg4[%arg11] : memref<?xindex>
        %19 = arith.addi %arg11, %c1 : index
        %20 = memref.load %arg4[%19] : memref<?xindex>
        %21 = scf.parallel (%arg13) = (%18) to (%20) step (%c1) init (%17) -> f32 {
          %22 = memref.load %arg5[%arg13] : memref<?xindex>
          %23 = arith.muli %arg12, %c64 : index
          %24 = arith.addi %23, %22 : index
          %25 = memref.load %arg6[%arg13] : memref<?xf32>
          %26 = memref.load %arg8[%24] : memref<?xf32>
          %27 = arith.mulf %25, %26 : f32
          scf.reduce(%27)  : f32 {
          ^bb0(%arg14: f32, %arg15: f32):
            %28 = arith.addf %arg14, %arg15 : f32
            scf.reduce.return %28 : f32
          }
          scf.yield
        } {"Emitted from" = "linalg.generic"}
        memref.store %21, %alloc[%16] : memref<32768xf32>
        scf.yield
      } {"Emitted from" = "linalg.generic"}
      scf.yield
    } {"Emitted from" = "linalg.generic"}
    scf.yield
  } {"Emitted from" = "linalg.generic"}
  return %cast, %5 : memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>
}

// -----// IR Dump After FinalizingBufferize (finalizing-bufferize) //----- //
func.func @SpTMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<2 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
  %c32768_i64 = arith.constant 32768 : i64
  %c0 = arith.constant 0 : index
  %c64_i64 = arith.constant 64 : i64
  %c32_i64 = arith.constant 32 : i64
  %c16_i64 = arith.constant 16 : i64
  %c0_i64 = arith.constant 0 : i64
  %c1 = arith.constant 1 : index
  %cst = arith.constant 0.000000e+00 : f32
  %c64 = arith.constant 64 : index
  %c32 = arith.constant 32 : index
  %alloc = memref.alloc() : memref<32768xf32>
  %cast = memref.cast %alloc : memref<32768xf32> to memref<?xf32>
  %0 = llvm.mlir.undef : !llvm.struct<(array<3 x i64>, array<1 x i64>)>
  %1 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %2 = llvm.insertvalue %c16_i64, %1[0, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %3 = llvm.insertvalue %c32_i64, %2[0, 1] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %4 = llvm.insertvalue %c64_i64, %3[0, 2] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  linalg.fill ins(%cst : f32) outs(%alloc : memref<32768xf32>)
  %5 = llvm.insertvalue %c32768_i64, %4[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %6 = memref.load %arg0[%c0] : memref<?xindex>
  %7 = memref.load %arg0[%c1] : memref<?xindex>
  scf.parallel (%arg10) = (%6) to (%7) step (%c1) {
    %8 = memref.load %arg1[%arg10] : memref<?xindex>
    %9 = memref.load %arg2[%arg10] : memref<?xindex>
    %10 = arith.addi %arg10, %c1 : index
    %11 = memref.load %arg2[%10] : memref<?xindex>
    scf.parallel (%arg11) = (%9) to (%11) step (%c1) {
      %12 = memref.load %arg3[%arg11] : memref<?xindex>
      %13 = arith.muli %8, %c32 : index
      %14 = arith.addi %13, %12 : index
      scf.parallel (%arg12) = (%c0) to (%c64) step (%c1) {
        %15 = arith.muli %14, %c64 : index
        %16 = arith.addi %15, %arg12 : index
        %17 = memref.load %alloc[%16] : memref<32768xf32>
        %18 = memref.load %arg4[%arg11] : memref<?xindex>
        %19 = arith.addi %arg11, %c1 : index
        %20 = memref.load %arg4[%19] : memref<?xindex>
        %21 = scf.parallel (%arg13) = (%18) to (%20) step (%c1) init (%17) -> f32 {
          %22 = memref.load %arg5[%arg13] : memref<?xindex>
          %23 = arith.muli %arg12, %c64 : index
          %24 = arith.addi %23, %22 : index
          %25 = memref.load %arg6[%arg13] : memref<?xf32>
          %26 = memref.load %arg8[%24] : memref<?xf32>
          %27 = arith.mulf %25, %26 : f32
          scf.reduce(%27)  : f32 {
          ^bb0(%arg14: f32, %arg15: f32):
            %28 = arith.addf %arg14, %arg15 : f32
            scf.reduce.return %28 : f32
          }
          scf.yield
        } {"Emitted from" = "linalg.generic"}
        memref.store %21, %alloc[%16] : memref<32768xf32>
        scf.yield
      } {"Emitted from" = "linalg.generic"}
      scf.yield
    } {"Emitted from" = "linalg.generic"}
    scf.yield
  } {"Emitted from" = "linalg.generic"}
  return %cast, %5 : memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>
}

// -----// IR Dump After LinalgLowerToLoops (convert-linalg-to-loops) //----- //
func.func @SpTMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<2 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
  %c0 = arith.constant 0 : index
  %c32768 = arith.constant 32768 : index
  %c1 = arith.constant 1 : index
  %c32768_i64 = arith.constant 32768 : i64
  %c64_i64 = arith.constant 64 : i64
  %c32_i64 = arith.constant 32 : i64
  %c16_i64 = arith.constant 16 : i64
  %c0_i64 = arith.constant 0 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %c64 = arith.constant 64 : index
  %c32 = arith.constant 32 : index
  %alloc = memref.alloc() : memref<32768xf32>
  %cast = memref.cast %alloc : memref<32768xf32> to memref<?xf32>
  %0 = llvm.mlir.undef : !llvm.struct<(array<3 x i64>, array<1 x i64>)>
  %1 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %2 = llvm.insertvalue %c16_i64, %1[0, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %3 = llvm.insertvalue %c32_i64, %2[0, 1] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %4 = llvm.insertvalue %c64_i64, %3[0, 2] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  scf.for %arg10 = %c0 to %c32768 step %c1 {
    memref.store %cst, %alloc[%arg10] : memref<32768xf32>
  }
  %5 = llvm.insertvalue %c32768_i64, %4[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %6 = memref.load %arg0[%c0] : memref<?xindex>
  %7 = memref.load %arg0[%c1] : memref<?xindex>
  scf.parallel (%arg10) = (%6) to (%7) step (%c1) {
    %8 = memref.load %arg1[%arg10] : memref<?xindex>
    %9 = memref.load %arg2[%arg10] : memref<?xindex>
    %10 = arith.addi %arg10, %c1 : index
    %11 = memref.load %arg2[%10] : memref<?xindex>
    scf.parallel (%arg11) = (%9) to (%11) step (%c1) {
      %12 = memref.load %arg3[%arg11] : memref<?xindex>
      %13 = arith.muli %8, %c32 : index
      %14 = arith.addi %13, %12 : index
      scf.parallel (%arg12) = (%c0) to (%c64) step (%c1) {
        %15 = arith.muli %14, %c64 : index
        %16 = arith.addi %15, %arg12 : index
        %17 = memref.load %alloc[%16] : memref<32768xf32>
        %18 = memref.load %arg4[%arg11] : memref<?xindex>
        %19 = arith.addi %arg11, %c1 : index
        %20 = memref.load %arg4[%19] : memref<?xindex>
        %21 = scf.parallel (%arg13) = (%18) to (%20) step (%c1) init (%17) -> f32 {
          %22 = memref.load %arg5[%arg13] : memref<?xindex>
          %23 = arith.muli %arg12, %c64 : index
          %24 = arith.addi %23, %22 : index
          %25 = memref.load %arg6[%arg13] : memref<?xf32>
          %26 = memref.load %arg8[%24] : memref<?xf32>
          %27 = arith.mulf %25, %26 : f32
          scf.reduce(%27)  : f32 {
          ^bb0(%arg14: f32, %arg15: f32):
            %28 = arith.addf %arg14, %arg15 : f32
            scf.reduce.return %28 : f32
          }
          scf.yield
        } {"Emitted from" = "linalg.generic"}
        memref.store %21, %alloc[%16] : memref<32768xf32>
        scf.yield
      } {"Emitted from" = "linalg.generic"}
      scf.yield
    } {"Emitted from" = "linalg.generic"}
    scf.yield
  } {"Emitted from" = "linalg.generic"}
  return %cast, %5 : memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>
}

// -----// IR Dump After ConvertVectorToSCF (convert-vector-to-scf) //----- //
func.func @SpTMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<2 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
  %c0 = arith.constant 0 : index
  %c32768 = arith.constant 32768 : index
  %c1 = arith.constant 1 : index
  %c32768_i64 = arith.constant 32768 : i64
  %c64_i64 = arith.constant 64 : i64
  %c32_i64 = arith.constant 32 : i64
  %c16_i64 = arith.constant 16 : i64
  %c0_i64 = arith.constant 0 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %c64 = arith.constant 64 : index
  %c32 = arith.constant 32 : index
  %alloc = memref.alloc() : memref<32768xf32>
  %cast = memref.cast %alloc : memref<32768xf32> to memref<?xf32>
  %0 = llvm.mlir.undef : !llvm.struct<(array<3 x i64>, array<1 x i64>)>
  %1 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %2 = llvm.insertvalue %c16_i64, %1[0, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %3 = llvm.insertvalue %c32_i64, %2[0, 1] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %4 = llvm.insertvalue %c64_i64, %3[0, 2] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  scf.for %arg10 = %c0 to %c32768 step %c1 {
    memref.store %cst, %alloc[%arg10] : memref<32768xf32>
  }
  %5 = llvm.insertvalue %c32768_i64, %4[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %6 = memref.load %arg0[%c0] : memref<?xindex>
  %7 = memref.load %arg0[%c1] : memref<?xindex>
  scf.parallel (%arg10) = (%6) to (%7) step (%c1) {
    %8 = memref.load %arg1[%arg10] : memref<?xindex>
    %9 = memref.load %arg2[%arg10] : memref<?xindex>
    %10 = arith.addi %arg10, %c1 : index
    %11 = memref.load %arg2[%10] : memref<?xindex>
    scf.parallel (%arg11) = (%9) to (%11) step (%c1) {
      %12 = memref.load %arg3[%arg11] : memref<?xindex>
      %13 = arith.muli %8, %c32 : index
      %14 = arith.addi %13, %12 : index
      scf.parallel (%arg12) = (%c0) to (%c64) step (%c1) {
        %15 = arith.muli %14, %c64 : index
        %16 = arith.addi %15, %arg12 : index
        %17 = memref.load %alloc[%16] : memref<32768xf32>
        %18 = memref.load %arg4[%arg11] : memref<?xindex>
        %19 = arith.addi %arg11, %c1 : index
        %20 = memref.load %arg4[%19] : memref<?xindex>
        %21 = scf.parallel (%arg13) = (%18) to (%20) step (%c1) init (%17) -> f32 {
          %22 = memref.load %arg5[%arg13] : memref<?xindex>
          %23 = arith.muli %arg12, %c64 : index
          %24 = arith.addi %23, %22 : index
          %25 = memref.load %arg6[%arg13] : memref<?xf32>
          %26 = memref.load %arg8[%24] : memref<?xf32>
          %27 = arith.mulf %25, %26 : f32
          scf.reduce(%27)  : f32 {
          ^bb0(%arg14: f32, %arg15: f32):
            %28 = arith.addf %arg14, %arg15 : f32
            scf.reduce.return %28 : f32
          }
          scf.yield
        } {"Emitted from" = "linalg.generic"}
        memref.store %21, %alloc[%16] : memref<32768xf32>
        scf.yield
      } {"Emitted from" = "linalg.generic"}
      scf.yield
    } {"Emitted from" = "linalg.generic"}
    scf.yield
  } {"Emitted from" = "linalg.generic"}
  return %cast, %5 : memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>
}

// -----// IR Dump After ConvertSCFToOpenMPPass (convert-scf-to-openmp) //----- //
module {
  omp.reduction.declare @__scf_reduction : f32 init {
  ^bb0(%arg0: f32):
    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    omp.yield(%0 : f32)
  } combiner {
  ^bb0(%arg0: f32, %arg1: f32):
    %0 = arith.addf %arg0, %arg1 : f32
    omp.yield(%0 : f32)
  } atomic {
  ^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr):
    %0 = llvm.load %arg1 : !llvm.ptr -> f32
    %1 = llvm.atomicrmw fadd %arg0, %0 monotonic : !llvm.ptr, f32
    omp.yield
  }
  func.func @SpTMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<2 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %c0 = arith.constant 0 : index
    %c32768 = arith.constant 32768 : index
    %c1 = arith.constant 1 : index
    %c32768_i64 = arith.constant 32768 : i64
    %c64_i64 = arith.constant 64 : i64
    %c32_i64 = arith.constant 32 : i64
    %c16_i64 = arith.constant 16 : i64
    %c0_i64 = arith.constant 0 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %c64 = arith.constant 64 : index
    %c32 = arith.constant 32 : index
    %alloc = memref.alloc() : memref<32768xf32>
    %cast = memref.cast %alloc : memref<32768xf32> to memref<?xf32>
    %0 = llvm.mlir.undef : !llvm.struct<(array<3 x i64>, array<1 x i64>)>
    %1 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %2 = llvm.insertvalue %c16_i64, %1[0, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %3 = llvm.insertvalue %c32_i64, %2[0, 1] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %4 = llvm.insertvalue %c64_i64, %3[0, 2] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    scf.for %arg10 = %c0 to %c32768 step %c1 {
      memref.store %cst, %alloc[%arg10] : memref<32768xf32>
    }
    %5 = llvm.insertvalue %c32768_i64, %4[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %6 = memref.load %arg0[%c0] : memref<?xindex>
    %7 = memref.load %arg0[%c1] : memref<?xindex>
    %8 = llvm.mlir.constant(1 : i64) : i64
    omp.parallel   {
      omp.wsloop   for  (%arg10) : index = (%6) to (%7) step (%c1) {
        memref.alloca_scope  {
          %9 = memref.load %arg1[%arg10] : memref<?xindex>
          %10 = memref.load %arg2[%arg10] : memref<?xindex>
          %11 = arith.addi %arg10, %c1 : index
          %12 = memref.load %arg2[%11] : memref<?xindex>
          %13 = llvm.mlir.constant(1 : i64) : i64
          omp.parallel   {
            omp.wsloop   for  (%arg11) : index = (%10) to (%12) step (%c1) {
              memref.alloca_scope  {
                %14 = memref.load %arg3[%arg11] : memref<?xindex>
                %15 = arith.muli %9, %c32 : index
                %16 = arith.addi %15, %14 : index
                %17 = llvm.mlir.constant(1 : i64) : i64
                omp.parallel   {
                  omp.wsloop   for  (%arg12) : index = (%c0) to (%c64) step (%c1) {
                    memref.alloca_scope  {
                      %18 = arith.muli %16, %c64 : index
                      %19 = arith.addi %18, %arg12 : index
                      %20 = memref.load %alloc[%19] : memref<32768xf32>
                      %21 = memref.load %arg4[%arg11] : memref<?xindex>
                      %22 = arith.addi %arg11, %c1 : index
                      %23 = memref.load %arg4[%22] : memref<?xindex>
                      %24 = llvm.mlir.constant(1 : i64) : i64
                      %25 = llvm.alloca %24 x f32 : (i64) -> !llvm.ptr
                      llvm.store %20, %25 : f32, !llvm.ptr
                      omp.parallel   {
                        omp.wsloop   reduction(@__scf_reduction -> %25 : !llvm.ptr) for  (%arg13) : index = (%21) to (%23) step (%c1) {
                          memref.alloca_scope  {
                            %27 = memref.load %arg5[%arg13] : memref<?xindex>
                            %28 = arith.muli %arg12, %c64 : index
                            %29 = arith.addi %28, %27 : index
                            %30 = memref.load %arg6[%arg13] : memref<?xf32>
                            %31 = memref.load %arg8[%29] : memref<?xf32>
                            %32 = arith.mulf %30, %31 : f32
                            omp.reduction %32, %25 : f32, !llvm.ptr
                          }
                          omp.yield
                        }
                        omp.terminator
                      }
                      %26 = llvm.load %25 : !llvm.ptr -> f32
                      memref.store %26, %alloc[%19] : memref<32768xf32>
                    }
                    omp.yield
                  }
                  omp.terminator
                }
              }
              omp.yield
            }
            omp.terminator
          }
        }
        omp.yield
      }
      omp.terminator
    }
    return %cast, %5 : memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @SpTMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<2 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
  %0 = llvm.mlir.constant(1 : i64) : i64
  %c0 = arith.constant 0 : index
  %c32768 = arith.constant 32768 : index
  %c1 = arith.constant 1 : index
  %c32768_i64 = arith.constant 32768 : i64
  %c64_i64 = arith.constant 64 : i64
  %c32_i64 = arith.constant 32 : i64
  %c16_i64 = arith.constant 16 : i64
  %c0_i64 = arith.constant 0 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %c64 = arith.constant 64 : index
  %c32 = arith.constant 32 : index
  %alloc = memref.alloc() : memref<32768xf32>
  %cast = memref.cast %alloc : memref<32768xf32> to memref<?xf32>
  %1 = llvm.mlir.undef : !llvm.struct<(array<3 x i64>, array<1 x i64>)>
  %2 = llvm.insertvalue %c0_i64, %1[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %3 = llvm.insertvalue %c16_i64, %2[0, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %4 = llvm.insertvalue %c32_i64, %3[0, 1] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %5 = llvm.insertvalue %c64_i64, %4[0, 2] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  scf.for %arg10 = %c0 to %c32768 step %c1 {
    memref.store %cst, %alloc[%arg10] : memref<32768xf32>
  }
  %6 = llvm.insertvalue %c32768_i64, %5[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %7 = memref.load %arg0[%c0] : memref<?xindex>
  %8 = memref.load %arg0[%c1] : memref<?xindex>
  omp.parallel   {
    omp.wsloop   for  (%arg10) : index = (%7) to (%8) step (%c1) {
      %9 = memref.load %arg1[%arg10] : memref<?xindex>
      %10 = memref.load %arg2[%arg10] : memref<?xindex>
      %11 = arith.addi %arg10, %c1 : index
      %12 = memref.load %arg2[%11] : memref<?xindex>
      omp.parallel   {
        omp.wsloop   for  (%arg11) : index = (%10) to (%12) step (%c1) {
          %13 = memref.load %arg3[%arg11] : memref<?xindex>
          %14 = arith.muli %9, %c32 : index
          %15 = arith.addi %14, %13 : index
          omp.parallel   {
            %16 = llvm.alloca %0 x f32 : (i64) -> !llvm.ptr
            omp.wsloop   for  (%arg12) : index = (%c0) to (%c64) step (%c1) {
              %17 = arith.muli %15, %c64 : index
              %18 = arith.addi %17, %arg12 : index
              %19 = memref.load %alloc[%18] : memref<32768xf32>
              %20 = memref.load %arg4[%arg11] : memref<?xindex>
              %21 = arith.addi %arg11, %c1 : index
              %22 = memref.load %arg4[%21] : memref<?xindex>
              llvm.store %19, %16 : f32, !llvm.ptr
              omp.parallel   {
                omp.wsloop   reduction(@__scf_reduction -> %16 : !llvm.ptr) for  (%arg13) : index = (%20) to (%22) step (%c1) {
                  memref.alloca_scope  {
                    %24 = memref.load %arg5[%arg13] : memref<?xindex>
                    %25 = arith.muli %arg12, %c64 : index
                    %26 = arith.addi %25, %24 : index
                    %27 = memref.load %arg6[%arg13] : memref<?xf32>
                    %28 = memref.load %arg8[%26] : memref<?xf32>
                    %29 = arith.mulf %27, %28 : f32
                    omp.reduction %29, %16 : f32, !llvm.ptr
                  }
                  omp.yield
                }
                omp.terminator
              }
              %23 = llvm.load %16 : !llvm.ptr -> f32
              memref.store %23, %alloc[%18] : memref<32768xf32>
              omp.yield
            }
            omp.terminator
          }
          omp.yield
        }
        omp.terminator
      }
      omp.yield
    }
    omp.terminator
  }
  return %cast, %6 : memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
func.func @SpTMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<2 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
  %0 = llvm.mlir.constant(1 : i64) : i64
  %c0 = arith.constant 0 : index
  %c32768 = arith.constant 32768 : index
  %c1 = arith.constant 1 : index
  %c32768_i64 = arith.constant 32768 : i64
  %c64_i64 = arith.constant 64 : i64
  %c32_i64 = arith.constant 32 : i64
  %c16_i64 = arith.constant 16 : i64
  %c0_i64 = arith.constant 0 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %c64 = arith.constant 64 : index
  %c32 = arith.constant 32 : index
  %alloc = memref.alloc() : memref<32768xf32>
  %cast = memref.cast %alloc : memref<32768xf32> to memref<?xf32>
  %1 = llvm.mlir.undef : !llvm.struct<(array<3 x i64>, array<1 x i64>)>
  %2 = llvm.insertvalue %c0_i64, %1[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %3 = llvm.insertvalue %c16_i64, %2[0, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %4 = llvm.insertvalue %c32_i64, %3[0, 1] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %5 = llvm.insertvalue %c64_i64, %4[0, 2] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  cf.br ^bb1(%c0 : index)
^bb1(%6: index):  // 2 preds: ^bb0, ^bb2
  %7 = arith.cmpi slt, %6, %c32768 : index
  cf.cond_br %7, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  memref.store %cst, %alloc[%6] : memref<32768xf32>
  %8 = arith.addi %6, %c1 : index
  cf.br ^bb1(%8 : index)
^bb3:  // pred: ^bb1
  %9 = llvm.insertvalue %c32768_i64, %5[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %10 = memref.load %arg0[%c0] : memref<?xindex>
  %11 = memref.load %arg0[%c1] : memref<?xindex>
  omp.parallel   {
    omp.wsloop   for  (%arg10) : index = (%10) to (%11) step (%c1) {
      %12 = memref.load %arg1[%arg10] : memref<?xindex>
      %13 = memref.load %arg2[%arg10] : memref<?xindex>
      %14 = arith.addi %arg10, %c1 : index
      %15 = memref.load %arg2[%14] : memref<?xindex>
      omp.parallel   {
        omp.wsloop   for  (%arg11) : index = (%13) to (%15) step (%c1) {
          %16 = memref.load %arg3[%arg11] : memref<?xindex>
          %17 = arith.muli %12, %c32 : index
          %18 = arith.addi %17, %16 : index
          omp.parallel   {
            %19 = llvm.alloca %0 x f32 : (i64) -> !llvm.ptr
            omp.wsloop   for  (%arg12) : index = (%c0) to (%c64) step (%c1) {
              %20 = arith.muli %18, %c64 : index
              %21 = arith.addi %20, %arg12 : index
              %22 = memref.load %alloc[%21] : memref<32768xf32>
              %23 = memref.load %arg4[%arg11] : memref<?xindex>
              %24 = arith.addi %arg11, %c1 : index
              %25 = memref.load %arg4[%24] : memref<?xindex>
              llvm.store %22, %19 : f32, !llvm.ptr
              omp.parallel   {
                omp.wsloop   reduction(@__scf_reduction -> %19 : !llvm.ptr) for  (%arg13) : index = (%23) to (%25) step (%c1) {
                  memref.alloca_scope  {
                    %27 = memref.load %arg5[%arg13] : memref<?xindex>
                    %28 = arith.muli %arg12, %c64 : index
                    %29 = arith.addi %28, %27 : index
                    %30 = memref.load %arg6[%arg13] : memref<?xf32>
                    %31 = memref.load %arg8[%29] : memref<?xf32>
                    %32 = arith.mulf %30, %31 : f32
                    omp.reduction %32, %19 : f32, !llvm.ptr
                  }
                  omp.yield
                }
                omp.terminator
              }
              %26 = llvm.load %19 : !llvm.ptr -> f32
              memref.store %26, %alloc[%21] : memref<32768xf32>
              omp.yield
            }
            omp.terminator
          }
          omp.yield
        }
        omp.terminator
      }
      omp.yield
    }
    omp.terminator
  }
  return %cast, %9 : memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>
}

// -----// IR Dump After ExpandStridedMetadata (expand-strided-metadata) //----- //
module {
  omp.reduction.declare @__scf_reduction : f32 init {
  ^bb0(%arg0: f32):
    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    omp.yield(%0 : f32)
  } combiner {
  ^bb0(%arg0: f32, %arg1: f32):
    %0 = arith.addf %arg0, %arg1 : f32
    omp.yield(%0 : f32)
  } atomic {
  ^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr):
    %0 = llvm.load %arg1 : !llvm.ptr -> f32
    %1 = llvm.atomicrmw fadd %arg0, %0 monotonic : !llvm.ptr, f32
    omp.yield
  }
  func.func @SpTMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<2 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(1 : i64) : i64
    %c0 = arith.constant 0 : index
    %c32768 = arith.constant 32768 : index
    %c1 = arith.constant 1 : index
    %c32768_i64 = arith.constant 32768 : i64
    %c64_i64 = arith.constant 64 : i64
    %c32_i64 = arith.constant 32 : i64
    %c16_i64 = arith.constant 16 : i64
    %c0_i64 = arith.constant 0 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %c64 = arith.constant 64 : index
    %c32 = arith.constant 32 : index
    %alloc = memref.alloc() : memref<32768xf32>
    %cast = memref.cast %alloc : memref<32768xf32> to memref<?xf32>
    %1 = llvm.mlir.undef : !llvm.struct<(array<3 x i64>, array<1 x i64>)>
    %2 = llvm.insertvalue %c0_i64, %1[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %3 = llvm.insertvalue %c16_i64, %2[0, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %4 = llvm.insertvalue %c32_i64, %3[0, 1] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %5 = llvm.insertvalue %c64_i64, %4[0, 2] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%6: index):  // 2 preds: ^bb0, ^bb2
    %7 = arith.cmpi slt, %6, %c32768 : index
    cf.cond_br %7, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    memref.store %cst, %alloc[%6] : memref<32768xf32>
    %8 = arith.addi %6, %c1 : index
    cf.br ^bb1(%8 : index)
  ^bb3:  // pred: ^bb1
    %9 = llvm.insertvalue %c32768_i64, %5[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %10 = memref.load %arg0[%c0] : memref<?xindex>
    %11 = memref.load %arg0[%c1] : memref<?xindex>
    omp.parallel   {
      omp.wsloop   for  (%arg10) : index = (%10) to (%11) step (%c1) {
        %12 = memref.load %arg1[%arg10] : memref<?xindex>
        %13 = memref.load %arg2[%arg10] : memref<?xindex>
        %14 = arith.addi %arg10, %c1 : index
        %15 = memref.load %arg2[%14] : memref<?xindex>
        omp.parallel   {
          omp.wsloop   for  (%arg11) : index = (%13) to (%15) step (%c1) {
            %16 = memref.load %arg3[%arg11] : memref<?xindex>
            %17 = arith.muli %12, %c32 : index
            %18 = arith.addi %17, %16 : index
            omp.parallel   {
              %19 = llvm.alloca %0 x f32 : (i64) -> !llvm.ptr
              omp.wsloop   for  (%arg12) : index = (%c0) to (%c64) step (%c1) {
                %20 = arith.muli %18, %c64 : index
                %21 = arith.addi %20, %arg12 : index
                %22 = memref.load %alloc[%21] : memref<32768xf32>
                %23 = memref.load %arg4[%arg11] : memref<?xindex>
                %24 = arith.addi %arg11, %c1 : index
                %25 = memref.load %arg4[%24] : memref<?xindex>
                llvm.store %22, %19 : f32, !llvm.ptr
                omp.parallel   {
                  omp.wsloop   reduction(@__scf_reduction -> %19 : !llvm.ptr) for  (%arg13) : index = (%23) to (%25) step (%c1) {
                    memref.alloca_scope  {
                      %27 = memref.load %arg5[%arg13] : memref<?xindex>
                      %28 = arith.muli %arg12, %c64 : index
                      %29 = arith.addi %28, %27 : index
                      %30 = memref.load %arg6[%arg13] : memref<?xf32>
                      %31 = memref.load %arg8[%29] : memref<?xf32>
                      %32 = arith.mulf %30, %31 : f32
                      omp.reduction %32, %19 : f32, !llvm.ptr
                    }
                    omp.yield
                  }
                  omp.terminator
                }
                %26 = llvm.load %19 : !llvm.ptr -> f32
                memref.store %26, %alloc[%21] : memref<32768xf32>
                omp.yield
              }
              omp.terminator
            }
            omp.yield
          }
          omp.terminator
        }
        omp.yield
      }
      omp.terminator
    }
    return %cast, %9 : memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
module {
  omp.reduction.declare @__scf_reduction : f32 init {
  ^bb0(%arg0: f32):
    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    omp.yield(%0 : f32)
  } combiner {
  ^bb0(%arg0: f32, %arg1: f32):
    %0 = arith.addf %arg0, %arg1 : f32
    omp.yield(%0 : f32)
  } atomic {
  ^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr):
    %0 = llvm.load %arg1 : !llvm.ptr -> f32
    %1 = llvm.atomicrmw fadd %arg0, %0 monotonic : !llvm.ptr, f32
    omp.yield
  }
  func.func @SpTMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<2 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(1 : i64) : i64
    %c0 = arith.constant 0 : index
    %c32768 = arith.constant 32768 : index
    %c1 = arith.constant 1 : index
    %c32768_i64 = arith.constant 32768 : i64
    %c64_i64 = arith.constant 64 : i64
    %c32_i64 = arith.constant 32 : i64
    %c16_i64 = arith.constant 16 : i64
    %c0_i64 = arith.constant 0 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %c64 = arith.constant 64 : index
    %c32 = arith.constant 32 : index
    %alloc = memref.alloc() : memref<32768xf32>
    %cast = memref.cast %alloc : memref<32768xf32> to memref<?xf32>
    %1 = llvm.mlir.undef : !llvm.struct<(array<3 x i64>, array<1 x i64>)>
    %2 = llvm.insertvalue %c0_i64, %1[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %3 = llvm.insertvalue %c16_i64, %2[0, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %4 = llvm.insertvalue %c32_i64, %3[0, 1] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %5 = llvm.insertvalue %c64_i64, %4[0, 2] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%6: index):  // 2 preds: ^bb0, ^bb2
    %7 = arith.cmpi slt, %6, %c32768 : index
    cf.cond_br %7, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    memref.store %cst, %alloc[%6] : memref<32768xf32>
    %8 = arith.addi %6, %c1 : index
    cf.br ^bb1(%8 : index)
  ^bb3:  // pred: ^bb1
    %9 = llvm.insertvalue %c32768_i64, %5[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %10 = memref.load %arg0[%c0] : memref<?xindex>
    %11 = memref.load %arg0[%c1] : memref<?xindex>
    omp.parallel   {
      omp.wsloop   for  (%arg10) : index = (%10) to (%11) step (%c1) {
        %12 = memref.load %arg1[%arg10] : memref<?xindex>
        %13 = memref.load %arg2[%arg10] : memref<?xindex>
        %14 = arith.addi %arg10, %c1 : index
        %15 = memref.load %arg2[%14] : memref<?xindex>
        omp.parallel   {
          omp.wsloop   for  (%arg11) : index = (%13) to (%15) step (%c1) {
            %16 = memref.load %arg3[%arg11] : memref<?xindex>
            %17 = arith.muli %12, %c32 : index
            %18 = arith.addi %17, %16 : index
            omp.parallel   {
              %19 = llvm.alloca %0 x f32 : (i64) -> !llvm.ptr
              omp.wsloop   for  (%arg12) : index = (%c0) to (%c64) step (%c1) {
                %20 = arith.muli %18, %c64 : index
                %21 = arith.addi %20, %arg12 : index
                %22 = memref.load %alloc[%21] : memref<32768xf32>
                %23 = memref.load %arg4[%arg11] : memref<?xindex>
                %24 = arith.addi %arg11, %c1 : index
                %25 = memref.load %arg4[%24] : memref<?xindex>
                llvm.store %22, %19 : f32, !llvm.ptr
                omp.parallel   {
                  omp.wsloop   reduction(@__scf_reduction -> %19 : !llvm.ptr) for  (%arg13) : index = (%23) to (%25) step (%c1) {
                    memref.alloca_scope  {
                      %27 = memref.load %arg5[%arg13] : memref<?xindex>
                      %28 = arith.muli %arg12, %c64 : index
                      %29 = arith.addi %28, %27 : index
                      %30 = memref.load %arg6[%arg13] : memref<?xf32>
                      %31 = memref.load %arg8[%29] : memref<?xf32>
                      %32 = arith.mulf %30, %31 : f32
                      omp.reduction %32, %19 : f32, !llvm.ptr
                    }
                    omp.yield
                  }
                  omp.terminator
                }
                %26 = llvm.load %19 : !llvm.ptr -> f32
                memref.store %26, %alloc[%21] : memref<32768xf32>
                omp.yield
              }
              omp.terminator
            }
            omp.yield
          }
          omp.terminator
        }
        omp.yield
      }
      omp.terminator
    }
    return %cast, %9 : memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After ConvertVectorToLLVMPass (convert-vector-to-llvm) //----- //
module {
  omp.reduction.declare @__scf_reduction : f32 init {
  ^bb0(%arg0: f32):
    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    omp.yield(%0 : f32)
  } combiner {
  ^bb0(%arg0: f32, %arg1: f32):
    %0 = arith.addf %arg0, %arg1 : f32
    omp.yield(%0 : f32)
  } atomic {
  ^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr):
    %0 = llvm.load %arg1 : !llvm.ptr -> f32
    %1 = llvm.atomicrmw fadd %arg0, %0 monotonic : !llvm.ptr, f32
    omp.yield
  }
  func.func @SpTMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<2 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(1 : i64) : i64
    %c0 = arith.constant 0 : index
    %c32768 = arith.constant 32768 : index
    %c1 = arith.constant 1 : index
    %c32768_i64 = arith.constant 32768 : i64
    %c64_i64 = arith.constant 64 : i64
    %c32_i64 = arith.constant 32 : i64
    %c16_i64 = arith.constant 16 : i64
    %c0_i64 = arith.constant 0 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %c64 = arith.constant 64 : index
    %c32 = arith.constant 32 : index
    %alloc = memref.alloc() : memref<32768xf32>
    %cast = memref.cast %alloc : memref<32768xf32> to memref<?xf32>
    %1 = llvm.mlir.undef : !llvm.struct<(array<3 x i64>, array<1 x i64>)>
    %2 = llvm.insertvalue %c0_i64, %1[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %3 = llvm.insertvalue %c16_i64, %2[0, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %4 = llvm.insertvalue %c32_i64, %3[0, 1] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %5 = llvm.insertvalue %c64_i64, %4[0, 2] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%6: index):  // 2 preds: ^bb0, ^bb2
    %7 = arith.cmpi slt, %6, %c32768 : index
    cf.cond_br %7, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    memref.store %cst, %alloc[%6] : memref<32768xf32>
    %8 = arith.addi %6, %c1 : index
    cf.br ^bb1(%8 : index)
  ^bb3:  // pred: ^bb1
    %9 = llvm.insertvalue %c32768_i64, %5[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %10 = memref.load %arg0[%c0] : memref<?xindex>
    %11 = memref.load %arg0[%c1] : memref<?xindex>
    omp.parallel   {
      omp.wsloop   for  (%arg10) : index = (%10) to (%11) step (%c1) {
        %12 = memref.load %arg1[%arg10] : memref<?xindex>
        %13 = memref.load %arg2[%arg10] : memref<?xindex>
        %14 = arith.addi %arg10, %c1 : index
        %15 = memref.load %arg2[%14] : memref<?xindex>
        omp.parallel   {
          omp.wsloop   for  (%arg11) : index = (%13) to (%15) step (%c1) {
            %16 = memref.load %arg3[%arg11] : memref<?xindex>
            %17 = arith.muli %12, %c32 : index
            %18 = arith.addi %17, %16 : index
            omp.parallel   {
              %19 = llvm.alloca %0 x f32 : (i64) -> !llvm.ptr
              omp.wsloop   for  (%arg12) : index = (%c0) to (%c64) step (%c1) {
                %20 = arith.muli %18, %c64 : index
                %21 = arith.addi %20, %arg12 : index
                %22 = memref.load %alloc[%21] : memref<32768xf32>
                %23 = memref.load %arg4[%arg11] : memref<?xindex>
                %24 = arith.addi %arg11, %c1 : index
                %25 = memref.load %arg4[%24] : memref<?xindex>
                llvm.store %22, %19 : f32, !llvm.ptr
                omp.parallel   {
                  omp.wsloop   reduction(@__scf_reduction -> %19 : !llvm.ptr) for  (%arg13) : index = (%23) to (%25) step (%c1) {
                    memref.alloca_scope  {
                      %27 = memref.load %arg5[%arg13] : memref<?xindex>
                      %28 = arith.muli %arg12, %c64 : index
                      %29 = arith.addi %28, %27 : index
                      %30 = memref.load %arg6[%arg13] : memref<?xf32>
                      %31 = memref.load %arg8[%29] : memref<?xf32>
                      %32 = arith.mulf %30, %31 : f32
                      omp.reduction %32, %19 : f32, !llvm.ptr
                    }
                    omp.yield
                  }
                  omp.terminator
                }
                %26 = llvm.load %19 : !llvm.ptr -> f32
                memref.store %26, %alloc[%21] : memref<32768xf32>
                omp.yield
              }
              omp.terminator
            }
            omp.yield
          }
          omp.terminator
        }
        omp.yield
      }
      omp.terminator
    }
    return %cast, %9 : memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After FinalizeMemRefToLLVMConversionPass (finalize-memref-to-llvm) //----- //
module {
  llvm.func @malloc(i64) -> !llvm.ptr
  omp.reduction.declare @__scf_reduction : f32 init {
  ^bb0(%arg0: f32):
    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    omp.yield(%0 : f32)
  } combiner {
  ^bb0(%arg0: f32, %arg1: f32):
    %0 = arith.addf %arg0, %arg1 : f32
    omp.yield(%0 : f32)
  } atomic {
  ^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr):
    %0 = llvm.load %arg1 : !llvm.ptr -> f32
    %1 = llvm.atomicrmw fadd %arg0, %0 monotonic : !llvm.ptr, f32
    omp.yield
  }
  func.func @SpTMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<2 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %2 = builtin.unrealized_conversion_cast %arg2 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %3 = builtin.unrealized_conversion_cast %arg3 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %4 = builtin.unrealized_conversion_cast %arg4 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = builtin.unrealized_conversion_cast %arg5 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %6 = builtin.unrealized_conversion_cast %arg6 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = builtin.unrealized_conversion_cast %arg8 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %8 = llvm.mlir.constant(1 : i64) : i64
    %c0 = arith.constant 0 : index
    %9 = builtin.unrealized_conversion_cast %c0 : index to i64
    %c32768 = arith.constant 32768 : index
    %c1 = arith.constant 1 : index
    %10 = builtin.unrealized_conversion_cast %c1 : index to i64
    %c32768_i64 = arith.constant 32768 : i64
    %c64_i64 = arith.constant 64 : i64
    %c32_i64 = arith.constant 32 : i64
    %c16_i64 = arith.constant 16 : i64
    %c0_i64 = arith.constant 0 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %c64 = arith.constant 64 : index
    %c32 = arith.constant 32 : index
    %11 = llvm.mlir.constant(32768 : index) : i64
    %12 = llvm.mlir.constant(1 : index) : i64
    %13 = llvm.mlir.null : !llvm.ptr
    %14 = llvm.getelementptr %13[%11] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %15 = llvm.ptrtoint %14 : !llvm.ptr to i64
    %16 = llvm.call @malloc(%15) : (i64) -> !llvm.ptr
    %17 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %18 = llvm.insertvalue %16, %17[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %19 = llvm.insertvalue %16, %18[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.mlir.constant(0 : index) : i64
    %21 = llvm.insertvalue %20, %19[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %11, %21[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %12, %22[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = builtin.unrealized_conversion_cast %23 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %25 = llvm.mlir.undef : !llvm.struct<(array<3 x i64>, array<1 x i64>)>
    %26 = llvm.insertvalue %c0_i64, %25[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %27 = llvm.insertvalue %c16_i64, %26[0, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %28 = llvm.insertvalue %c32_i64, %27[0, 1] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %29 = llvm.insertvalue %c64_i64, %28[0, 2] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%30: index):  // 2 preds: ^bb0, ^bb2
    %31 = builtin.unrealized_conversion_cast %30 : index to i64
    %32 = arith.cmpi slt, %30, %c32768 : index
    cf.cond_br %32, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %33 = llvm.extractvalue %23[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = llvm.getelementptr %33[%31] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %cst, %34 : f32, !llvm.ptr
    %35 = arith.addi %30, %c1 : index
    cf.br ^bb1(%35 : index)
  ^bb3:  // pred: ^bb1
    %36 = llvm.insertvalue %c32768_i64, %29[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %37 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %38 = llvm.getelementptr %37[%9] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %39 = llvm.load %38 : !llvm.ptr -> i64
    %40 = builtin.unrealized_conversion_cast %39 : i64 to index
    %41 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %42 = llvm.getelementptr %41[%10] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %43 = llvm.load %42 : !llvm.ptr -> i64
    %44 = builtin.unrealized_conversion_cast %43 : i64 to index
    omp.parallel   {
      omp.wsloop   for  (%arg10) : index = (%40) to (%44) step (%c1) {
        %45 = builtin.unrealized_conversion_cast %arg10 : index to i64
        %46 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %47 = llvm.getelementptr %46[%45] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %48 = llvm.load %47 : !llvm.ptr -> i64
        %49 = builtin.unrealized_conversion_cast %48 : i64 to index
        %50 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %51 = llvm.getelementptr %50[%45] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %52 = llvm.load %51 : !llvm.ptr -> i64
        %53 = builtin.unrealized_conversion_cast %52 : i64 to index
        %54 = arith.addi %arg10, %c1 : index
        %55 = builtin.unrealized_conversion_cast %54 : index to i64
        %56 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %57 = llvm.getelementptr %56[%55] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %58 = llvm.load %57 : !llvm.ptr -> i64
        %59 = builtin.unrealized_conversion_cast %58 : i64 to index
        omp.parallel   {
          omp.wsloop   for  (%arg11) : index = (%53) to (%59) step (%c1) {
            %60 = builtin.unrealized_conversion_cast %arg11 : index to i64
            %61 = llvm.extractvalue %3[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %62 = llvm.getelementptr %61[%60] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %63 = llvm.load %62 : !llvm.ptr -> i64
            %64 = builtin.unrealized_conversion_cast %63 : i64 to index
            %65 = arith.muli %49, %c32 : index
            %66 = arith.addi %65, %64 : index
            omp.parallel   {
              %67 = llvm.alloca %8 x f32 : (i64) -> !llvm.ptr
              omp.wsloop   for  (%arg12) : index = (%c0) to (%c64) step (%c1) {
                %68 = arith.muli %66, %c64 : index
                %69 = arith.addi %68, %arg12 : index
                %70 = builtin.unrealized_conversion_cast %69 : index to i64
                %71 = llvm.extractvalue %23[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %72 = llvm.getelementptr %71[%70] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                %73 = llvm.load %72 : !llvm.ptr -> f32
                %74 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %75 = llvm.getelementptr %74[%60] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                %76 = llvm.load %75 : !llvm.ptr -> i64
                %77 = builtin.unrealized_conversion_cast %76 : i64 to index
                %78 = arith.addi %arg11, %c1 : index
                %79 = builtin.unrealized_conversion_cast %78 : index to i64
                %80 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %81 = llvm.getelementptr %80[%79] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                %82 = llvm.load %81 : !llvm.ptr -> i64
                %83 = builtin.unrealized_conversion_cast %82 : i64 to index
                llvm.store %73, %67 : f32, !llvm.ptr
                omp.parallel   {
                  omp.wsloop   reduction(@__scf_reduction -> %67 : !llvm.ptr) for  (%arg13) : index = (%77) to (%83) step (%c1) {
                    %87 = builtin.unrealized_conversion_cast %arg13 : index to i64
                    %88 = llvm.intr.stacksave : !llvm.ptr
                    llvm.br ^bb1
                  ^bb1:  // pred: ^bb0
                    %89 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                    %90 = llvm.getelementptr %89[%87] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                    %91 = llvm.load %90 : !llvm.ptr -> i64
                    %92 = builtin.unrealized_conversion_cast %91 : i64 to index
                    %93 = arith.muli %arg12, %c64 : index
                    %94 = arith.addi %93, %92 : index
                    %95 = builtin.unrealized_conversion_cast %94 : index to i64
                    %96 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                    %97 = llvm.getelementptr %96[%87] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                    %98 = llvm.load %97 : !llvm.ptr -> f32
                    %99 = llvm.extractvalue %7[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                    %100 = llvm.getelementptr %99[%95] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                    %101 = llvm.load %100 : !llvm.ptr -> f32
                    %102 = arith.mulf %98, %101 : f32
                    omp.reduction %102, %67 : f32, !llvm.ptr
                    llvm.intr.stackrestore %88 : !llvm.ptr
                    llvm.br ^bb2
                  ^bb2:  // pred: ^bb1
                    omp.yield
                  }
                  omp.terminator
                }
                %84 = llvm.load %67 : !llvm.ptr -> f32
                %85 = llvm.extractvalue %23[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %86 = llvm.getelementptr %85[%70] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                llvm.store %84, %86 : f32, !llvm.ptr
                omp.yield
              }
              omp.terminator
            }
            omp.yield
          }
          omp.terminator
        }
        omp.yield
      }
      omp.terminator
    }
    return %24, %36 : memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After ConvertComplexToStandard (convert-complex-to-standard) //----- //
func.func @SpTMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<2 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
  %0 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %1 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %2 = builtin.unrealized_conversion_cast %arg2 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %3 = builtin.unrealized_conversion_cast %arg3 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %4 = builtin.unrealized_conversion_cast %arg4 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %5 = builtin.unrealized_conversion_cast %arg5 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %6 = builtin.unrealized_conversion_cast %arg6 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %7 = builtin.unrealized_conversion_cast %arg8 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %8 = llvm.mlir.constant(1 : i64) : i64
  %c0 = arith.constant 0 : index
  %9 = builtin.unrealized_conversion_cast %c0 : index to i64
  %c32768 = arith.constant 32768 : index
  %c1 = arith.constant 1 : index
  %10 = builtin.unrealized_conversion_cast %c1 : index to i64
  %c32768_i64 = arith.constant 32768 : i64
  %c64_i64 = arith.constant 64 : i64
  %c32_i64 = arith.constant 32 : i64
  %c16_i64 = arith.constant 16 : i64
  %c0_i64 = arith.constant 0 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %c64 = arith.constant 64 : index
  %c32 = arith.constant 32 : index
  %11 = llvm.mlir.constant(32768 : index) : i64
  %12 = llvm.mlir.constant(1 : index) : i64
  %13 = llvm.mlir.null : !llvm.ptr
  %14 = llvm.getelementptr %13[32768] : (!llvm.ptr) -> !llvm.ptr, f32
  %15 = llvm.ptrtoint %14 : !llvm.ptr to i64
  %16 = llvm.call @malloc(%15) : (i64) -> !llvm.ptr
  %17 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %18 = llvm.insertvalue %16, %17[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %19 = llvm.insertvalue %16, %18[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %20 = llvm.mlir.constant(0 : index) : i64
  %21 = llvm.insertvalue %20, %19[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %22 = llvm.insertvalue %11, %21[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %23 = llvm.insertvalue %12, %22[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %24 = builtin.unrealized_conversion_cast %23 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
  %25 = llvm.mlir.undef : !llvm.struct<(array<3 x i64>, array<1 x i64>)>
  %26 = llvm.insertvalue %c0_i64, %25[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %27 = llvm.insertvalue %c16_i64, %26[0, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %28 = llvm.insertvalue %c32_i64, %27[0, 1] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %29 = llvm.insertvalue %c64_i64, %28[0, 2] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  cf.br ^bb1(%c0 : index)
^bb1(%30: index):  // 2 preds: ^bb0, ^bb2
  %31 = builtin.unrealized_conversion_cast %30 : index to i64
  %32 = arith.cmpi slt, %30, %c32768 : index
  cf.cond_br %32, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %33 = llvm.getelementptr %16[%31] : (!llvm.ptr, i64) -> !llvm.ptr, f32
  llvm.store %cst, %33 : f32, !llvm.ptr
  %34 = arith.addi %30, %c1 : index
  cf.br ^bb1(%34 : index)
^bb3:  // pred: ^bb1
  %35 = llvm.insertvalue %c32768_i64, %29[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %36 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %37 = llvm.getelementptr %36[%9] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %38 = llvm.load %37 : !llvm.ptr -> i64
  %39 = builtin.unrealized_conversion_cast %38 : i64 to index
  %40 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %41 = llvm.getelementptr %40[%10] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %42 = llvm.load %41 : !llvm.ptr -> i64
  %43 = builtin.unrealized_conversion_cast %42 : i64 to index
  omp.parallel   {
    omp.wsloop   for  (%arg10) : index = (%39) to (%43) step (%c1) {
      %44 = builtin.unrealized_conversion_cast %arg10 : index to i64
      %45 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
      %46 = llvm.getelementptr %45[%44] : (!llvm.ptr, i64) -> !llvm.ptr, i64
      %47 = llvm.load %46 : !llvm.ptr -> i64
      %48 = builtin.unrealized_conversion_cast %47 : i64 to index
      %49 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
      %50 = llvm.getelementptr %49[%44] : (!llvm.ptr, i64) -> !llvm.ptr, i64
      %51 = llvm.load %50 : !llvm.ptr -> i64
      %52 = builtin.unrealized_conversion_cast %51 : i64 to index
      %53 = arith.addi %arg10, %c1 : index
      %54 = builtin.unrealized_conversion_cast %53 : index to i64
      %55 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
      %56 = llvm.getelementptr %55[%54] : (!llvm.ptr, i64) -> !llvm.ptr, i64
      %57 = llvm.load %56 : !llvm.ptr -> i64
      %58 = builtin.unrealized_conversion_cast %57 : i64 to index
      omp.parallel   {
        omp.wsloop   for  (%arg11) : index = (%52) to (%58) step (%c1) {
          %59 = builtin.unrealized_conversion_cast %arg11 : index to i64
          %60 = llvm.extractvalue %3[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
          %61 = llvm.getelementptr %60[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
          %62 = llvm.load %61 : !llvm.ptr -> i64
          %63 = builtin.unrealized_conversion_cast %62 : i64 to index
          %64 = arith.muli %48, %c32 : index
          %65 = arith.addi %64, %63 : index
          omp.parallel   {
            %66 = llvm.alloca %8 x f32 : (i64) -> !llvm.ptr
            omp.wsloop   for  (%arg12) : index = (%c0) to (%c64) step (%c1) {
              %67 = arith.muli %65, %c64 : index
              %68 = arith.addi %67, %arg12 : index
              %69 = builtin.unrealized_conversion_cast %68 : index to i64
              %70 = llvm.getelementptr %16[%69] : (!llvm.ptr, i64) -> !llvm.ptr, f32
              %71 = llvm.load %70 : !llvm.ptr -> f32
              %72 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
              %73 = llvm.getelementptr %72[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
              %74 = llvm.load %73 : !llvm.ptr -> i64
              %75 = builtin.unrealized_conversion_cast %74 : i64 to index
              %76 = arith.addi %arg11, %c1 : index
              %77 = builtin.unrealized_conversion_cast %76 : index to i64
              %78 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
              %79 = llvm.getelementptr %78[%77] : (!llvm.ptr, i64) -> !llvm.ptr, i64
              %80 = llvm.load %79 : !llvm.ptr -> i64
              %81 = builtin.unrealized_conversion_cast %80 : i64 to index
              llvm.store %71, %66 : f32, !llvm.ptr
              omp.parallel   {
                omp.wsloop   reduction(@__scf_reduction -> %66 : !llvm.ptr) for  (%arg13) : index = (%75) to (%81) step (%c1) {
                  %84 = builtin.unrealized_conversion_cast %arg13 : index to i64
                  %85 = llvm.intr.stacksave : !llvm.ptr
                  llvm.br ^bb1
                ^bb1:  // pred: ^bb0
                  %86 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                  %87 = llvm.getelementptr %86[%84] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                  %88 = llvm.load %87 : !llvm.ptr -> i64
                  %89 = builtin.unrealized_conversion_cast %88 : i64 to index
                  %90 = arith.muli %arg12, %c64 : index
                  %91 = arith.addi %90, %89 : index
                  %92 = builtin.unrealized_conversion_cast %91 : index to i64
                  %93 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                  %94 = llvm.getelementptr %93[%84] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                  %95 = llvm.load %94 : !llvm.ptr -> f32
                  %96 = llvm.extractvalue %7[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                  %97 = llvm.getelementptr %96[%92] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                  %98 = llvm.load %97 : !llvm.ptr -> f32
                  %99 = arith.mulf %95, %98 : f32
                  omp.reduction %99, %66 : f32, !llvm.ptr
                  llvm.intr.stackrestore %85 : !llvm.ptr
                  llvm.br ^bb2
                ^bb2:  // pred: ^bb1
                  omp.yield
                }
                omp.terminator
              }
              %82 = llvm.load %66 : !llvm.ptr -> f32
              %83 = llvm.getelementptr %16[%69] : (!llvm.ptr, i64) -> !llvm.ptr, f32
              llvm.store %82, %83 : f32, !llvm.ptr
              omp.yield
            }
            omp.terminator
          }
          omp.yield
        }
        omp.terminator
      }
      omp.yield
    }
    omp.terminator
  }
  return %24, %35 : memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>
}

// -----// IR Dump After ArithExpandOps (arith-expand) //----- //
func.func @SpTMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<2 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
  %0 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %1 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %2 = builtin.unrealized_conversion_cast %arg2 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %3 = builtin.unrealized_conversion_cast %arg3 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %4 = builtin.unrealized_conversion_cast %arg4 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %5 = builtin.unrealized_conversion_cast %arg5 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %6 = builtin.unrealized_conversion_cast %arg6 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %7 = builtin.unrealized_conversion_cast %arg8 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %8 = llvm.mlir.constant(1 : i64) : i64
  %c0 = arith.constant 0 : index
  %9 = builtin.unrealized_conversion_cast %c0 : index to i64
  %c32768 = arith.constant 32768 : index
  %c1 = arith.constant 1 : index
  %10 = builtin.unrealized_conversion_cast %c1 : index to i64
  %c32768_i64 = arith.constant 32768 : i64
  %c64_i64 = arith.constant 64 : i64
  %c32_i64 = arith.constant 32 : i64
  %c16_i64 = arith.constant 16 : i64
  %c0_i64 = arith.constant 0 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %c64 = arith.constant 64 : index
  %c32 = arith.constant 32 : index
  %11 = llvm.mlir.constant(32768 : index) : i64
  %12 = llvm.mlir.constant(1 : index) : i64
  %13 = llvm.mlir.null : !llvm.ptr
  %14 = llvm.getelementptr %13[32768] : (!llvm.ptr) -> !llvm.ptr, f32
  %15 = llvm.ptrtoint %14 : !llvm.ptr to i64
  %16 = llvm.call @malloc(%15) : (i64) -> !llvm.ptr
  %17 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %18 = llvm.insertvalue %16, %17[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %19 = llvm.insertvalue %16, %18[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %20 = llvm.mlir.constant(0 : index) : i64
  %21 = llvm.insertvalue %20, %19[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %22 = llvm.insertvalue %11, %21[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %23 = llvm.insertvalue %12, %22[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %24 = builtin.unrealized_conversion_cast %23 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
  %25 = llvm.mlir.undef : !llvm.struct<(array<3 x i64>, array<1 x i64>)>
  %26 = llvm.insertvalue %c0_i64, %25[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %27 = llvm.insertvalue %c16_i64, %26[0, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %28 = llvm.insertvalue %c32_i64, %27[0, 1] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %29 = llvm.insertvalue %c64_i64, %28[0, 2] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  cf.br ^bb1(%c0 : index)
^bb1(%30: index):  // 2 preds: ^bb0, ^bb2
  %31 = builtin.unrealized_conversion_cast %30 : index to i64
  %32 = arith.cmpi slt, %30, %c32768 : index
  cf.cond_br %32, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %33 = llvm.getelementptr %16[%31] : (!llvm.ptr, i64) -> !llvm.ptr, f32
  llvm.store %cst, %33 : f32, !llvm.ptr
  %34 = arith.addi %30, %c1 : index
  cf.br ^bb1(%34 : index)
^bb3:  // pred: ^bb1
  %35 = llvm.insertvalue %c32768_i64, %29[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %36 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %37 = llvm.getelementptr %36[%9] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %38 = llvm.load %37 : !llvm.ptr -> i64
  %39 = builtin.unrealized_conversion_cast %38 : i64 to index
  %40 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %41 = llvm.getelementptr %40[%10] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %42 = llvm.load %41 : !llvm.ptr -> i64
  %43 = builtin.unrealized_conversion_cast %42 : i64 to index
  omp.parallel   {
    omp.wsloop   for  (%arg10) : index = (%39) to (%43) step (%c1) {
      %44 = builtin.unrealized_conversion_cast %arg10 : index to i64
      %45 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
      %46 = llvm.getelementptr %45[%44] : (!llvm.ptr, i64) -> !llvm.ptr, i64
      %47 = llvm.load %46 : !llvm.ptr -> i64
      %48 = builtin.unrealized_conversion_cast %47 : i64 to index
      %49 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
      %50 = llvm.getelementptr %49[%44] : (!llvm.ptr, i64) -> !llvm.ptr, i64
      %51 = llvm.load %50 : !llvm.ptr -> i64
      %52 = builtin.unrealized_conversion_cast %51 : i64 to index
      %53 = arith.addi %arg10, %c1 : index
      %54 = builtin.unrealized_conversion_cast %53 : index to i64
      %55 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
      %56 = llvm.getelementptr %55[%54] : (!llvm.ptr, i64) -> !llvm.ptr, i64
      %57 = llvm.load %56 : !llvm.ptr -> i64
      %58 = builtin.unrealized_conversion_cast %57 : i64 to index
      omp.parallel   {
        omp.wsloop   for  (%arg11) : index = (%52) to (%58) step (%c1) {
          %59 = builtin.unrealized_conversion_cast %arg11 : index to i64
          %60 = llvm.extractvalue %3[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
          %61 = llvm.getelementptr %60[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
          %62 = llvm.load %61 : !llvm.ptr -> i64
          %63 = builtin.unrealized_conversion_cast %62 : i64 to index
          %64 = arith.muli %48, %c32 : index
          %65 = arith.addi %64, %63 : index
          omp.parallel   {
            %66 = llvm.alloca %8 x f32 : (i64) -> !llvm.ptr
            omp.wsloop   for  (%arg12) : index = (%c0) to (%c64) step (%c1) {
              %67 = arith.muli %65, %c64 : index
              %68 = arith.addi %67, %arg12 : index
              %69 = builtin.unrealized_conversion_cast %68 : index to i64
              %70 = llvm.getelementptr %16[%69] : (!llvm.ptr, i64) -> !llvm.ptr, f32
              %71 = llvm.load %70 : !llvm.ptr -> f32
              %72 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
              %73 = llvm.getelementptr %72[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
              %74 = llvm.load %73 : !llvm.ptr -> i64
              %75 = builtin.unrealized_conversion_cast %74 : i64 to index
              %76 = arith.addi %arg11, %c1 : index
              %77 = builtin.unrealized_conversion_cast %76 : index to i64
              %78 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
              %79 = llvm.getelementptr %78[%77] : (!llvm.ptr, i64) -> !llvm.ptr, i64
              %80 = llvm.load %79 : !llvm.ptr -> i64
              %81 = builtin.unrealized_conversion_cast %80 : i64 to index
              llvm.store %71, %66 : f32, !llvm.ptr
              omp.parallel   {
                omp.wsloop   reduction(@__scf_reduction -> %66 : !llvm.ptr) for  (%arg13) : index = (%75) to (%81) step (%c1) {
                  %84 = builtin.unrealized_conversion_cast %arg13 : index to i64
                  %85 = llvm.intr.stacksave : !llvm.ptr
                  llvm.br ^bb1
                ^bb1:  // pred: ^bb0
                  %86 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                  %87 = llvm.getelementptr %86[%84] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                  %88 = llvm.load %87 : !llvm.ptr -> i64
                  %89 = builtin.unrealized_conversion_cast %88 : i64 to index
                  %90 = arith.muli %arg12, %c64 : index
                  %91 = arith.addi %90, %89 : index
                  %92 = builtin.unrealized_conversion_cast %91 : index to i64
                  %93 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                  %94 = llvm.getelementptr %93[%84] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                  %95 = llvm.load %94 : !llvm.ptr -> f32
                  %96 = llvm.extractvalue %7[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                  %97 = llvm.getelementptr %96[%92] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                  %98 = llvm.load %97 : !llvm.ptr -> f32
                  %99 = arith.mulf %95, %98 : f32
                  omp.reduction %99, %66 : f32, !llvm.ptr
                  llvm.intr.stackrestore %85 : !llvm.ptr
                  llvm.br ^bb2
                ^bb2:  // pred: ^bb1
                  omp.yield
                }
                omp.terminator
              }
              %82 = llvm.load %66 : !llvm.ptr -> f32
              %83 = llvm.getelementptr %16[%69] : (!llvm.ptr, i64) -> !llvm.ptr, f32
              llvm.store %82, %83 : f32, !llvm.ptr
              omp.yield
            }
            omp.terminator
          }
          omp.yield
        }
        omp.terminator
      }
      omp.yield
    }
    omp.terminator
  }
  return %24, %35 : memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>
}

// -----// IR Dump After ConvertMathToLLVMPass (convert-math-to-llvm) //----- //
func.func @SpTMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<2 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
  %0 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %1 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %2 = builtin.unrealized_conversion_cast %arg2 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %3 = builtin.unrealized_conversion_cast %arg3 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %4 = builtin.unrealized_conversion_cast %arg4 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %5 = builtin.unrealized_conversion_cast %arg5 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %6 = builtin.unrealized_conversion_cast %arg6 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %7 = builtin.unrealized_conversion_cast %arg8 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %8 = llvm.mlir.constant(1 : i64) : i64
  %c0 = arith.constant 0 : index
  %9 = builtin.unrealized_conversion_cast %c0 : index to i64
  %c32768 = arith.constant 32768 : index
  %c1 = arith.constant 1 : index
  %10 = builtin.unrealized_conversion_cast %c1 : index to i64
  %c32768_i64 = arith.constant 32768 : i64
  %c64_i64 = arith.constant 64 : i64
  %c32_i64 = arith.constant 32 : i64
  %c16_i64 = arith.constant 16 : i64
  %c0_i64 = arith.constant 0 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %c64 = arith.constant 64 : index
  %c32 = arith.constant 32 : index
  %11 = llvm.mlir.constant(32768 : index) : i64
  %12 = llvm.mlir.constant(1 : index) : i64
  %13 = llvm.mlir.null : !llvm.ptr
  %14 = llvm.getelementptr %13[32768] : (!llvm.ptr) -> !llvm.ptr, f32
  %15 = llvm.ptrtoint %14 : !llvm.ptr to i64
  %16 = llvm.call @malloc(%15) : (i64) -> !llvm.ptr
  %17 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
  %18 = llvm.insertvalue %16, %17[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %19 = llvm.insertvalue %16, %18[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %20 = llvm.mlir.constant(0 : index) : i64
  %21 = llvm.insertvalue %20, %19[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %22 = llvm.insertvalue %11, %21[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %23 = llvm.insertvalue %12, %22[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %24 = builtin.unrealized_conversion_cast %23 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
  %25 = llvm.mlir.undef : !llvm.struct<(array<3 x i64>, array<1 x i64>)>
  %26 = llvm.insertvalue %c0_i64, %25[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %27 = llvm.insertvalue %c16_i64, %26[0, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %28 = llvm.insertvalue %c32_i64, %27[0, 1] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %29 = llvm.insertvalue %c64_i64, %28[0, 2] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  cf.br ^bb1(%c0 : index)
^bb1(%30: index):  // 2 preds: ^bb0, ^bb2
  %31 = builtin.unrealized_conversion_cast %30 : index to i64
  %32 = arith.cmpi slt, %30, %c32768 : index
  cf.cond_br %32, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %33 = llvm.getelementptr %16[%31] : (!llvm.ptr, i64) -> !llvm.ptr, f32
  llvm.store %cst, %33 : f32, !llvm.ptr
  %34 = arith.addi %30, %c1 : index
  cf.br ^bb1(%34 : index)
^bb3:  // pred: ^bb1
  %35 = llvm.insertvalue %c32768_i64, %29[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
  %36 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %37 = llvm.getelementptr %36[%9] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %38 = llvm.load %37 : !llvm.ptr -> i64
  %39 = builtin.unrealized_conversion_cast %38 : i64 to index
  %40 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
  %41 = llvm.getelementptr %40[%10] : (!llvm.ptr, i64) -> !llvm.ptr, i64
  %42 = llvm.load %41 : !llvm.ptr -> i64
  %43 = builtin.unrealized_conversion_cast %42 : i64 to index
  omp.parallel   {
    omp.wsloop   for  (%arg10) : index = (%39) to (%43) step (%c1) {
      %44 = builtin.unrealized_conversion_cast %arg10 : index to i64
      %45 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
      %46 = llvm.getelementptr %45[%44] : (!llvm.ptr, i64) -> !llvm.ptr, i64
      %47 = llvm.load %46 : !llvm.ptr -> i64
      %48 = builtin.unrealized_conversion_cast %47 : i64 to index
      %49 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
      %50 = llvm.getelementptr %49[%44] : (!llvm.ptr, i64) -> !llvm.ptr, i64
      %51 = llvm.load %50 : !llvm.ptr -> i64
      %52 = builtin.unrealized_conversion_cast %51 : i64 to index
      %53 = arith.addi %arg10, %c1 : index
      %54 = builtin.unrealized_conversion_cast %53 : index to i64
      %55 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
      %56 = llvm.getelementptr %55[%54] : (!llvm.ptr, i64) -> !llvm.ptr, i64
      %57 = llvm.load %56 : !llvm.ptr -> i64
      %58 = builtin.unrealized_conversion_cast %57 : i64 to index
      omp.parallel   {
        omp.wsloop   for  (%arg11) : index = (%52) to (%58) step (%c1) {
          %59 = builtin.unrealized_conversion_cast %arg11 : index to i64
          %60 = llvm.extractvalue %3[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
          %61 = llvm.getelementptr %60[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
          %62 = llvm.load %61 : !llvm.ptr -> i64
          %63 = builtin.unrealized_conversion_cast %62 : i64 to index
          %64 = arith.muli %48, %c32 : index
          %65 = arith.addi %64, %63 : index
          omp.parallel   {
            %66 = llvm.alloca %8 x f32 : (i64) -> !llvm.ptr
            omp.wsloop   for  (%arg12) : index = (%c0) to (%c64) step (%c1) {
              %67 = arith.muli %65, %c64 : index
              %68 = arith.addi %67, %arg12 : index
              %69 = builtin.unrealized_conversion_cast %68 : index to i64
              %70 = llvm.getelementptr %16[%69] : (!llvm.ptr, i64) -> !llvm.ptr, f32
              %71 = llvm.load %70 : !llvm.ptr -> f32
              %72 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
              %73 = llvm.getelementptr %72[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
              %74 = llvm.load %73 : !llvm.ptr -> i64
              %75 = builtin.unrealized_conversion_cast %74 : i64 to index
              %76 = arith.addi %arg11, %c1 : index
              %77 = builtin.unrealized_conversion_cast %76 : index to i64
              %78 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
              %79 = llvm.getelementptr %78[%77] : (!llvm.ptr, i64) -> !llvm.ptr, i64
              %80 = llvm.load %79 : !llvm.ptr -> i64
              %81 = builtin.unrealized_conversion_cast %80 : i64 to index
              llvm.store %71, %66 : f32, !llvm.ptr
              omp.parallel   {
                omp.wsloop   reduction(@__scf_reduction -> %66 : !llvm.ptr) for  (%arg13) : index = (%75) to (%81) step (%c1) {
                  %84 = builtin.unrealized_conversion_cast %arg13 : index to i64
                  %85 = llvm.intr.stacksave : !llvm.ptr
                  llvm.br ^bb1
                ^bb1:  // pred: ^bb0
                  %86 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                  %87 = llvm.getelementptr %86[%84] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                  %88 = llvm.load %87 : !llvm.ptr -> i64
                  %89 = builtin.unrealized_conversion_cast %88 : i64 to index
                  %90 = arith.muli %arg12, %c64 : index
                  %91 = arith.addi %90, %89 : index
                  %92 = builtin.unrealized_conversion_cast %91 : index to i64
                  %93 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                  %94 = llvm.getelementptr %93[%84] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                  %95 = llvm.load %94 : !llvm.ptr -> f32
                  %96 = llvm.extractvalue %7[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                  %97 = llvm.getelementptr %96[%92] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                  %98 = llvm.load %97 : !llvm.ptr -> f32
                  %99 = arith.mulf %95, %98 : f32
                  omp.reduction %99, %66 : f32, !llvm.ptr
                  llvm.intr.stackrestore %85 : !llvm.ptr
                  llvm.br ^bb2
                ^bb2:  // pred: ^bb1
                  omp.yield
                }
                omp.terminator
              }
              %82 = llvm.load %66 : !llvm.ptr -> f32
              %83 = llvm.getelementptr %16[%69] : (!llvm.ptr, i64) -> !llvm.ptr, f32
              llvm.store %82, %83 : f32, !llvm.ptr
              omp.yield
            }
            omp.terminator
          }
          omp.yield
        }
        omp.terminator
      }
      omp.yield
    }
    omp.terminator
  }
  return %24, %35 : memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>
}

// -----// IR Dump After ConvertMathToLibm (convert-math-to-libm) //----- //
module {
  llvm.func @malloc(i64) -> !llvm.ptr
  omp.reduction.declare @__scf_reduction : f32 init {
  ^bb0(%arg0: f32):
    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    omp.yield(%0 : f32)
  } combiner {
  ^bb0(%arg0: f32, %arg1: f32):
    %0 = arith.addf %arg0, %arg1 : f32
    omp.yield(%0 : f32)
  } atomic {
  ^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr):
    %0 = llvm.load %arg1 : !llvm.ptr -> f32
    %1 = llvm.atomicrmw fadd %arg0, %0 monotonic : !llvm.ptr, f32
    omp.yield
  }
  func.func @SpTMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<2 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %2 = builtin.unrealized_conversion_cast %arg2 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %3 = builtin.unrealized_conversion_cast %arg3 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %4 = builtin.unrealized_conversion_cast %arg4 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = builtin.unrealized_conversion_cast %arg5 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %6 = builtin.unrealized_conversion_cast %arg6 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = builtin.unrealized_conversion_cast %arg8 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %8 = llvm.mlir.constant(1 : i64) : i64
    %c0 = arith.constant 0 : index
    %9 = builtin.unrealized_conversion_cast %c0 : index to i64
    %c32768 = arith.constant 32768 : index
    %c1 = arith.constant 1 : index
    %10 = builtin.unrealized_conversion_cast %c1 : index to i64
    %c32768_i64 = arith.constant 32768 : i64
    %c64_i64 = arith.constant 64 : i64
    %c32_i64 = arith.constant 32 : i64
    %c16_i64 = arith.constant 16 : i64
    %c0_i64 = arith.constant 0 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %c64 = arith.constant 64 : index
    %c32 = arith.constant 32 : index
    %11 = llvm.mlir.constant(32768 : index) : i64
    %12 = llvm.mlir.constant(1 : index) : i64
    %13 = llvm.mlir.null : !llvm.ptr
    %14 = llvm.getelementptr %13[32768] : (!llvm.ptr) -> !llvm.ptr, f32
    %15 = llvm.ptrtoint %14 : !llvm.ptr to i64
    %16 = llvm.call @malloc(%15) : (i64) -> !llvm.ptr
    %17 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %18 = llvm.insertvalue %16, %17[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %19 = llvm.insertvalue %16, %18[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.mlir.constant(0 : index) : i64
    %21 = llvm.insertvalue %20, %19[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %11, %21[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %12, %22[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = builtin.unrealized_conversion_cast %23 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %25 = llvm.mlir.undef : !llvm.struct<(array<3 x i64>, array<1 x i64>)>
    %26 = llvm.insertvalue %c0_i64, %25[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %27 = llvm.insertvalue %c16_i64, %26[0, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %28 = llvm.insertvalue %c32_i64, %27[0, 1] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %29 = llvm.insertvalue %c64_i64, %28[0, 2] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%30: index):  // 2 preds: ^bb0, ^bb2
    %31 = builtin.unrealized_conversion_cast %30 : index to i64
    %32 = arith.cmpi slt, %30, %c32768 : index
    cf.cond_br %32, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %33 = llvm.getelementptr %16[%31] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %cst, %33 : f32, !llvm.ptr
    %34 = arith.addi %30, %c1 : index
    cf.br ^bb1(%34 : index)
  ^bb3:  // pred: ^bb1
    %35 = llvm.insertvalue %c32768_i64, %29[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %36 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %37 = llvm.getelementptr %36[%9] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %38 = llvm.load %37 : !llvm.ptr -> i64
    %39 = builtin.unrealized_conversion_cast %38 : i64 to index
    %40 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %41 = llvm.getelementptr %40[%10] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %42 = llvm.load %41 : !llvm.ptr -> i64
    %43 = builtin.unrealized_conversion_cast %42 : i64 to index
    omp.parallel   {
      omp.wsloop   for  (%arg10) : index = (%39) to (%43) step (%c1) {
        %44 = builtin.unrealized_conversion_cast %arg10 : index to i64
        %45 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %46 = llvm.getelementptr %45[%44] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %47 = llvm.load %46 : !llvm.ptr -> i64
        %48 = builtin.unrealized_conversion_cast %47 : i64 to index
        %49 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %50 = llvm.getelementptr %49[%44] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %51 = llvm.load %50 : !llvm.ptr -> i64
        %52 = builtin.unrealized_conversion_cast %51 : i64 to index
        %53 = arith.addi %arg10, %c1 : index
        %54 = builtin.unrealized_conversion_cast %53 : index to i64
        %55 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %56 = llvm.getelementptr %55[%54] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %57 = llvm.load %56 : !llvm.ptr -> i64
        %58 = builtin.unrealized_conversion_cast %57 : i64 to index
        omp.parallel   {
          omp.wsloop   for  (%arg11) : index = (%52) to (%58) step (%c1) {
            %59 = builtin.unrealized_conversion_cast %arg11 : index to i64
            %60 = llvm.extractvalue %3[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %61 = llvm.getelementptr %60[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %62 = llvm.load %61 : !llvm.ptr -> i64
            %63 = builtin.unrealized_conversion_cast %62 : i64 to index
            %64 = arith.muli %48, %c32 : index
            %65 = arith.addi %64, %63 : index
            omp.parallel   {
              %66 = llvm.alloca %8 x f32 : (i64) -> !llvm.ptr
              omp.wsloop   for  (%arg12) : index = (%c0) to (%c64) step (%c1) {
                %67 = arith.muli %65, %c64 : index
                %68 = arith.addi %67, %arg12 : index
                %69 = builtin.unrealized_conversion_cast %68 : index to i64
                %70 = llvm.getelementptr %16[%69] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                %71 = llvm.load %70 : !llvm.ptr -> f32
                %72 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %73 = llvm.getelementptr %72[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                %74 = llvm.load %73 : !llvm.ptr -> i64
                %75 = builtin.unrealized_conversion_cast %74 : i64 to index
                %76 = arith.addi %arg11, %c1 : index
                %77 = builtin.unrealized_conversion_cast %76 : index to i64
                %78 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %79 = llvm.getelementptr %78[%77] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                %80 = llvm.load %79 : !llvm.ptr -> i64
                %81 = builtin.unrealized_conversion_cast %80 : i64 to index
                llvm.store %71, %66 : f32, !llvm.ptr
                omp.parallel   {
                  omp.wsloop   reduction(@__scf_reduction -> %66 : !llvm.ptr) for  (%arg13) : index = (%75) to (%81) step (%c1) {
                    %84 = builtin.unrealized_conversion_cast %arg13 : index to i64
                    %85 = llvm.intr.stacksave : !llvm.ptr
                    llvm.br ^bb1
                  ^bb1:  // pred: ^bb0
                    %86 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                    %87 = llvm.getelementptr %86[%84] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                    %88 = llvm.load %87 : !llvm.ptr -> i64
                    %89 = builtin.unrealized_conversion_cast %88 : i64 to index
                    %90 = arith.muli %arg12, %c64 : index
                    %91 = arith.addi %90, %89 : index
                    %92 = builtin.unrealized_conversion_cast %91 : index to i64
                    %93 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                    %94 = llvm.getelementptr %93[%84] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                    %95 = llvm.load %94 : !llvm.ptr -> f32
                    %96 = llvm.extractvalue %7[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                    %97 = llvm.getelementptr %96[%92] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                    %98 = llvm.load %97 : !llvm.ptr -> f32
                    %99 = arith.mulf %95, %98 : f32
                    omp.reduction %99, %66 : f32, !llvm.ptr
                    llvm.intr.stackrestore %85 : !llvm.ptr
                    llvm.br ^bb2
                  ^bb2:  // pred: ^bb1
                    omp.yield
                  }
                  omp.terminator
                }
                %82 = llvm.load %66 : !llvm.ptr -> f32
                %83 = llvm.getelementptr %16[%69] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                llvm.store %82, %83 : f32, !llvm.ptr
                omp.yield
              }
              omp.terminator
            }
            omp.yield
          }
          omp.terminator
        }
        omp.yield
      }
      omp.terminator
    }
    return %24, %35 : memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After ConvertComplexToLibm (convert-complex-to-libm) //----- //
module {
  llvm.func @malloc(i64) -> !llvm.ptr
  omp.reduction.declare @__scf_reduction : f32 init {
  ^bb0(%arg0: f32):
    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    omp.yield(%0 : f32)
  } combiner {
  ^bb0(%arg0: f32, %arg1: f32):
    %0 = arith.addf %arg0, %arg1 : f32
    omp.yield(%0 : f32)
  } atomic {
  ^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr):
    %0 = llvm.load %arg1 : !llvm.ptr -> f32
    %1 = llvm.atomicrmw fadd %arg0, %0 monotonic : !llvm.ptr, f32
    omp.yield
  }
  func.func @SpTMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<2 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %2 = builtin.unrealized_conversion_cast %arg2 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %3 = builtin.unrealized_conversion_cast %arg3 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %4 = builtin.unrealized_conversion_cast %arg4 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = builtin.unrealized_conversion_cast %arg5 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %6 = builtin.unrealized_conversion_cast %arg6 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = builtin.unrealized_conversion_cast %arg8 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %8 = llvm.mlir.constant(1 : i64) : i64
    %c0 = arith.constant 0 : index
    %9 = builtin.unrealized_conversion_cast %c0 : index to i64
    %c32768 = arith.constant 32768 : index
    %c1 = arith.constant 1 : index
    %10 = builtin.unrealized_conversion_cast %c1 : index to i64
    %c32768_i64 = arith.constant 32768 : i64
    %c64_i64 = arith.constant 64 : i64
    %c32_i64 = arith.constant 32 : i64
    %c16_i64 = arith.constant 16 : i64
    %c0_i64 = arith.constant 0 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %c64 = arith.constant 64 : index
    %c32 = arith.constant 32 : index
    %11 = llvm.mlir.constant(32768 : index) : i64
    %12 = llvm.mlir.constant(1 : index) : i64
    %13 = llvm.mlir.null : !llvm.ptr
    %14 = llvm.getelementptr %13[32768] : (!llvm.ptr) -> !llvm.ptr, f32
    %15 = llvm.ptrtoint %14 : !llvm.ptr to i64
    %16 = llvm.call @malloc(%15) : (i64) -> !llvm.ptr
    %17 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %18 = llvm.insertvalue %16, %17[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %19 = llvm.insertvalue %16, %18[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.mlir.constant(0 : index) : i64
    %21 = llvm.insertvalue %20, %19[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %11, %21[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %12, %22[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = builtin.unrealized_conversion_cast %23 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %25 = llvm.mlir.undef : !llvm.struct<(array<3 x i64>, array<1 x i64>)>
    %26 = llvm.insertvalue %c0_i64, %25[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %27 = llvm.insertvalue %c16_i64, %26[0, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %28 = llvm.insertvalue %c32_i64, %27[0, 1] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %29 = llvm.insertvalue %c64_i64, %28[0, 2] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%30: index):  // 2 preds: ^bb0, ^bb2
    %31 = builtin.unrealized_conversion_cast %30 : index to i64
    %32 = arith.cmpi slt, %30, %c32768 : index
    cf.cond_br %32, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %33 = llvm.getelementptr %16[%31] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %cst, %33 : f32, !llvm.ptr
    %34 = arith.addi %30, %c1 : index
    cf.br ^bb1(%34 : index)
  ^bb3:  // pred: ^bb1
    %35 = llvm.insertvalue %c32768_i64, %29[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %36 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %37 = llvm.getelementptr %36[%9] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %38 = llvm.load %37 : !llvm.ptr -> i64
    %39 = builtin.unrealized_conversion_cast %38 : i64 to index
    %40 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %41 = llvm.getelementptr %40[%10] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %42 = llvm.load %41 : !llvm.ptr -> i64
    %43 = builtin.unrealized_conversion_cast %42 : i64 to index
    omp.parallel   {
      omp.wsloop   for  (%arg10) : index = (%39) to (%43) step (%c1) {
        %44 = builtin.unrealized_conversion_cast %arg10 : index to i64
        %45 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %46 = llvm.getelementptr %45[%44] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %47 = llvm.load %46 : !llvm.ptr -> i64
        %48 = builtin.unrealized_conversion_cast %47 : i64 to index
        %49 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %50 = llvm.getelementptr %49[%44] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %51 = llvm.load %50 : !llvm.ptr -> i64
        %52 = builtin.unrealized_conversion_cast %51 : i64 to index
        %53 = arith.addi %arg10, %c1 : index
        %54 = builtin.unrealized_conversion_cast %53 : index to i64
        %55 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %56 = llvm.getelementptr %55[%54] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %57 = llvm.load %56 : !llvm.ptr -> i64
        %58 = builtin.unrealized_conversion_cast %57 : i64 to index
        omp.parallel   {
          omp.wsloop   for  (%arg11) : index = (%52) to (%58) step (%c1) {
            %59 = builtin.unrealized_conversion_cast %arg11 : index to i64
            %60 = llvm.extractvalue %3[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %61 = llvm.getelementptr %60[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %62 = llvm.load %61 : !llvm.ptr -> i64
            %63 = builtin.unrealized_conversion_cast %62 : i64 to index
            %64 = arith.muli %48, %c32 : index
            %65 = arith.addi %64, %63 : index
            omp.parallel   {
              %66 = llvm.alloca %8 x f32 : (i64) -> !llvm.ptr
              omp.wsloop   for  (%arg12) : index = (%c0) to (%c64) step (%c1) {
                %67 = arith.muli %65, %c64 : index
                %68 = arith.addi %67, %arg12 : index
                %69 = builtin.unrealized_conversion_cast %68 : index to i64
                %70 = llvm.getelementptr %16[%69] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                %71 = llvm.load %70 : !llvm.ptr -> f32
                %72 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %73 = llvm.getelementptr %72[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                %74 = llvm.load %73 : !llvm.ptr -> i64
                %75 = builtin.unrealized_conversion_cast %74 : i64 to index
                %76 = arith.addi %arg11, %c1 : index
                %77 = builtin.unrealized_conversion_cast %76 : index to i64
                %78 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %79 = llvm.getelementptr %78[%77] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                %80 = llvm.load %79 : !llvm.ptr -> i64
                %81 = builtin.unrealized_conversion_cast %80 : i64 to index
                llvm.store %71, %66 : f32, !llvm.ptr
                omp.parallel   {
                  omp.wsloop   reduction(@__scf_reduction -> %66 : !llvm.ptr) for  (%arg13) : index = (%75) to (%81) step (%c1) {
                    %84 = builtin.unrealized_conversion_cast %arg13 : index to i64
                    %85 = llvm.intr.stacksave : !llvm.ptr
                    llvm.br ^bb1
                  ^bb1:  // pred: ^bb0
                    %86 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                    %87 = llvm.getelementptr %86[%84] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                    %88 = llvm.load %87 : !llvm.ptr -> i64
                    %89 = builtin.unrealized_conversion_cast %88 : i64 to index
                    %90 = arith.muli %arg12, %c64 : index
                    %91 = arith.addi %90, %89 : index
                    %92 = builtin.unrealized_conversion_cast %91 : index to i64
                    %93 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                    %94 = llvm.getelementptr %93[%84] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                    %95 = llvm.load %94 : !llvm.ptr -> f32
                    %96 = llvm.extractvalue %7[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                    %97 = llvm.getelementptr %96[%92] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                    %98 = llvm.load %97 : !llvm.ptr -> f32
                    %99 = arith.mulf %95, %98 : f32
                    omp.reduction %99, %66 : f32, !llvm.ptr
                    llvm.intr.stackrestore %85 : !llvm.ptr
                    llvm.br ^bb2
                  ^bb2:  // pred: ^bb1
                    omp.yield
                  }
                  omp.terminator
                }
                %82 = llvm.load %66 : !llvm.ptr -> f32
                %83 = llvm.getelementptr %16[%69] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                llvm.store %82, %83 : f32, !llvm.ptr
                omp.yield
              }
              omp.terminator
            }
            omp.yield
          }
          omp.terminator
        }
        omp.yield
      }
      omp.terminator
    }
    return %24, %35 : memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After ConvertVectorToLLVMPass (convert-vector-to-llvm) //----- //
module {
  llvm.func @malloc(i64) -> !llvm.ptr
  omp.reduction.declare @__scf_reduction : f32 init {
  ^bb0(%arg0: f32):
    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    omp.yield(%0 : f32)
  } combiner {
  ^bb0(%arg0: f32, %arg1: f32):
    %0 = arith.addf %arg0, %arg1 : f32
    omp.yield(%0 : f32)
  } atomic {
  ^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr):
    %0 = llvm.load %arg1 : !llvm.ptr -> f32
    %1 = llvm.atomicrmw fadd %arg0, %0 monotonic : !llvm.ptr, f32
    omp.yield
  }
  func.func @SpTMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<2 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.constant(1 : index) : i64
    %2 = llvm.mlir.constant(32768 : index) : i64
    %c32 = arith.constant 32 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c0_i64 = arith.constant 0 : i64
    %c16_i64 = arith.constant 16 : i64
    %c32_i64 = arith.constant 32 : i64
    %c64_i64 = arith.constant 64 : i64
    %c32768_i64 = arith.constant 32768 : i64
    %c1 = arith.constant 1 : index
    %c32768 = arith.constant 32768 : index
    %c0 = arith.constant 0 : index
    %3 = llvm.mlir.constant(1 : i64) : i64
    %4 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %6 = builtin.unrealized_conversion_cast %arg2 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = builtin.unrealized_conversion_cast %arg3 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %8 = builtin.unrealized_conversion_cast %arg4 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %9 = builtin.unrealized_conversion_cast %arg5 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %10 = builtin.unrealized_conversion_cast %arg6 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %11 = builtin.unrealized_conversion_cast %arg8 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %12 = builtin.unrealized_conversion_cast %c0 : index to i64
    %13 = builtin.unrealized_conversion_cast %c1 : index to i64
    %14 = llvm.mlir.null : !llvm.ptr
    %15 = llvm.getelementptr %14[32768] : (!llvm.ptr) -> !llvm.ptr, f32
    %16 = llvm.ptrtoint %15 : !llvm.ptr to i64
    %17 = llvm.call @malloc(%16) : (i64) -> !llvm.ptr
    %18 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %19 = llvm.insertvalue %17, %18[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.insertvalue %17, %19[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.insertvalue %0, %20[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %2, %21[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %1, %22[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = builtin.unrealized_conversion_cast %23 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %25 = llvm.mlir.undef : !llvm.struct<(array<3 x i64>, array<1 x i64>)>
    %26 = llvm.insertvalue %c0_i64, %25[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %27 = llvm.insertvalue %c16_i64, %26[0, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %28 = llvm.insertvalue %c32_i64, %27[0, 1] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %29 = llvm.insertvalue %c64_i64, %28[0, 2] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%30: index):  // 2 preds: ^bb0, ^bb2
    %31 = builtin.unrealized_conversion_cast %30 : index to i64
    %32 = arith.cmpi slt, %30, %c32768 : index
    cf.cond_br %32, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %33 = llvm.getelementptr %17[%31] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %cst, %33 : f32, !llvm.ptr
    %34 = arith.addi %30, %c1 : index
    cf.br ^bb1(%34 : index)
  ^bb3:  // pred: ^bb1
    %35 = llvm.insertvalue %c32768_i64, %29[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %36 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %37 = llvm.getelementptr %36[%12] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %38 = llvm.load %37 : !llvm.ptr -> i64
    %39 = builtin.unrealized_conversion_cast %38 : i64 to index
    %40 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %41 = llvm.getelementptr %40[%13] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %42 = llvm.load %41 : !llvm.ptr -> i64
    %43 = builtin.unrealized_conversion_cast %42 : i64 to index
    omp.parallel   {
      omp.wsloop   for  (%arg10) : index = (%39) to (%43) step (%c1) {
        %44 = builtin.unrealized_conversion_cast %arg10 : index to i64
        %45 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %46 = llvm.getelementptr %45[%44] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %47 = llvm.load %46 : !llvm.ptr -> i64
        %48 = builtin.unrealized_conversion_cast %47 : i64 to index
        %49 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %50 = llvm.getelementptr %49[%44] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %51 = llvm.load %50 : !llvm.ptr -> i64
        %52 = builtin.unrealized_conversion_cast %51 : i64 to index
        %53 = arith.addi %arg10, %c1 : index
        %54 = builtin.unrealized_conversion_cast %53 : index to i64
        %55 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %56 = llvm.getelementptr %55[%54] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %57 = llvm.load %56 : !llvm.ptr -> i64
        %58 = builtin.unrealized_conversion_cast %57 : i64 to index
        omp.parallel   {
          omp.wsloop   for  (%arg11) : index = (%52) to (%58) step (%c1) {
            %59 = builtin.unrealized_conversion_cast %arg11 : index to i64
            %60 = llvm.extractvalue %7[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %61 = llvm.getelementptr %60[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %62 = llvm.load %61 : !llvm.ptr -> i64
            %63 = builtin.unrealized_conversion_cast %62 : i64 to index
            %64 = arith.muli %48, %c32 : index
            %65 = arith.addi %64, %63 : index
            omp.parallel   {
              %66 = llvm.alloca %3 x f32 : (i64) -> !llvm.ptr
              omp.wsloop   for  (%arg12) : index = (%c0) to (%c64) step (%c1) {
                %67 = arith.muli %65, %c64 : index
                %68 = arith.addi %67, %arg12 : index
                %69 = builtin.unrealized_conversion_cast %68 : index to i64
                %70 = llvm.getelementptr %17[%69] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                %71 = llvm.load %70 : !llvm.ptr -> f32
                %72 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %73 = llvm.getelementptr %72[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                %74 = llvm.load %73 : !llvm.ptr -> i64
                %75 = builtin.unrealized_conversion_cast %74 : i64 to index
                %76 = arith.addi %arg11, %c1 : index
                %77 = builtin.unrealized_conversion_cast %76 : index to i64
                %78 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %79 = llvm.getelementptr %78[%77] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                %80 = llvm.load %79 : !llvm.ptr -> i64
                %81 = builtin.unrealized_conversion_cast %80 : i64 to index
                llvm.store %71, %66 : f32, !llvm.ptr
                omp.parallel   {
                  omp.wsloop   reduction(@__scf_reduction -> %66 : !llvm.ptr) for  (%arg13) : index = (%75) to (%81) step (%c1) {
                    %84 = builtin.unrealized_conversion_cast %arg13 : index to i64
                    %85 = llvm.intr.stacksave : !llvm.ptr
                    llvm.br ^bb1
                  ^bb1:  // pred: ^bb0
                    %86 = llvm.extractvalue %9[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                    %87 = llvm.getelementptr %86[%84] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                    %88 = llvm.load %87 : !llvm.ptr -> i64
                    %89 = builtin.unrealized_conversion_cast %88 : i64 to index
                    %90 = arith.muli %arg12, %c64 : index
                    %91 = arith.addi %90, %89 : index
                    %92 = builtin.unrealized_conversion_cast %91 : index to i64
                    %93 = llvm.extractvalue %10[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                    %94 = llvm.getelementptr %93[%84] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                    %95 = llvm.load %94 : !llvm.ptr -> f32
                    %96 = llvm.extractvalue %11[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                    %97 = llvm.getelementptr %96[%92] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                    %98 = llvm.load %97 : !llvm.ptr -> f32
                    %99 = arith.mulf %95, %98 : f32
                    omp.reduction %99, %66 : f32, !llvm.ptr
                    llvm.intr.stackrestore %85 : !llvm.ptr
                    llvm.br ^bb2
                  ^bb2:  // pred: ^bb1
                    omp.yield
                  }
                  omp.terminator
                }
                %82 = llvm.load %66 : !llvm.ptr -> f32
                %83 = llvm.getelementptr %17[%69] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                llvm.store %82, %83 : f32, !llvm.ptr
                omp.yield
              }
              omp.terminator
            }
            omp.yield
          }
          omp.terminator
        }
        omp.yield
      }
      omp.terminator
    }
    return %24, %35 : memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After ConvertComplexToLLVMPass (convert-complex-to-llvm) //----- //
module {
  llvm.func @malloc(i64) -> !llvm.ptr
  omp.reduction.declare @__scf_reduction : f32 init {
  ^bb0(%arg0: f32):
    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    omp.yield(%0 : f32)
  } combiner {
  ^bb0(%arg0: f32, %arg1: f32):
    %0 = arith.addf %arg0, %arg1 : f32
    omp.yield(%0 : f32)
  } atomic {
  ^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr):
    %0 = llvm.load %arg1 : !llvm.ptr -> f32
    %1 = llvm.atomicrmw fadd %arg0, %0 monotonic : !llvm.ptr, f32
    omp.yield
  }
  func.func @SpTMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<2 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.constant(1 : index) : i64
    %2 = llvm.mlir.constant(32768 : index) : i64
    %c32 = arith.constant 32 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c0_i64 = arith.constant 0 : i64
    %c16_i64 = arith.constant 16 : i64
    %c32_i64 = arith.constant 32 : i64
    %c64_i64 = arith.constant 64 : i64
    %c32768_i64 = arith.constant 32768 : i64
    %c1 = arith.constant 1 : index
    %c32768 = arith.constant 32768 : index
    %c0 = arith.constant 0 : index
    %3 = llvm.mlir.constant(1 : i64) : i64
    %4 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %6 = builtin.unrealized_conversion_cast %arg2 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = builtin.unrealized_conversion_cast %arg3 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %8 = builtin.unrealized_conversion_cast %arg4 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %9 = builtin.unrealized_conversion_cast %arg5 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %10 = builtin.unrealized_conversion_cast %arg6 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %11 = builtin.unrealized_conversion_cast %arg8 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %12 = builtin.unrealized_conversion_cast %c0 : index to i64
    %13 = builtin.unrealized_conversion_cast %c1 : index to i64
    %14 = llvm.mlir.null : !llvm.ptr
    %15 = llvm.getelementptr %14[32768] : (!llvm.ptr) -> !llvm.ptr, f32
    %16 = llvm.ptrtoint %15 : !llvm.ptr to i64
    %17 = llvm.call @malloc(%16) : (i64) -> !llvm.ptr
    %18 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %19 = llvm.insertvalue %17, %18[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.insertvalue %17, %19[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.insertvalue %0, %20[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %2, %21[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %1, %22[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = builtin.unrealized_conversion_cast %23 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %25 = llvm.mlir.undef : !llvm.struct<(array<3 x i64>, array<1 x i64>)>
    %26 = llvm.insertvalue %c0_i64, %25[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %27 = llvm.insertvalue %c16_i64, %26[0, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %28 = llvm.insertvalue %c32_i64, %27[0, 1] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %29 = llvm.insertvalue %c64_i64, %28[0, 2] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%30: index):  // 2 preds: ^bb0, ^bb2
    %31 = builtin.unrealized_conversion_cast %30 : index to i64
    %32 = arith.cmpi slt, %30, %c32768 : index
    cf.cond_br %32, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %33 = llvm.getelementptr %17[%31] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %cst, %33 : f32, !llvm.ptr
    %34 = arith.addi %30, %c1 : index
    cf.br ^bb1(%34 : index)
  ^bb3:  // pred: ^bb1
    %35 = llvm.insertvalue %c32768_i64, %29[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %36 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %37 = llvm.getelementptr %36[%12] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %38 = llvm.load %37 : !llvm.ptr -> i64
    %39 = builtin.unrealized_conversion_cast %38 : i64 to index
    %40 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %41 = llvm.getelementptr %40[%13] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %42 = llvm.load %41 : !llvm.ptr -> i64
    %43 = builtin.unrealized_conversion_cast %42 : i64 to index
    omp.parallel   {
      omp.wsloop   for  (%arg10) : index = (%39) to (%43) step (%c1) {
        %44 = builtin.unrealized_conversion_cast %arg10 : index to i64
        %45 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %46 = llvm.getelementptr %45[%44] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %47 = llvm.load %46 : !llvm.ptr -> i64
        %48 = builtin.unrealized_conversion_cast %47 : i64 to index
        %49 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %50 = llvm.getelementptr %49[%44] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %51 = llvm.load %50 : !llvm.ptr -> i64
        %52 = builtin.unrealized_conversion_cast %51 : i64 to index
        %53 = arith.addi %arg10, %c1 : index
        %54 = builtin.unrealized_conversion_cast %53 : index to i64
        %55 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %56 = llvm.getelementptr %55[%54] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %57 = llvm.load %56 : !llvm.ptr -> i64
        %58 = builtin.unrealized_conversion_cast %57 : i64 to index
        omp.parallel   {
          omp.wsloop   for  (%arg11) : index = (%52) to (%58) step (%c1) {
            %59 = builtin.unrealized_conversion_cast %arg11 : index to i64
            %60 = llvm.extractvalue %7[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %61 = llvm.getelementptr %60[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %62 = llvm.load %61 : !llvm.ptr -> i64
            %63 = builtin.unrealized_conversion_cast %62 : i64 to index
            %64 = arith.muli %48, %c32 : index
            %65 = arith.addi %64, %63 : index
            omp.parallel   {
              %66 = llvm.alloca %3 x f32 : (i64) -> !llvm.ptr
              omp.wsloop   for  (%arg12) : index = (%c0) to (%c64) step (%c1) {
                %67 = arith.muli %65, %c64 : index
                %68 = arith.addi %67, %arg12 : index
                %69 = builtin.unrealized_conversion_cast %68 : index to i64
                %70 = llvm.getelementptr %17[%69] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                %71 = llvm.load %70 : !llvm.ptr -> f32
                %72 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %73 = llvm.getelementptr %72[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                %74 = llvm.load %73 : !llvm.ptr -> i64
                %75 = builtin.unrealized_conversion_cast %74 : i64 to index
                %76 = arith.addi %arg11, %c1 : index
                %77 = builtin.unrealized_conversion_cast %76 : index to i64
                %78 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %79 = llvm.getelementptr %78[%77] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                %80 = llvm.load %79 : !llvm.ptr -> i64
                %81 = builtin.unrealized_conversion_cast %80 : i64 to index
                llvm.store %71, %66 : f32, !llvm.ptr
                omp.parallel   {
                  omp.wsloop   reduction(@__scf_reduction -> %66 : !llvm.ptr) for  (%arg13) : index = (%75) to (%81) step (%c1) {
                    %84 = builtin.unrealized_conversion_cast %arg13 : index to i64
                    %85 = llvm.intr.stacksave : !llvm.ptr
                    llvm.br ^bb1
                  ^bb1:  // pred: ^bb0
                    %86 = llvm.extractvalue %9[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                    %87 = llvm.getelementptr %86[%84] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                    %88 = llvm.load %87 : !llvm.ptr -> i64
                    %89 = builtin.unrealized_conversion_cast %88 : i64 to index
                    %90 = arith.muli %arg12, %c64 : index
                    %91 = arith.addi %90, %89 : index
                    %92 = builtin.unrealized_conversion_cast %91 : index to i64
                    %93 = llvm.extractvalue %10[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                    %94 = llvm.getelementptr %93[%84] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                    %95 = llvm.load %94 : !llvm.ptr -> f32
                    %96 = llvm.extractvalue %11[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                    %97 = llvm.getelementptr %96[%92] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                    %98 = llvm.load %97 : !llvm.ptr -> f32
                    %99 = arith.mulf %95, %98 : f32
                    omp.reduction %99, %66 : f32, !llvm.ptr
                    llvm.intr.stackrestore %85 : !llvm.ptr
                    llvm.br ^bb2
                  ^bb2:  // pred: ^bb1
                    omp.yield
                  }
                  omp.terminator
                }
                %82 = llvm.load %66 : !llvm.ptr -> f32
                %83 = llvm.getelementptr %17[%69] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                llvm.store %82, %83 : f32, !llvm.ptr
                omp.yield
              }
              omp.terminator
            }
            omp.yield
          }
          omp.terminator
        }
        omp.yield
      }
      omp.terminator
    }
    return %24, %35 : memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After ConvertVectorToLLVMPass (convert-vector-to-llvm) //----- //
module {
  llvm.func @malloc(i64) -> !llvm.ptr
  omp.reduction.declare @__scf_reduction : f32 init {
  ^bb0(%arg0: f32):
    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    omp.yield(%0 : f32)
  } combiner {
  ^bb0(%arg0: f32, %arg1: f32):
    %0 = arith.addf %arg0, %arg1 : f32
    omp.yield(%0 : f32)
  } atomic {
  ^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr):
    %0 = llvm.load %arg1 : !llvm.ptr -> f32
    %1 = llvm.atomicrmw fadd %arg0, %0 monotonic : !llvm.ptr, f32
    omp.yield
  }
  func.func @SpTMMul.Z.0.main(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xindex>, %arg3: memref<?xindex>, %arg4: memref<?xindex>, %arg5: memref<?xindex>, %arg6: memref<?xf32>, %arg7: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg8: memref<?xf32>, %arg9: !llvm.struct<(array<2 x i64>, array<1 x i64>)>) -> (memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.constant(1 : index) : i64
    %2 = llvm.mlir.constant(32768 : index) : i64
    %c32 = arith.constant 32 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c0_i64 = arith.constant 0 : i64
    %c16_i64 = arith.constant 16 : i64
    %c32_i64 = arith.constant 32 : i64
    %c64_i64 = arith.constant 64 : i64
    %c32768_i64 = arith.constant 32768 : i64
    %c1 = arith.constant 1 : index
    %c32768 = arith.constant 32768 : index
    %c0 = arith.constant 0 : index
    %3 = llvm.mlir.constant(1 : i64) : i64
    %4 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %6 = builtin.unrealized_conversion_cast %arg2 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = builtin.unrealized_conversion_cast %arg3 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %8 = builtin.unrealized_conversion_cast %arg4 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %9 = builtin.unrealized_conversion_cast %arg5 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %10 = builtin.unrealized_conversion_cast %arg6 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %11 = builtin.unrealized_conversion_cast %arg8 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %12 = builtin.unrealized_conversion_cast %c0 : index to i64
    %13 = builtin.unrealized_conversion_cast %c1 : index to i64
    %14 = llvm.mlir.null : !llvm.ptr
    %15 = llvm.getelementptr %14[32768] : (!llvm.ptr) -> !llvm.ptr, f32
    %16 = llvm.ptrtoint %15 : !llvm.ptr to i64
    %17 = llvm.call @malloc(%16) : (i64) -> !llvm.ptr
    %18 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %19 = llvm.insertvalue %17, %18[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.insertvalue %17, %19[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.insertvalue %0, %20[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %2, %21[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %1, %22[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = builtin.unrealized_conversion_cast %23 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %25 = llvm.mlir.undef : !llvm.struct<(array<3 x i64>, array<1 x i64>)>
    %26 = llvm.insertvalue %c0_i64, %25[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %27 = llvm.insertvalue %c16_i64, %26[0, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %28 = llvm.insertvalue %c32_i64, %27[0, 1] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %29 = llvm.insertvalue %c64_i64, %28[0, 2] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%30: index):  // 2 preds: ^bb0, ^bb2
    %31 = builtin.unrealized_conversion_cast %30 : index to i64
    %32 = arith.cmpi slt, %30, %c32768 : index
    cf.cond_br %32, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %33 = llvm.getelementptr %17[%31] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %cst, %33 : f32, !llvm.ptr
    %34 = arith.addi %30, %c1 : index
    cf.br ^bb1(%34 : index)
  ^bb3:  // pred: ^bb1
    %35 = llvm.insertvalue %c32768_i64, %29[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %36 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %37 = llvm.getelementptr %36[%12] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %38 = llvm.load %37 : !llvm.ptr -> i64
    %39 = builtin.unrealized_conversion_cast %38 : i64 to index
    %40 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %41 = llvm.getelementptr %40[%13] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %42 = llvm.load %41 : !llvm.ptr -> i64
    %43 = builtin.unrealized_conversion_cast %42 : i64 to index
    omp.parallel   {
      omp.wsloop   for  (%arg10) : index = (%39) to (%43) step (%c1) {
        %44 = builtin.unrealized_conversion_cast %arg10 : index to i64
        %45 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %46 = llvm.getelementptr %45[%44] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %47 = llvm.load %46 : !llvm.ptr -> i64
        %48 = builtin.unrealized_conversion_cast %47 : i64 to index
        %49 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %50 = llvm.getelementptr %49[%44] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %51 = llvm.load %50 : !llvm.ptr -> i64
        %52 = builtin.unrealized_conversion_cast %51 : i64 to index
        %53 = arith.addi %arg10, %c1 : index
        %54 = builtin.unrealized_conversion_cast %53 : index to i64
        %55 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %56 = llvm.getelementptr %55[%54] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %57 = llvm.load %56 : !llvm.ptr -> i64
        %58 = builtin.unrealized_conversion_cast %57 : i64 to index
        omp.parallel   {
          omp.wsloop   for  (%arg11) : index = (%52) to (%58) step (%c1) {
            %59 = builtin.unrealized_conversion_cast %arg11 : index to i64
            %60 = llvm.extractvalue %7[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %61 = llvm.getelementptr %60[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %62 = llvm.load %61 : !llvm.ptr -> i64
            %63 = builtin.unrealized_conversion_cast %62 : i64 to index
            %64 = arith.muli %48, %c32 : index
            %65 = arith.addi %64, %63 : index
            omp.parallel   {
              %66 = llvm.alloca %3 x f32 : (i64) -> !llvm.ptr
              omp.wsloop   for  (%arg12) : index = (%c0) to (%c64) step (%c1) {
                %67 = arith.muli %65, %c64 : index
                %68 = arith.addi %67, %arg12 : index
                %69 = builtin.unrealized_conversion_cast %68 : index to i64
                %70 = llvm.getelementptr %17[%69] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                %71 = llvm.load %70 : !llvm.ptr -> f32
                %72 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %73 = llvm.getelementptr %72[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                %74 = llvm.load %73 : !llvm.ptr -> i64
                %75 = builtin.unrealized_conversion_cast %74 : i64 to index
                %76 = arith.addi %arg11, %c1 : index
                %77 = builtin.unrealized_conversion_cast %76 : index to i64
                %78 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %79 = llvm.getelementptr %78[%77] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                %80 = llvm.load %79 : !llvm.ptr -> i64
                %81 = builtin.unrealized_conversion_cast %80 : i64 to index
                llvm.store %71, %66 : f32, !llvm.ptr
                omp.parallel   {
                  omp.wsloop   reduction(@__scf_reduction -> %66 : !llvm.ptr) for  (%arg13) : index = (%75) to (%81) step (%c1) {
                    %84 = builtin.unrealized_conversion_cast %arg13 : index to i64
                    %85 = llvm.intr.stacksave : !llvm.ptr
                    llvm.br ^bb1
                  ^bb1:  // pred: ^bb0
                    %86 = llvm.extractvalue %9[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                    %87 = llvm.getelementptr %86[%84] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                    %88 = llvm.load %87 : !llvm.ptr -> i64
                    %89 = builtin.unrealized_conversion_cast %88 : i64 to index
                    %90 = arith.muli %arg12, %c64 : index
                    %91 = arith.addi %90, %89 : index
                    %92 = builtin.unrealized_conversion_cast %91 : index to i64
                    %93 = llvm.extractvalue %10[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                    %94 = llvm.getelementptr %93[%84] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                    %95 = llvm.load %94 : !llvm.ptr -> f32
                    %96 = llvm.extractvalue %11[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                    %97 = llvm.getelementptr %96[%92] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                    %98 = llvm.load %97 : !llvm.ptr -> f32
                    %99 = arith.mulf %95, %98 : f32
                    omp.reduction %99, %66 : f32, !llvm.ptr
                    llvm.intr.stackrestore %85 : !llvm.ptr
                    llvm.br ^bb2
                  ^bb2:  // pred: ^bb1
                    omp.yield
                  }
                  omp.terminator
                }
                %82 = llvm.load %66 : !llvm.ptr -> f32
                %83 = llvm.getelementptr %17[%69] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                llvm.store %82, %83 : f32, !llvm.ptr
                omp.yield
              }
              omp.terminator
            }
            omp.yield
          }
          omp.terminator
        }
        omp.yield
      }
      omp.terminator
    }
    return %24, %35 : memref<?xf32>, !llvm.struct<(array<3 x i64>, array<1 x i64>)>
  }
}


// -----// IR Dump After ConvertOpenMPToLLVMPass (convert-openmp-to-llvm) //----- //
module {
  llvm.func @malloc(i64) -> !llvm.ptr
  omp.reduction.declare @__scf_reduction : f32 init {
  ^bb0(%arg0: f32):
    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    omp.yield(%0 : f32)
  } combiner {
  ^bb0(%arg0: f32, %arg1: f32):
    %0 = llvm.fadd %arg0, %arg1  : f32
    omp.yield(%0 : f32)
  } atomic {
  ^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr):
    %0 = llvm.load %arg1 : !llvm.ptr -> f32
    %1 = llvm.atomicrmw fadd %arg0, %0 monotonic : !llvm.ptr, f32
    omp.yield
  }
  llvm.func @SpTMMul.Z.0.main(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: !llvm.ptr, %arg6: !llvm.ptr, %arg7: i64, %arg8: i64, %arg9: i64, %arg10: !llvm.ptr, %arg11: !llvm.ptr, %arg12: i64, %arg13: i64, %arg14: i64, %arg15: !llvm.ptr, %arg16: !llvm.ptr, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: !llvm.ptr, %arg21: !llvm.ptr, %arg22: i64, %arg23: i64, %arg24: i64, %arg25: !llvm.ptr, %arg26: !llvm.ptr, %arg27: i64, %arg28: i64, %arg29: i64, %arg30: !llvm.ptr, %arg31: !llvm.ptr, %arg32: i64, %arg33: i64, %arg34: i64, %arg35: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg36: !llvm.ptr, %arg37: !llvm.ptr, %arg38: i64, %arg39: i64, %arg40: i64, %arg41: !llvm.struct<(array<2 x i64>, array<1 x i64>)>) -> !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<3 x i64>, array<1 x i64>)>)> attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = llvm.insertvalue %arg0, %0[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %2 = llvm.insertvalue %arg1, %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %3 = llvm.insertvalue %arg2, %2[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %4 = llvm.insertvalue %arg3, %3[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %5 = llvm.insertvalue %arg4, %4[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %6 = builtin.unrealized_conversion_cast %5 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %7 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %8 = llvm.insertvalue %arg5, %7[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %9 = llvm.insertvalue %arg6, %8[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %10 = llvm.insertvalue %arg7, %9[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %11 = llvm.insertvalue %arg8, %10[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %12 = llvm.insertvalue %arg9, %11[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %13 = builtin.unrealized_conversion_cast %12 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %14 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %15 = llvm.insertvalue %arg10, %14[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.insertvalue %arg11, %15[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.insertvalue %arg12, %16[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.insertvalue %arg13, %17[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %19 = llvm.insertvalue %arg14, %18[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = builtin.unrealized_conversion_cast %19 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %21 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %22 = llvm.insertvalue %arg15, %21[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %arg16, %22[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = llvm.insertvalue %arg17, %23[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %25 = llvm.insertvalue %arg18, %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %26 = llvm.insertvalue %arg19, %25[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %27 = builtin.unrealized_conversion_cast %26 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %28 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %29 = llvm.insertvalue %arg20, %28[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.insertvalue %arg21, %29[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %31 = llvm.insertvalue %arg22, %30[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %32 = llvm.insertvalue %arg23, %31[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.insertvalue %arg24, %32[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = builtin.unrealized_conversion_cast %33 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %35 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %36 = llvm.insertvalue %arg25, %35[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %37 = llvm.insertvalue %arg26, %36[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %38 = llvm.insertvalue %arg27, %37[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %39 = llvm.insertvalue %arg28, %38[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %40 = llvm.insertvalue %arg29, %39[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %41 = builtin.unrealized_conversion_cast %40 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %42 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %43 = llvm.insertvalue %arg30, %42[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %44 = llvm.insertvalue %arg31, %43[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %45 = llvm.insertvalue %arg32, %44[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %46 = llvm.insertvalue %arg33, %45[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %47 = llvm.insertvalue %arg34, %46[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %48 = builtin.unrealized_conversion_cast %47 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %49 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %50 = llvm.insertvalue %arg36, %49[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %51 = llvm.insertvalue %arg37, %50[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %52 = llvm.insertvalue %arg38, %51[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %53 = llvm.insertvalue %arg39, %52[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %54 = llvm.insertvalue %arg40, %53[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %55 = builtin.unrealized_conversion_cast %54 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %56 = llvm.mlir.constant(0 : index) : i64
    %57 = llvm.mlir.constant(1 : index) : i64
    %58 = llvm.mlir.constant(32768 : index) : i64
    %59 = llvm.mlir.constant(32 : index) : i64
    %60 = llvm.mlir.constant(64 : index) : i64
    %61 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %62 = llvm.mlir.constant(0 : i64) : i64
    %63 = llvm.mlir.constant(16 : i64) : i64
    %64 = llvm.mlir.constant(32 : i64) : i64
    %65 = llvm.mlir.constant(64 : i64) : i64
    %66 = llvm.mlir.constant(32768 : i64) : i64
    %67 = llvm.mlir.constant(1 : index) : i64
    %68 = builtin.unrealized_conversion_cast %67 : i64 to index
    %69 = llvm.mlir.constant(32768 : index) : i64
    %70 = llvm.mlir.constant(0 : index) : i64
    %71 = builtin.unrealized_conversion_cast %70 : i64 to index
    %72 = llvm.mlir.constant(1 : i64) : i64
    %73 = builtin.unrealized_conversion_cast %6 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %74 = builtin.unrealized_conversion_cast %13 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %75 = builtin.unrealized_conversion_cast %20 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %76 = builtin.unrealized_conversion_cast %27 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %77 = builtin.unrealized_conversion_cast %34 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %78 = builtin.unrealized_conversion_cast %41 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %79 = builtin.unrealized_conversion_cast %48 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %80 = builtin.unrealized_conversion_cast %55 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %81 = builtin.unrealized_conversion_cast %71 : index to i64
    %82 = builtin.unrealized_conversion_cast %68 : index to i64
    %83 = llvm.mlir.null : !llvm.ptr
    %84 = llvm.getelementptr %83[32768] : (!llvm.ptr) -> !llvm.ptr, f32
    %85 = llvm.ptrtoint %84 : !llvm.ptr to i64
    %86 = llvm.call @malloc(%85) : (i64) -> !llvm.ptr
    %87 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %88 = llvm.insertvalue %86, %87[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %89 = llvm.insertvalue %86, %88[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %90 = llvm.insertvalue %56, %89[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %91 = llvm.insertvalue %58, %90[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %92 = llvm.insertvalue %57, %91[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %93 = builtin.unrealized_conversion_cast %92 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %94 = llvm.mlir.undef : !llvm.struct<(array<3 x i64>, array<1 x i64>)>
    %95 = llvm.insertvalue %62, %94[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %96 = llvm.insertvalue %63, %95[0, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %97 = llvm.insertvalue %64, %96[0, 1] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %98 = llvm.insertvalue %65, %97[0, 2] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    llvm.br ^bb1(%70 : i64)
  ^bb1(%99: i64):  // 2 preds: ^bb0, ^bb2
    %100 = builtin.unrealized_conversion_cast %99 : i64 to index
    %101 = builtin.unrealized_conversion_cast %100 : index to i64
    %102 = llvm.icmp "slt" %99, %69 : i64
    llvm.cond_br %102, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %103 = llvm.getelementptr %86[%101] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %61, %103 : f32, !llvm.ptr
    %104 = llvm.add %99, %67  : i64
    llvm.br ^bb1(%104 : i64)
  ^bb3:  // pred: ^bb1
    %105 = llvm.insertvalue %66, %98[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %106 = llvm.extractvalue %73[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %107 = llvm.getelementptr %106[%81] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %108 = llvm.load %107 : !llvm.ptr -> i64
    %109 = builtin.unrealized_conversion_cast %108 : i64 to index
    %110 = llvm.extractvalue %73[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %111 = llvm.getelementptr %110[%82] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %112 = llvm.load %111 : !llvm.ptr -> i64
    %113 = builtin.unrealized_conversion_cast %112 : i64 to index
    omp.parallel   {
      omp.wsloop   for  (%arg42) : i64 = (%108) to (%112) step (%67) {
        %117 = builtin.unrealized_conversion_cast %arg42 : i64 to index
        %118 = builtin.unrealized_conversion_cast %117 : index to i64
        %119 = llvm.extractvalue %74[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %120 = llvm.getelementptr %119[%118] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %121 = llvm.load %120 : !llvm.ptr -> i64
        %122 = builtin.unrealized_conversion_cast %121 : i64 to index
        %123 = llvm.extractvalue %75[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %124 = llvm.getelementptr %123[%118] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %125 = llvm.load %124 : !llvm.ptr -> i64
        %126 = builtin.unrealized_conversion_cast %125 : i64 to index
        %127 = llvm.add %arg42, %67  : i64
        %128 = builtin.unrealized_conversion_cast %127 : i64 to index
        %129 = builtin.unrealized_conversion_cast %128 : index to i64
        %130 = llvm.extractvalue %75[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %131 = llvm.getelementptr %130[%129] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %132 = llvm.load %131 : !llvm.ptr -> i64
        %133 = builtin.unrealized_conversion_cast %132 : i64 to index
        omp.parallel   {
          omp.wsloop   for  (%arg43) : i64 = (%125) to (%132) step (%67) {
            %134 = builtin.unrealized_conversion_cast %arg43 : i64 to index
            %135 = builtin.unrealized_conversion_cast %134 : index to i64
            %136 = llvm.extractvalue %76[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %137 = llvm.getelementptr %136[%135] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %138 = llvm.load %137 : !llvm.ptr -> i64
            %139 = builtin.unrealized_conversion_cast %138 : i64 to index
            %140 = llvm.mul %121, %59  : i64
            %141 = llvm.add %140, %138  : i64
            omp.parallel   {
              %142 = llvm.alloca %72 x f32 : (i64) -> !llvm.ptr
              omp.wsloop   for  (%arg44) : i64 = (%70) to (%60) step (%67) {
                %143 = llvm.mul %141, %60  : i64
                %144 = llvm.add %143, %arg44  : i64
                %145 = builtin.unrealized_conversion_cast %144 : i64 to index
                %146 = builtin.unrealized_conversion_cast %145 : index to i64
                %147 = llvm.getelementptr %86[%146] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                %148 = llvm.load %147 : !llvm.ptr -> f32
                %149 = llvm.extractvalue %77[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %150 = llvm.getelementptr %149[%135] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                %151 = llvm.load %150 : !llvm.ptr -> i64
                %152 = builtin.unrealized_conversion_cast %151 : i64 to index
                %153 = llvm.add %arg43, %67  : i64
                %154 = builtin.unrealized_conversion_cast %153 : i64 to index
                %155 = builtin.unrealized_conversion_cast %154 : index to i64
                %156 = llvm.extractvalue %77[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %157 = llvm.getelementptr %156[%155] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                %158 = llvm.load %157 : !llvm.ptr -> i64
                %159 = builtin.unrealized_conversion_cast %158 : i64 to index
                llvm.store %148, %142 : f32, !llvm.ptr
                omp.parallel   {
                  omp.wsloop   reduction(@__scf_reduction -> %142 : !llvm.ptr) for  (%arg45) : i64 = (%151) to (%158) step (%67) {
                    %162 = builtin.unrealized_conversion_cast %arg45 : i64 to index
                    %163 = builtin.unrealized_conversion_cast %162 : index to i64
                    %164 = llvm.intr.stacksave : !llvm.ptr
                    llvm.br ^bb1
                  ^bb1:  // pred: ^bb0
                    %165 = llvm.extractvalue %78[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                    %166 = llvm.getelementptr %165[%163] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                    %167 = llvm.load %166 : !llvm.ptr -> i64
                    %168 = builtin.unrealized_conversion_cast %167 : i64 to index
                    %169 = llvm.mul %arg44, %60  : i64
                    %170 = llvm.add %169, %167  : i64
                    %171 = builtin.unrealized_conversion_cast %170 : i64 to index
                    %172 = builtin.unrealized_conversion_cast %171 : index to i64
                    %173 = llvm.extractvalue %79[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                    %174 = llvm.getelementptr %173[%163] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                    %175 = llvm.load %174 : !llvm.ptr -> f32
                    %176 = llvm.extractvalue %80[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                    %177 = llvm.getelementptr %176[%172] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                    %178 = llvm.load %177 : !llvm.ptr -> f32
                    %179 = llvm.fmul %175, %178  : f32
                    omp.reduction %179, %142 : f32, !llvm.ptr
                    llvm.intr.stackrestore %164 : !llvm.ptr
                    llvm.br ^bb2
                  ^bb2:  // pred: ^bb1
                    omp.yield
                  }
                  omp.terminator
                }
                %160 = llvm.load %142 : !llvm.ptr -> f32
                %161 = llvm.getelementptr %86[%146] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                llvm.store %160, %161 : f32, !llvm.ptr
                omp.yield
              }
              omp.terminator
            }
            omp.yield
          }
          omp.terminator
        }
        omp.yield
      }
      omp.terminator
    }
    %114 = llvm.mlir.undef : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<3 x i64>, array<1 x i64>)>)>
    %115 = llvm.insertvalue %92, %114[0] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<3 x i64>, array<1 x i64>)>)> 
    %116 = llvm.insertvalue %105, %115[1] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<3 x i64>, array<1 x i64>)>)> 
    llvm.return %116 : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<3 x i64>, array<1 x i64>)>)>
  }
  llvm.func @_mlir_ciface_SpTMMul.Z.0.main(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr, %arg3: !llvm.ptr, %arg4: !llvm.ptr, %arg5: !llvm.ptr, %arg6: !llvm.ptr, %arg7: !llvm.ptr, %arg8: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg9: !llvm.ptr, %arg10: !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %5 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %6 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = llvm.extractvalue %6[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %8 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %9 = llvm.extractvalue %6[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %10 = llvm.extractvalue %6[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %11 = llvm.extractvalue %6[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %12 = llvm.load %arg3 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %13 = llvm.extractvalue %12[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.extractvalue %12[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.extractvalue %12[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.extractvalue %12[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.extractvalue %12[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.load %arg4 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %19 = llvm.extractvalue %18[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.extractvalue %18[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.extractvalue %18[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.extractvalue %18[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.extractvalue %18[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = llvm.load %arg5 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %25 = llvm.extractvalue %24[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %26 = llvm.extractvalue %24[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %27 = llvm.extractvalue %24[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %28 = llvm.extractvalue %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %29 = llvm.extractvalue %24[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.load %arg6 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %31 = llvm.extractvalue %30[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %32 = llvm.extractvalue %30[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.extractvalue %30[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = llvm.extractvalue %30[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %35 = llvm.extractvalue %30[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %36 = llvm.load %arg7 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %37 = llvm.extractvalue %36[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %38 = llvm.extractvalue %36[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %39 = llvm.extractvalue %36[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %40 = llvm.extractvalue %36[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %41 = llvm.extractvalue %36[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %42 = llvm.load %arg9 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %43 = llvm.extractvalue %42[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %44 = llvm.extractvalue %42[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %45 = llvm.extractvalue %42[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %46 = llvm.extractvalue %42[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %47 = llvm.extractvalue %42[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %48 = llvm.call @SpTMMul.Z.0.main(%1, %2, %3, %4, %5, %7, %8, %9, %10, %11, %13, %14, %15, %16, %17, %19, %20, %21, %22, %23, %25, %26, %27, %28, %29, %31, %32, %33, %34, %35, %37, %38, %39, %40, %41, %arg8, %43, %44, %45, %46, %47, %arg10) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.struct<(array<3 x i64>, array<7 x i64>)>, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) -> !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<3 x i64>, array<1 x i64>)>)>
    llvm.store %48, %arg0 : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<3 x i64>, array<1 x i64>)>)>, !llvm.ptr
    llvm.return
  }
}


// -----// IR Dump After ConvertFuncToLLVMPass (convert-func-to-llvm) //----- //
module attributes {llvm.data_layout = ""} {
  llvm.func @malloc(i64) -> !llvm.ptr
  omp.reduction.declare @__scf_reduction : f32 init {
  ^bb0(%arg0: f32):
    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    omp.yield(%0 : f32)
  } combiner {
  ^bb0(%arg0: f32, %arg1: f32):
    %0 = llvm.fadd %arg0, %arg1  : f32
    omp.yield(%0 : f32)
  } atomic {
  ^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr):
    %0 = llvm.load %arg1 : !llvm.ptr -> f32
    %1 = llvm.atomicrmw fadd %arg0, %0 monotonic : !llvm.ptr, f32
    omp.yield
  }
  llvm.func @SpTMMul.Z.0.main(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: !llvm.ptr, %arg6: !llvm.ptr, %arg7: i64, %arg8: i64, %arg9: i64, %arg10: !llvm.ptr, %arg11: !llvm.ptr, %arg12: i64, %arg13: i64, %arg14: i64, %arg15: !llvm.ptr, %arg16: !llvm.ptr, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: !llvm.ptr, %arg21: !llvm.ptr, %arg22: i64, %arg23: i64, %arg24: i64, %arg25: !llvm.ptr, %arg26: !llvm.ptr, %arg27: i64, %arg28: i64, %arg29: i64, %arg30: !llvm.ptr, %arg31: !llvm.ptr, %arg32: i64, %arg33: i64, %arg34: i64, %arg35: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg36: !llvm.ptr, %arg37: !llvm.ptr, %arg38: i64, %arg39: i64, %arg40: i64, %arg41: !llvm.struct<(array<2 x i64>, array<1 x i64>)>) -> !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<3 x i64>, array<1 x i64>)>)> attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = llvm.insertvalue %arg0, %0[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %2 = llvm.insertvalue %arg1, %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %3 = llvm.insertvalue %arg2, %2[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %4 = llvm.insertvalue %arg3, %3[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %5 = llvm.insertvalue %arg4, %4[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %6 = builtin.unrealized_conversion_cast %5 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %7 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %8 = llvm.insertvalue %arg5, %7[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %9 = llvm.insertvalue %arg6, %8[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %10 = llvm.insertvalue %arg7, %9[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %11 = llvm.insertvalue %arg8, %10[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %12 = llvm.insertvalue %arg9, %11[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %13 = builtin.unrealized_conversion_cast %12 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %14 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %15 = llvm.insertvalue %arg10, %14[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.insertvalue %arg11, %15[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.insertvalue %arg12, %16[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.insertvalue %arg13, %17[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %19 = llvm.insertvalue %arg14, %18[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = builtin.unrealized_conversion_cast %19 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %21 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %22 = llvm.insertvalue %arg15, %21[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %arg16, %22[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = llvm.insertvalue %arg17, %23[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %25 = llvm.insertvalue %arg18, %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %26 = llvm.insertvalue %arg19, %25[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %27 = builtin.unrealized_conversion_cast %26 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %28 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %29 = llvm.insertvalue %arg20, %28[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.insertvalue %arg21, %29[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %31 = llvm.insertvalue %arg22, %30[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %32 = llvm.insertvalue %arg23, %31[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.insertvalue %arg24, %32[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = builtin.unrealized_conversion_cast %33 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %35 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %36 = llvm.insertvalue %arg25, %35[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %37 = llvm.insertvalue %arg26, %36[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %38 = llvm.insertvalue %arg27, %37[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %39 = llvm.insertvalue %arg28, %38[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %40 = llvm.insertvalue %arg29, %39[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %41 = builtin.unrealized_conversion_cast %40 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %42 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %43 = llvm.insertvalue %arg30, %42[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %44 = llvm.insertvalue %arg31, %43[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %45 = llvm.insertvalue %arg32, %44[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %46 = llvm.insertvalue %arg33, %45[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %47 = llvm.insertvalue %arg34, %46[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %48 = builtin.unrealized_conversion_cast %47 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %49 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %50 = llvm.insertvalue %arg36, %49[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %51 = llvm.insertvalue %arg37, %50[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %52 = llvm.insertvalue %arg38, %51[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %53 = llvm.insertvalue %arg39, %52[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %54 = llvm.insertvalue %arg40, %53[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %55 = builtin.unrealized_conversion_cast %54 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %56 = llvm.mlir.constant(0 : index) : i64
    %57 = llvm.mlir.constant(1 : index) : i64
    %58 = llvm.mlir.constant(32768 : index) : i64
    %59 = llvm.mlir.constant(32 : index) : i64
    %60 = llvm.mlir.constant(64 : index) : i64
    %61 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %62 = llvm.mlir.constant(0 : i64) : i64
    %63 = llvm.mlir.constant(16 : i64) : i64
    %64 = llvm.mlir.constant(32 : i64) : i64
    %65 = llvm.mlir.constant(64 : i64) : i64
    %66 = llvm.mlir.constant(32768 : i64) : i64
    %67 = llvm.mlir.constant(1 : index) : i64
    %68 = builtin.unrealized_conversion_cast %67 : i64 to index
    %69 = llvm.mlir.constant(32768 : index) : i64
    %70 = llvm.mlir.constant(0 : index) : i64
    %71 = builtin.unrealized_conversion_cast %70 : i64 to index
    %72 = llvm.mlir.constant(1 : i64) : i64
    %73 = builtin.unrealized_conversion_cast %6 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %74 = builtin.unrealized_conversion_cast %13 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %75 = builtin.unrealized_conversion_cast %20 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %76 = builtin.unrealized_conversion_cast %27 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %77 = builtin.unrealized_conversion_cast %34 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %78 = builtin.unrealized_conversion_cast %41 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %79 = builtin.unrealized_conversion_cast %48 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %80 = builtin.unrealized_conversion_cast %55 : memref<?xf32> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %81 = builtin.unrealized_conversion_cast %71 : index to i64
    %82 = builtin.unrealized_conversion_cast %68 : index to i64
    %83 = llvm.mlir.null : !llvm.ptr
    %84 = llvm.getelementptr %83[32768] : (!llvm.ptr) -> !llvm.ptr, f32
    %85 = llvm.ptrtoint %84 : !llvm.ptr to i64
    %86 = llvm.call @malloc(%85) : (i64) -> !llvm.ptr
    %87 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %88 = llvm.insertvalue %86, %87[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %89 = llvm.insertvalue %86, %88[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %90 = llvm.insertvalue %56, %89[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %91 = llvm.insertvalue %58, %90[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %92 = llvm.insertvalue %57, %91[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %93 = builtin.unrealized_conversion_cast %92 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf32>
    %94 = llvm.mlir.undef : !llvm.struct<(array<3 x i64>, array<1 x i64>)>
    %95 = llvm.insertvalue %62, %94[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %96 = llvm.insertvalue %63, %95[0, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %97 = llvm.insertvalue %64, %96[0, 1] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %98 = llvm.insertvalue %65, %97[0, 2] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    llvm.br ^bb1(%70 : i64)
  ^bb1(%99: i64):  // 2 preds: ^bb0, ^bb2
    %100 = builtin.unrealized_conversion_cast %99 : i64 to index
    %101 = builtin.unrealized_conversion_cast %100 : index to i64
    %102 = llvm.icmp "slt" %99, %69 : i64
    llvm.cond_br %102, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %103 = llvm.getelementptr %86[%101] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %61, %103 : f32, !llvm.ptr
    %104 = llvm.add %99, %67  : i64
    llvm.br ^bb1(%104 : i64)
  ^bb3:  // pred: ^bb1
    %105 = llvm.insertvalue %66, %98[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %106 = llvm.extractvalue %73[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %107 = llvm.getelementptr %106[%81] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %108 = llvm.load %107 : !llvm.ptr -> i64
    %109 = builtin.unrealized_conversion_cast %108 : i64 to index
    %110 = llvm.extractvalue %73[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %111 = llvm.getelementptr %110[%82] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %112 = llvm.load %111 : !llvm.ptr -> i64
    %113 = builtin.unrealized_conversion_cast %112 : i64 to index
    omp.parallel   {
      omp.wsloop   for  (%arg42) : i64 = (%108) to (%112) step (%67) {
        %117 = builtin.unrealized_conversion_cast %arg42 : i64 to index
        %118 = builtin.unrealized_conversion_cast %117 : index to i64
        %119 = llvm.extractvalue %74[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %120 = llvm.getelementptr %119[%118] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %121 = llvm.load %120 : !llvm.ptr -> i64
        %122 = builtin.unrealized_conversion_cast %121 : i64 to index
        %123 = llvm.extractvalue %75[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %124 = llvm.getelementptr %123[%118] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %125 = llvm.load %124 : !llvm.ptr -> i64
        %126 = builtin.unrealized_conversion_cast %125 : i64 to index
        %127 = llvm.add %arg42, %67  : i64
        %128 = builtin.unrealized_conversion_cast %127 : i64 to index
        %129 = builtin.unrealized_conversion_cast %128 : index to i64
        %130 = llvm.extractvalue %75[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %131 = llvm.getelementptr %130[%129] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %132 = llvm.load %131 : !llvm.ptr -> i64
        %133 = builtin.unrealized_conversion_cast %132 : i64 to index
        omp.parallel   {
          omp.wsloop   for  (%arg43) : i64 = (%125) to (%132) step (%67) {
            %134 = builtin.unrealized_conversion_cast %arg43 : i64 to index
            %135 = builtin.unrealized_conversion_cast %134 : index to i64
            %136 = llvm.extractvalue %76[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %137 = llvm.getelementptr %136[%135] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %138 = llvm.load %137 : !llvm.ptr -> i64
            %139 = builtin.unrealized_conversion_cast %138 : i64 to index
            %140 = llvm.mul %121, %59  : i64
            %141 = llvm.add %140, %138  : i64
            omp.parallel   {
              %142 = llvm.alloca %72 x f32 : (i64) -> !llvm.ptr
              omp.wsloop   for  (%arg44) : i64 = (%70) to (%60) step (%67) {
                %143 = llvm.mul %141, %60  : i64
                %144 = llvm.add %143, %arg44  : i64
                %145 = builtin.unrealized_conversion_cast %144 : i64 to index
                %146 = builtin.unrealized_conversion_cast %145 : index to i64
                %147 = llvm.getelementptr %86[%146] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                %148 = llvm.load %147 : !llvm.ptr -> f32
                %149 = llvm.extractvalue %77[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %150 = llvm.getelementptr %149[%135] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                %151 = llvm.load %150 : !llvm.ptr -> i64
                %152 = builtin.unrealized_conversion_cast %151 : i64 to index
                %153 = llvm.add %arg43, %67  : i64
                %154 = builtin.unrealized_conversion_cast %153 : i64 to index
                %155 = builtin.unrealized_conversion_cast %154 : index to i64
                %156 = llvm.extractvalue %77[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %157 = llvm.getelementptr %156[%155] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                %158 = llvm.load %157 : !llvm.ptr -> i64
                %159 = builtin.unrealized_conversion_cast %158 : i64 to index
                llvm.store %148, %142 : f32, !llvm.ptr
                omp.parallel   {
                  omp.wsloop   reduction(@__scf_reduction -> %142 : !llvm.ptr) for  (%arg45) : i64 = (%151) to (%158) step (%67) {
                    %162 = builtin.unrealized_conversion_cast %arg45 : i64 to index
                    %163 = builtin.unrealized_conversion_cast %162 : index to i64
                    %164 = llvm.intr.stacksave : !llvm.ptr
                    llvm.br ^bb1
                  ^bb1:  // pred: ^bb0
                    %165 = llvm.extractvalue %78[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                    %166 = llvm.getelementptr %165[%163] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                    %167 = llvm.load %166 : !llvm.ptr -> i64
                    %168 = builtin.unrealized_conversion_cast %167 : i64 to index
                    %169 = llvm.mul %arg44, %60  : i64
                    %170 = llvm.add %169, %167  : i64
                    %171 = builtin.unrealized_conversion_cast %170 : i64 to index
                    %172 = builtin.unrealized_conversion_cast %171 : index to i64
                    %173 = llvm.extractvalue %79[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                    %174 = llvm.getelementptr %173[%163] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                    %175 = llvm.load %174 : !llvm.ptr -> f32
                    %176 = llvm.extractvalue %80[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                    %177 = llvm.getelementptr %176[%172] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                    %178 = llvm.load %177 : !llvm.ptr -> f32
                    %179 = llvm.fmul %175, %178  : f32
                    omp.reduction %179, %142 : f32, !llvm.ptr
                    llvm.intr.stackrestore %164 : !llvm.ptr
                    llvm.br ^bb2
                  ^bb2:  // pred: ^bb1
                    omp.yield
                  }
                  omp.terminator
                }
                %160 = llvm.load %142 : !llvm.ptr -> f32
                %161 = llvm.getelementptr %86[%146] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                llvm.store %160, %161 : f32, !llvm.ptr
                omp.yield
              }
              omp.terminator
            }
            omp.yield
          }
          omp.terminator
        }
        omp.yield
      }
      omp.terminator
    }
    %114 = llvm.mlir.undef : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<3 x i64>, array<1 x i64>)>)>
    %115 = llvm.insertvalue %92, %114[0] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<3 x i64>, array<1 x i64>)>)> 
    %116 = llvm.insertvalue %105, %115[1] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<3 x i64>, array<1 x i64>)>)> 
    llvm.return %116 : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<3 x i64>, array<1 x i64>)>)>
  }
  llvm.func @_mlir_ciface_SpTMMul.Z.0.main(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr, %arg3: !llvm.ptr, %arg4: !llvm.ptr, %arg5: !llvm.ptr, %arg6: !llvm.ptr, %arg7: !llvm.ptr, %arg8: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg9: !llvm.ptr, %arg10: !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %5 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %6 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = llvm.extractvalue %6[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %8 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %9 = llvm.extractvalue %6[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %10 = llvm.extractvalue %6[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %11 = llvm.extractvalue %6[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %12 = llvm.load %arg3 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %13 = llvm.extractvalue %12[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.extractvalue %12[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.extractvalue %12[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.extractvalue %12[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.extractvalue %12[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.load %arg4 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %19 = llvm.extractvalue %18[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.extractvalue %18[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.extractvalue %18[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.extractvalue %18[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.extractvalue %18[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = llvm.load %arg5 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %25 = llvm.extractvalue %24[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %26 = llvm.extractvalue %24[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %27 = llvm.extractvalue %24[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %28 = llvm.extractvalue %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %29 = llvm.extractvalue %24[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.load %arg6 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %31 = llvm.extractvalue %30[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %32 = llvm.extractvalue %30[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.extractvalue %30[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = llvm.extractvalue %30[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %35 = llvm.extractvalue %30[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %36 = llvm.load %arg7 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %37 = llvm.extractvalue %36[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %38 = llvm.extractvalue %36[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %39 = llvm.extractvalue %36[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %40 = llvm.extractvalue %36[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %41 = llvm.extractvalue %36[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %42 = llvm.load %arg9 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %43 = llvm.extractvalue %42[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %44 = llvm.extractvalue %42[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %45 = llvm.extractvalue %42[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %46 = llvm.extractvalue %42[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %47 = llvm.extractvalue %42[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %48 = llvm.call @SpTMMul.Z.0.main(%1, %2, %3, %4, %5, %7, %8, %9, %10, %11, %13, %14, %15, %16, %17, %19, %20, %21, %22, %23, %25, %26, %27, %28, %29, %31, %32, %33, %34, %35, %37, %38, %39, %40, %41, %arg8, %43, %44, %45, %46, %47, %arg10) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.struct<(array<3 x i64>, array<7 x i64>)>, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) -> !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<3 x i64>, array<1 x i64>)>)>
    llvm.store %48, %arg0 : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<3 x i64>, array<1 x i64>)>)>, !llvm.ptr
    llvm.return
  }
}


// -----// IR Dump After ReconcileUnrealizedCasts (reconcile-unrealized-casts) //----- //
module attributes {llvm.data_layout = ""} {
  llvm.func @malloc(i64) -> !llvm.ptr
  omp.reduction.declare @__scf_reduction : f32 init {
  ^bb0(%arg0: f32):
    %0 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    omp.yield(%0 : f32)
  } combiner {
  ^bb0(%arg0: f32, %arg1: f32):
    %0 = llvm.fadd %arg0, %arg1  : f32
    omp.yield(%0 : f32)
  } atomic {
  ^bb0(%arg0: !llvm.ptr, %arg1: !llvm.ptr):
    %0 = llvm.load %arg1 : !llvm.ptr -> f32
    %1 = llvm.atomicrmw fadd %arg0, %0 monotonic : !llvm.ptr, f32
    omp.yield
  }
  llvm.func @SpTMMul.Z.0.main(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: !llvm.ptr, %arg6: !llvm.ptr, %arg7: i64, %arg8: i64, %arg9: i64, %arg10: !llvm.ptr, %arg11: !llvm.ptr, %arg12: i64, %arg13: i64, %arg14: i64, %arg15: !llvm.ptr, %arg16: !llvm.ptr, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: !llvm.ptr, %arg21: !llvm.ptr, %arg22: i64, %arg23: i64, %arg24: i64, %arg25: !llvm.ptr, %arg26: !llvm.ptr, %arg27: i64, %arg28: i64, %arg29: i64, %arg30: !llvm.ptr, %arg31: !llvm.ptr, %arg32: i64, %arg33: i64, %arg34: i64, %arg35: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg36: !llvm.ptr, %arg37: !llvm.ptr, %arg38: i64, %arg39: i64, %arg40: i64, %arg41: !llvm.struct<(array<2 x i64>, array<1 x i64>)>) -> !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<3 x i64>, array<1 x i64>)>)> attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = llvm.insertvalue %arg0, %0[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %2 = llvm.insertvalue %arg1, %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %3 = llvm.insertvalue %arg2, %2[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %4 = llvm.insertvalue %arg3, %3[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %5 = llvm.insertvalue %arg4, %4[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %6 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = llvm.insertvalue %arg5, %6[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %8 = llvm.insertvalue %arg6, %7[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %9 = llvm.insertvalue %arg7, %8[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %10 = llvm.insertvalue %arg8, %9[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %11 = llvm.insertvalue %arg9, %10[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %12 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %13 = llvm.insertvalue %arg10, %12[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.insertvalue %arg11, %13[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.insertvalue %arg12, %14[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.insertvalue %arg13, %15[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.insertvalue %arg14, %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %19 = llvm.insertvalue %arg15, %18[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.insertvalue %arg16, %19[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.insertvalue %arg17, %20[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %arg18, %21[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %arg19, %22[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %25 = llvm.insertvalue %arg20, %24[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %26 = llvm.insertvalue %arg21, %25[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %27 = llvm.insertvalue %arg22, %26[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %28 = llvm.insertvalue %arg23, %27[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %29 = llvm.insertvalue %arg24, %28[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %31 = llvm.insertvalue %arg25, %30[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %32 = llvm.insertvalue %arg26, %31[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.insertvalue %arg27, %32[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = llvm.insertvalue %arg28, %33[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %35 = llvm.insertvalue %arg29, %34[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %36 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %37 = llvm.insertvalue %arg30, %36[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %38 = llvm.insertvalue %arg31, %37[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %39 = llvm.insertvalue %arg32, %38[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %40 = llvm.insertvalue %arg33, %39[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %41 = llvm.insertvalue %arg34, %40[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %42 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %43 = llvm.insertvalue %arg36, %42[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %44 = llvm.insertvalue %arg37, %43[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %45 = llvm.insertvalue %arg38, %44[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %46 = llvm.insertvalue %arg39, %45[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %47 = llvm.insertvalue %arg40, %46[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %48 = llvm.mlir.constant(0 : index) : i64
    %49 = llvm.mlir.constant(1 : index) : i64
    %50 = llvm.mlir.constant(32768 : index) : i64
    %51 = llvm.mlir.constant(32 : index) : i64
    %52 = llvm.mlir.constant(64 : index) : i64
    %53 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %54 = llvm.mlir.constant(0 : i64) : i64
    %55 = llvm.mlir.constant(16 : i64) : i64
    %56 = llvm.mlir.constant(32 : i64) : i64
    %57 = llvm.mlir.constant(64 : i64) : i64
    %58 = llvm.mlir.constant(32768 : i64) : i64
    %59 = llvm.mlir.constant(1 : index) : i64
    %60 = llvm.mlir.constant(32768 : index) : i64
    %61 = llvm.mlir.constant(0 : index) : i64
    %62 = llvm.mlir.constant(1 : i64) : i64
    %63 = llvm.mlir.null : !llvm.ptr
    %64 = llvm.getelementptr %63[32768] : (!llvm.ptr) -> !llvm.ptr, f32
    %65 = llvm.ptrtoint %64 : !llvm.ptr to i64
    %66 = llvm.call @malloc(%65) : (i64) -> !llvm.ptr
    %67 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %68 = llvm.insertvalue %66, %67[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %69 = llvm.insertvalue %66, %68[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %70 = llvm.insertvalue %48, %69[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %71 = llvm.insertvalue %50, %70[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %72 = llvm.insertvalue %49, %71[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %73 = llvm.mlir.undef : !llvm.struct<(array<3 x i64>, array<1 x i64>)>
    %74 = llvm.insertvalue %54, %73[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %75 = llvm.insertvalue %55, %74[0, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %76 = llvm.insertvalue %56, %75[0, 1] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %77 = llvm.insertvalue %57, %76[0, 2] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    llvm.br ^bb1(%61 : i64)
  ^bb1(%78: i64):  // 2 preds: ^bb0, ^bb2
    %79 = llvm.icmp "slt" %78, %60 : i64
    llvm.cond_br %79, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %80 = llvm.getelementptr %66[%78] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %53, %80 : f32, !llvm.ptr
    %81 = llvm.add %78, %59  : i64
    llvm.br ^bb1(%81 : i64)
  ^bb3:  // pred: ^bb1
    %82 = llvm.insertvalue %58, %77[1, 0] : !llvm.struct<(array<3 x i64>, array<1 x i64>)> 
    %83 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %84 = llvm.getelementptr %83[%61] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %85 = llvm.load %84 : !llvm.ptr -> i64
    %86 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %87 = llvm.getelementptr %86[%59] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %88 = llvm.load %87 : !llvm.ptr -> i64
    omp.parallel   {
      omp.wsloop   for  (%arg42) : i64 = (%85) to (%88) step (%59) {
        %92 = llvm.extractvalue %11[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %93 = llvm.getelementptr %92[%arg42] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %94 = llvm.load %93 : !llvm.ptr -> i64
        %95 = llvm.extractvalue %17[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %96 = llvm.getelementptr %95[%arg42] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %97 = llvm.load %96 : !llvm.ptr -> i64
        %98 = llvm.add %arg42, %59  : i64
        %99 = llvm.extractvalue %17[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
        %100 = llvm.getelementptr %99[%98] : (!llvm.ptr, i64) -> !llvm.ptr, i64
        %101 = llvm.load %100 : !llvm.ptr -> i64
        omp.parallel   {
          omp.wsloop   for  (%arg43) : i64 = (%97) to (%101) step (%59) {
            %102 = llvm.extractvalue %23[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
            %103 = llvm.getelementptr %102[%arg43] : (!llvm.ptr, i64) -> !llvm.ptr, i64
            %104 = llvm.load %103 : !llvm.ptr -> i64
            %105 = llvm.mul %94, %51  : i64
            %106 = llvm.add %105, %104  : i64
            omp.parallel   {
              %107 = llvm.alloca %62 x f32 : (i64) -> !llvm.ptr
              omp.wsloop   for  (%arg44) : i64 = (%61) to (%52) step (%59) {
                %108 = llvm.mul %106, %52  : i64
                %109 = llvm.add %108, %arg44  : i64
                %110 = llvm.getelementptr %66[%109] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                %111 = llvm.load %110 : !llvm.ptr -> f32
                %112 = llvm.extractvalue %29[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %113 = llvm.getelementptr %112[%arg43] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                %114 = llvm.load %113 : !llvm.ptr -> i64
                %115 = llvm.add %arg43, %59  : i64
                %116 = llvm.extractvalue %29[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                %117 = llvm.getelementptr %116[%115] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                %118 = llvm.load %117 : !llvm.ptr -> i64
                llvm.store %111, %107 : f32, !llvm.ptr
                omp.parallel   {
                  omp.wsloop   reduction(@__scf_reduction -> %107 : !llvm.ptr) for  (%arg45) : i64 = (%114) to (%118) step (%59) {
                    %121 = llvm.intr.stacksave : !llvm.ptr
                    llvm.br ^bb1
                  ^bb1:  // pred: ^bb0
                    %122 = llvm.extractvalue %35[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                    %123 = llvm.getelementptr %122[%arg45] : (!llvm.ptr, i64) -> !llvm.ptr, i64
                    %124 = llvm.load %123 : !llvm.ptr -> i64
                    %125 = llvm.mul %arg44, %52  : i64
                    %126 = llvm.add %125, %124  : i64
                    %127 = llvm.extractvalue %41[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                    %128 = llvm.getelementptr %127[%arg45] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                    %129 = llvm.load %128 : !llvm.ptr -> f32
                    %130 = llvm.extractvalue %47[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
                    %131 = llvm.getelementptr %130[%126] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                    %132 = llvm.load %131 : !llvm.ptr -> f32
                    %133 = llvm.fmul %129, %132  : f32
                    omp.reduction %133, %107 : f32, !llvm.ptr
                    llvm.intr.stackrestore %121 : !llvm.ptr
                    llvm.br ^bb2
                  ^bb2:  // pred: ^bb1
                    omp.yield
                  }
                  omp.terminator
                }
                %119 = llvm.load %107 : !llvm.ptr -> f32
                %120 = llvm.getelementptr %66[%109] : (!llvm.ptr, i64) -> !llvm.ptr, f32
                llvm.store %119, %120 : f32, !llvm.ptr
                omp.yield
              }
              omp.terminator
            }
            omp.yield
          }
          omp.terminator
        }
        omp.yield
      }
      omp.terminator
    }
    %89 = llvm.mlir.undef : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<3 x i64>, array<1 x i64>)>)>
    %90 = llvm.insertvalue %72, %89[0] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<3 x i64>, array<1 x i64>)>)> 
    %91 = llvm.insertvalue %82, %90[1] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<3 x i64>, array<1 x i64>)>)> 
    llvm.return %91 : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<3 x i64>, array<1 x i64>)>)>
  }
  llvm.func @_mlir_ciface_SpTMMul.Z.0.main(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr, %arg3: !llvm.ptr, %arg4: !llvm.ptr, %arg5: !llvm.ptr, %arg6: !llvm.ptr, %arg7: !llvm.ptr, %arg8: !llvm.struct<(array<3 x i64>, array<7 x i64>)>, %arg9: !llvm.ptr, %arg10: !llvm.struct<(array<2 x i64>, array<1 x i64>)>) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %5 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %6 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = llvm.extractvalue %6[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %8 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %9 = llvm.extractvalue %6[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %10 = llvm.extractvalue %6[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %11 = llvm.extractvalue %6[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %12 = llvm.load %arg3 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %13 = llvm.extractvalue %12[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.extractvalue %12[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.extractvalue %12[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.extractvalue %12[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.extractvalue %12[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.load %arg4 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %19 = llvm.extractvalue %18[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.extractvalue %18[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.extractvalue %18[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.extractvalue %18[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.extractvalue %18[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = llvm.load %arg5 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %25 = llvm.extractvalue %24[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %26 = llvm.extractvalue %24[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %27 = llvm.extractvalue %24[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %28 = llvm.extractvalue %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %29 = llvm.extractvalue %24[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.load %arg6 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %31 = llvm.extractvalue %30[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %32 = llvm.extractvalue %30[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.extractvalue %30[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = llvm.extractvalue %30[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %35 = llvm.extractvalue %30[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %36 = llvm.load %arg7 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %37 = llvm.extractvalue %36[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %38 = llvm.extractvalue %36[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %39 = llvm.extractvalue %36[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %40 = llvm.extractvalue %36[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %41 = llvm.extractvalue %36[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %42 = llvm.load %arg9 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %43 = llvm.extractvalue %42[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %44 = llvm.extractvalue %42[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %45 = llvm.extractvalue %42[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %46 = llvm.extractvalue %42[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %47 = llvm.extractvalue %42[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %48 = llvm.call @SpTMMul.Z.0.main(%1, %2, %3, %4, %5, %7, %8, %9, %10, %11, %13, %14, %15, %16, %17, %19, %20, %21, %22, %23, %25, %26, %27, %28, %29, %31, %32, %33, %34, %35, %37, %38, %39, %40, %41, %arg8, %43, %44, %45, %46, %47, %arg10) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.struct<(array<3 x i64>, array<7 x i64>)>, !llvm.ptr, !llvm.ptr, i64, i64, i64, !llvm.struct<(array<2 x i64>, array<1 x i64>)>) -> !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<3 x i64>, array<1 x i64>)>)>
    llvm.store %48, %arg0 : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<3 x i64>, array<1 x i64>)>)>, !llvm.ptr
    llvm.return
  }
}


